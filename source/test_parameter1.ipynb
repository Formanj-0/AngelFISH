{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "946feaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import xarray as xr\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import zarr\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, zarr_path):\n",
    "        self._zarr_path = Path(zarr_path)\n",
    "        self._ds = None\n",
    "        self._loaded = False\n",
    "\n",
    "        self._ds = self.dataset\n",
    "\n",
    "    @property\n",
    "    def zarr_path(self):\n",
    "        return self._zarr_path\n",
    "\n",
    "    @zarr_path.setter\n",
    "    def zarr_path(self, new_path):\n",
    "        self._zarr_path = Path(new_path)\n",
    "        self._loaded = False  # force reload on next access\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        \"\"\"Lazily load the dataset if not already loaded.\"\"\"\n",
    "        if not self._zarr_path.exists():\n",
    "            self._zarr_path.mkdir(parents=True, exist_ok=True)\n",
    "            zarr.open(self._zarr_path, mode='w')  # Initialize an empty Zarr dataset\n",
    "        if not self._loaded:\n",
    "            self._ds = zarr.open(self._zarr_path, mode='a')  # Open in append mode for read/write access\n",
    "            self._loaded = True\n",
    "        return self._ds\n",
    "\n",
    "    def __get__(self, instance, value):\n",
    "        # Retrieve the value from the Zarr dataset\n",
    "        return self.dataset.get(value, None)\n",
    "    \n",
    "    def __set__(self, instance, value):\n",
    "        # Store the value in the Zarr dataset\n",
    "        self.dataset[instance] = value\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be2f2b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project': 'neuro123', 'date': '2025-04-27'}\n"
     ]
    }
   ],
   "source": [
    "zimg = Data(\"zarr_output/big_image_stack.zarr\")\n",
    "\n",
    "zimg.metadata = {\"project\": \"neuro123\", \"date\": \"2025-04-27\"}\n",
    "print(zimg.metadata)\n",
    "\n",
    "# Generate a fake image and store it in the dataset\n",
    "fake_image = np.random.rand(100, 100)  # Create a 100x100 random image\n",
    "zimg.images = fake_image[np.newaxis, ...]  # Add a new time dimension and store it\n",
    "\n",
    "# Get a slice of images\n",
    "slice_stack = zimg.images[0]\n",
    "\n",
    "# Compute mean and save\n",
    "zimg.mean = slice_stack.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35452b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 completed. Data shape: (10, 10)\n",
      "Task 1 completed. Data shape: (10, 10)\n",
      "Task 2 completed. Data shape: (10, 10)\n",
      "Task 3 completed. Data shape: (10, 10)\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np\n",
    "\n",
    "# Function to simulate parallel access to the Data class\n",
    "def parallel_task(zimg, task_id):\n",
    "    # Each task writes and reads data\n",
    "    zimg.dataset[f\"task_{task_id}_data\"] = np.random.rand(10, 10)\n",
    "    retrieved_data = zimg.dataset[f\"task_{task_id}_data\"]\n",
    "    return f\"Task {task_id} completed. Data shape: {retrieved_data.shape}\"\n",
    "\n",
    "# Create a ThreadPoolExecutor to test parallel access\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    # Submit multiple tasks to the executor\n",
    "    futures = [executor.submit(parallel_task, zimg, i) for i in range(4)]\n",
    "\n",
    "    # Collect and print results\n",
    "    for future in futures:\n",
    "        print(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ba5520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed slice 0 saved. Shape: (25, 100)\n",
      "Processed slice 1 saved. Shape: (25, 100)\n",
      "Processed slice 2 saved. Shape: (25, 100)\n",
      "Processed slice 3 saved. Shape: (25, 100)\n"
     ]
    }
   ],
   "source": [
    "# Function to perform computation on a slice of the image and save the result\n",
    "def process_and_save(zimg, image_slice, index):\n",
    "    # Perform some computation (e.g., compute the square of the slice)\n",
    "    processed_slice = np.square(image_slice)\n",
    "    # Save the processed slice to the Zarr dataset\n",
    "    zimg.dataset[f\"processed_slice_{index}\"] = processed_slice\n",
    "    return f\"Processed slice {index} saved. Shape: {processed_slice.shape}\"\n",
    "\n",
    "# Split the fake_image into chunks for parallel processing\n",
    "num_chunks = 4\n",
    "image_chunks = np.array_split(fake_image, num_chunks, axis=0)\n",
    "\n",
    "# Use ThreadPoolExecutor to process and save each chunk in parallel\n",
    "with ThreadPoolExecutor(max_workers=num_chunks) as executor:\n",
    "    futures = [\n",
    "        executor.submit(process_and_save, zimg, chunk, i)\n",
    "        for i, chunk in enumerate(image_chunks)\n",
    "    ]\n",
    "\n",
    "    # Collect and print results\n",
    "    for future in futures:\n",
    "        print(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e4f62a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled slice 0 saved. Shape: (25, 100)\n",
      "Scaled slice 1 saved. Shape: (25, 100)\n",
      "Scaled slice 2 saved. Shape: (25, 100)\n",
      "Scaled slice 3 saved. Shape: (25, 100)\n"
     ]
    }
   ],
   "source": [
    "# Function to scale a chunk and save it to the Zarr dataset\n",
    "def scale_and_save(zimg, chunk, index):\n",
    "    scaled_chunk = chunk * 1000\n",
    "    zimg.dataset[f\"scaled_slice_{index}\"] = scaled_chunk\n",
    "    return f\"Scaled slice {index} saved. Shape: {scaled_chunk.shape}\"\n",
    "\n",
    "# Use ThreadPoolExecutor to process and save each chunk in parallel\n",
    "with ThreadPoolExecutor(max_workers=num_chunks) as executor:\n",
    "    futures = [\n",
    "        executor.submit(scale_and_save, zimg, chunk, i)\n",
    "        for i, chunk in enumerate(image_chunks)\n",
    "    ]\n",
    "\n",
    "    # Collect and print results\n",
    "    for future in futures:\n",
    "        print(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b35dbaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Mask: nuc_mask\n",
      "Shape: (100, 100)\n",
      "Unique values: [0 1]\n",
      "\n",
      "Saved Mask: cyto_mask\n",
      "Shape: (100, 100)\n",
      "Unique values: [0 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example dictionary of masks\n",
    "masks = {\n",
    "    \"nuc_mask\": np.random.randint(0, 2, size=(100, 100)),  # Binary mask for nucleus\n",
    "    \"cyto_mask\": np.random.randint(0, 2, size=(100, 100))  # Binary mask for cytoplasm\n",
    "}\n",
    "\n",
    "# Save masks to the Zarr dataset\n",
    "for mask_name, mask_array in masks.items():\n",
    "    zimg.dataset[f\"mask_{mask_name}\"] = mask_array\n",
    "\n",
    "# Test the saved masks\n",
    "for mask_name in masks.keys():\n",
    "    saved_mask = zimg.dataset[f\"mask_{mask_name}\"][:]\n",
    "    print(f\"Saved Mask: {mask_name}\")\n",
    "    print(f\"Shape: {saved_mask.shape}\")\n",
    "    print(f\"Unique values: {np.unique(saved_mask)}\")  # Should be 0 and 1 for binary masks\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1f63d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
