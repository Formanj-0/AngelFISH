{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda:0') # use the first GPU on this system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in h5 file\n",
    "h5_location = r'C:\\Users\\formanj\\GitHub\\FISH_Processing\\Demos\\DUSP1_Dex_0min_20220224\\DUSP1_Dex_0min_20220224.h5'\n",
    "h5_file = h5py.File(h5_location, 'r') # making this read is important otherwise you may get WINERROR 33\n",
    "\n",
    "level = 1\n",
    "\n",
    "def print_group(name, obj):\n",
    "    # Calculate current level based on the name depth\n",
    "    current_level = name.count('/')\n",
    "    if current_level <= level:\n",
    "        print(\"  \" * 2 * current_level + f\"- {name}\")\n",
    "\n",
    "h5_file.visititems(print_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the spot df \n",
    "spots = pd.read_hdf(h5_location, key='Analysis_demo_2024-11-21/df_spotresults')\n",
    "spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in images\n",
    "d = h5_file['raw_images']\n",
    "# p, t, c, z, y, x\n",
    "images = da.from_array(d, (1,1,-1,-1,-1,-1))\n",
    "\n",
    "# display each of the channels\n",
    "def display_channel(channel):\n",
    "    plt.imshow(np.max(images[0,0,channel,:,:,:], axis=0))\n",
    "    # increase the contrast of the image automatically\n",
    "    plt.clim(0, np.percentile(images[0,0,channel,:,:,:].flatten(), 99.99))\n",
    "    plt.show()\n",
    "\n",
    "for i in range(images.shape[2]):\n",
    "    display_channel(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build gui to classify spots\n",
    "def classify_spots(image, spot_df, fish_channel):\n",
    "    # Go to the first position (index 0), first time point (index 1), and the fish channel (index 2)\n",
    "    img = image[0, 0, fish_channel, :, :, :]\n",
    "    \n",
    "    # Max project on the z axis (index 4)\n",
    "    max_proj_img = np.max(img, axis=0)\n",
    "    \n",
    "    # Create a column of NaN in the spot df called good_spots\n",
    "    spot_df['good_spots'] = np.nan\n",
    "    \n",
    "    # Initialize the position index\n",
    "    pos_index = 0\n",
    "\n",
    "    current_spots = spot_df[spot_df['fov'] == 0]\n",
    "    \n",
    "    if current_spots.empty:\n",
    "        print(f\"No spots found for position {0}\")\n",
    "        return\n",
    "    \n",
    "    def update_display(idx):\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Filter spots for the current position\n",
    "        current_spots = spot_df[spot_df['fov'] == pos_index]\n",
    "        spot = current_spots.iloc[idx]\n",
    "        if current_spots.empty:\n",
    "            print(f\"No spots found for position {pos_index}\")\n",
    "            return\n",
    "        \n",
    "        # Display each spot\n",
    "        y, x = int(spot['y_px']), int(spot['x_px'])\n",
    "\n",
    "        crop = max_proj_img[y-15:y+15, x-15:x+15]\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        \n",
    "        im = ax[0].imshow(max_proj_img)\n",
    "        ax[0].set_xlim(x-100 if x-100 > 0 else 0, x+100 if x+100 < max_proj_img.shape[1] else max_proj_img.shape[1])\n",
    "        ax[0].set_ylim(y-100 if y-100 > 0 else 0, y+100 if y+100 < max_proj_img.shape[0] else max_proj_img.shape[0])\n",
    "        ax[0].scatter([x], [y], c='r')\n",
    "        im.set_clim(0, np.percentile(max_proj_img.flatten(), 99.99)) # TODO: Use big fish strech function\n",
    "        ax[0].set_title('Max Projected Image')\n",
    "        \n",
    "        im = ax[1].imshow(crop)\n",
    "        im.set_clim(0, np.percentile(crop.flatten(), 99.99))\n",
    "        ax[1].set_title('Spot Crop')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        def mark_good(b):\n",
    "            nonlocal idx\n",
    "            spot_df.at[idx, 'good_spots'] = 1\n",
    "            idx += 1\n",
    "            update_display(idx)\n",
    "        \n",
    "        def mark_bad(b):\n",
    "            nonlocal idx\n",
    "            spot_df.at[idx, 'good_spots'] = 0\n",
    "            idx += 1\n",
    "            update_display(idx)\n",
    "        \n",
    "        def next_image(b):\n",
    "            nonlocal pos_index\n",
    "            nonlocal idx\n",
    "            nonlocal img\n",
    "            nonlocal max_proj_img\n",
    "            pos_index += 1\n",
    "            idx = 0\n",
    "            img = image[pos_index, 0, fish_channel, :, :, :]\n",
    "            # Max project on the z axis (index 4)\n",
    "            max_proj_img = np.max(img, axis=0)\n",
    "            update_display(idx)\n",
    "        \n",
    "        def finish(b):\n",
    "            print(\"Finished classifying spots\")\n",
    "            return\n",
    "\n",
    "        finish_button = widgets.Button(description=\"Finish\")\n",
    "        finish_button.on_click(finish)\n",
    "        \n",
    "        good_button = widgets.Button(description=\"Good Spot\")\n",
    "        good_button.on_click(mark_good)\n",
    "        \n",
    "        bad_button = widgets.Button(description=\"Bad Spot\")\n",
    "        bad_button.on_click(mark_bad)\n",
    "        \n",
    "        next_button = widgets.Button(description=\"Next Image\")\n",
    "        next_button.on_click(next_image)\n",
    "        \n",
    "        display(widgets.HBox([good_button, bad_button, next_button, finish_button]))\n",
    "\n",
    "\n",
    "    break_loop = False\n",
    "    idx = 0\n",
    "    spot = current_spots.iloc[idx]\n",
    "    update_display(idx)\n",
    "\n",
    "# Example usage\n",
    "classify_spots(images, spots, fish_channel=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build binary classifier to classify spots as good or bad\n",
    "input_width = 36\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 1, kernel_size=3, padding=1),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Conv2d(1, 1, kernel_size=3, padding=1),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(input_width**2, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "loss = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier\n",
    "def extract_images(image, xyz, width):\n",
    "    z, y, x = xyz\n",
    "    return np.max(image[:, y-width//2:y+width//2, x-width//2:x+width//2], axis=0)\n",
    "\n",
    "dataset = []\n",
    "for i, row in spots.iterrows():\n",
    "    if row['good_spots'] == 1 or row['good_spots'] == 0:\n",
    "        # Extract the image\n",
    "        img = extract_images(images[row['fov'], row['timepoint'], row['FISH_Channel']:, :, :], (row['z_px'], row['y_px'], row['x_px']), input_width)\n",
    "\n",
    "        dataset.append(img)\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, img in enumerate(dataset):\n",
    "        img = torch.tensor(img).unsqueeze(0).unsqueeze(0).float()\n",
    "        y = torch.tensor(spots.iloc[i]['good_spots']).float()\n",
    "        \n",
    "        y_pred = model(img)\n",
    "        l = loss(y_pred, y)\n",
    "        \n",
    "        l.backward()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Image {i}, Loss: {l}\")\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data location of training data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
