{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs available: 2\n",
      "GPU 0: NVIDIA GeForce RTX 2070\n",
      "GPU 1: NVIDIA GeForce RTX 2070\n",
      "GPU 0 memory allocated: 0.00 GB\n",
      "GPU 0 memory reserved: 0.00 GB\n",
      "GPU 1 memory allocated: 0.00 GB\n",
      "GPU 1 memory reserved: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    # Get the number of GPUs available\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "\n",
    "    # Get the name of each GPU\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "\n",
    "    # Get the current GPU memory usage\n",
    "    for i in range(num_gpus):\n",
    "        gpu_memory_allocated = torch.cuda.memory_allocated(i)\n",
    "        gpu_memory_reserved = torch.cuda.memory_reserved(i)\n",
    "        print(f\"GPU {i} memory allocated: {gpu_memory_allocated / (1024 ** 3):.2f} GB\")\n",
    "        print(f\"GPU {i} memory reserved: {gpu_memory_reserved / (1024 ** 3):.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 16 threads.\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import numba\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)\n",
    "\n",
    "matplotlib_logger = logging.getLogger('matplotlib')\n",
    "matplotlib_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Add the src directory to sys.path\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.IndependentSteps import Pycromanager2NativeDataType, FFF2NativeDataType\n",
    "\n",
    "from src.SequentialSteps import BIGFISH_SpotDetection, SimpleCellposeSegmentaion, Calculate_BIGFISH_Threshold\n",
    "\n",
    "from src.FinalizationSteps import Save_Outputs, Save_Images, Save_Parameters, Save_Masks, return_to_NAS, remove_local_data_but_keep_h5\n",
    "\n",
    "from src.Parameters import Parameters, Experiment, Settings, ScopeClass, DataContainer\n",
    "\n",
    "from src.Displays import Display\n",
    "\n",
    "from src.GUI import GUI, StepGUI\n",
    "\n",
    "from src.Pipeline import Pipeline\n",
    "\n",
    "from src.GeneralStep import SequentialStepsClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you initialize the parameters\n",
    "scope = ScopeClass() \n",
    "data = DataContainer() # you can also initialize these with parameters, but it is not necessary due to defaults\n",
    "settings = Settings(name='test') # you also must give a name for the analysis your are doing\n",
    "experiment = Experiment()\n",
    "\n",
    "SequentialStepsClass.order = 'parallel'\n",
    "\n",
    "experiment.initial_data_location = ['smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224']\n",
    "                                    # 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_10min_20220224']\n",
    "data.local_dataset_location = None # [r'C:\\Users\\formanj\\GitHub\\FISH_Processing\\Demos\\DUSP1_Dex_10min_20220224', r'C:\\Users\\formanj\\GitHub\\FISH_Processing\\Demos\\DUSP1_Dex_0min_20220224']\n",
    "experiment.FISHChannel = 0\n",
    "experiment.nucChannel = 2\n",
    "experiment.cytoChannel = 1\n",
    "experiment.voxel_size_z = 500\n",
    "\n",
    "settings.num_chunks_to_run = 10 # this is the limit to how many chunks you want to run and it will stop after that\n",
    "\n",
    "scope.spot_yx = 130\n",
    "scope.spot_z = 360\n",
    "scope.voxel_size_yx = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment:\n",
      "initial_data_location: ['smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224'] \n",
      "index_dict: None \n",
      "nucChannel: 2 \n",
      "cytoChannel: 1 \n",
      "FISHChannel: 0 \n",
      "voxel_size_z: 500 \n",
      "independent_params: None \n",
      "kwargs: None \n",
      "timestep_s: None \n",
      "\n",
      "Settings:\n",
      "name: test \n",
      "return_data_to_NAS: True \n",
      "NUMBER_OF_CORES: 4 \n",
      "save_files: True \n",
      "num_chunks_to_run: 10 \n",
      "download_data_from_NAS: True \n",
      "connection_config_location: c:\\Users\\formanj\\GitHub\\AngelFISH\\config_nas.yml \n",
      "share_name: share \n",
      "display_plots: True \n",
      "load_in_mask: False \n",
      "mask_structure: {'masks': ('ptczyx', None, None), 'cell_mask': ('zyx', 'cytoChannel', 'masks'), 'nuc_mask': ('zyx', 'nucChannel', 'masks')} \n",
      "\n",
      "ScopeClass:\n",
      "voxel_size_yx: 100 \n",
      "spot_z: 360 \n",
      "spot_yx: 130 \n",
      "microscope_saving_format: pycromanager \n",
      "\n",
      "DataContainer:\n",
      "local_dataset_location: None \n",
      "h5_file: None \n",
      "total_num_chunks: None \n",
      "images: None \n",
      "masks: None \n",
      "temp: <TemporaryDirectory 'c:\\\\Users\\\\formanj\\\\GitHub\\\\AngelFISH\\\\dev\\\\tmpaq4opyv0'> \n",
      "clear_after_error: True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can see the parameters in each of these classes by printing them\n",
    "print(experiment)\n",
    "print(settings)\n",
    "print(scope)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'voxel_size_yx': 100,\n",
       " 'spot_z': 360,\n",
       " 'spot_yx': 130,\n",
       " 'microscope_saving_format': 'pycromanager',\n",
       " 'local_dataset_location': None,\n",
       " 'h5_file': None,\n",
       " 'total_num_chunks': None,\n",
       " 'images': None,\n",
       " 'masks': None,\n",
       " 'temp': <TemporaryDirectory 'c:\\\\Users\\\\formanj\\\\GitHub\\\\AngelFISH\\\\dev\\\\tmpaq4opyv0'>,\n",
       " 'clear_after_error': True,\n",
       " 'name': 'test',\n",
       " 'return_data_to_NAS': True,\n",
       " 'NUMBER_OF_CORES': 4,\n",
       " 'save_files': True,\n",
       " 'num_chunks_to_run': 10,\n",
       " 'download_data_from_NAS': True,\n",
       " 'connection_config_location': 'c:\\\\Users\\\\formanj\\\\GitHub\\\\AngelFISH\\\\config_nas.yml',\n",
       " 'share_name': 'share',\n",
       " 'display_plots': True,\n",
       " 'load_in_mask': False,\n",
       " 'mask_structure': {'masks': ('ptczyx', None, None),\n",
       "  'cell_mask': ('zyx', 'cytoChannel', 'masks'),\n",
       "  'nuc_mask': ('zyx', 'nucChannel', 'masks')},\n",
       " 'initial_data_location': ['smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224'],\n",
       " 'index_dict': None,\n",
       " 'nucChannel': 2,\n",
       " 'cytoChannel': 1,\n",
       " 'FISHChannel': 0,\n",
       " 'voxel_size_z': 500,\n",
       " 'independent_params': None,\n",
       " 'kwargs': None,\n",
       " 'timestep_s': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can get all of the parameters that you have initialized by calling get_parameters\n",
    "Parameters.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# You can check that all the manditory parameters are set by calling validate\n",
    "Parameters.validate()\n",
    "\n",
    "# this will give you two type of response, one if its a warning like this one below\n",
    "# this is just a warning because you may not have a cytoChannel,\n",
    "# but it is not manditory so the pipeline will still run\n",
    "# there are also errors that will stop the pipeline from running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting local_dataset_location in DataContainer\n",
      "Overwriting h5_file in DataContainer\n",
      "Overwriting total_num_chunks in DataContainer\n",
      "Overwriting independent_params in Experiment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'local_dataset_location': ['c:\\\\Users\\\\formanj\\\\GitHub\\\\AngelFISH\\\\dataBases\\\\DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'],\n",
       " 'h5_file': [<HDF5 file \"DUSP1_Dex_0min_20220224.h5\" (mode r)>],\n",
       " 'total_num_chunks': 30,\n",
       " 'images': dask.array<rechunk-merge, shape=(30, 1, 3, 27, 936, 640), dtype=float32, chunksize=(1, 1, 3, 27, 936, 640), chunktype=numpy.ndarray>,\n",
       " 'masks': dask.array<rechunk-merge, shape=(30, 1, 3, 27, 936, 640), dtype=int8, chunksize=(1, 1, 3, 27, 936, 640), chunktype=numpy.ndarray>,\n",
       " 'independent_params': {0: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  1: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  2: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  3: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  4: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  5: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  6: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  7: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  8: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  9: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  10: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  11: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  12: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  13: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  14: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  15: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  16: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  17: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  18: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  19: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  20: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  21: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  22: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  23: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  24: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  25: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  26: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  27: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  28: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  29: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'}},\n",
       " 'position_indexs': array([30])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want this to load in the previous made masks\n",
    "settings.load_in_mask = True\n",
    "FFF2NativeDataType().run() # this will run the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you would like to remove the original data from disk\n",
    "remove_local_data_but_keep_h5().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:asyncio:Using selector: SelectSelector\n",
      "INFO:distributed.scheduler:State start\n",
      "INFO:distributed.diskutils:Found stale lock file and directory 'c:\\\\temp\\\\dask-scratch-space\\\\scheduler-mw5ezivm', purging\n",
      "INFO:distributed.diskutils:Found stale lock file and directory 'c:\\\\temp\\\\dask-scratch-space\\\\worker-0eth6h59', purging\n",
      "INFO:distributed.diskutils:Found stale lock file and directory 'c:\\\\temp\\\\dask-scratch-space\\\\worker-0xa2cdxm', purging\n",
      "INFO:distributed.diskutils:Found stale lock file and directory 'c:\\\\temp\\\\dask-scratch-space\\\\worker-2_72t0q_', purging\n",
      "INFO:distributed.diskutils:Found stale lock file and directory 'c:\\\\temp\\\\dask-scratch-space\\\\worker-6bfeipi2', purging\n",
      "INFO:distributed.diskutils:Found stale lock file and directory 'c:\\\\temp\\\\dask-scratch-space\\\\worker-j01vcdts', purging\n",
      "INFO:distributed.diskutils:Found stale lock file and directory 'c:\\\\temp\\\\dask-scratch-space\\\\worker-p6a_hipp', purging\n",
      "INFO:distributed.diskutils:Found stale lock file and directory 'c:\\\\temp\\\\dask-scratch-space\\\\worker-qec5y_43', purging\n",
      "INFO:distributed.diskutils:Found stale lock file and directory 'c:\\\\temp\\\\dask-scratch-space\\\\worker-qzr99_ep', purging\n",
      "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:52546\n",
      "INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:8787/status\n",
      "INFO:distributed.scheduler:Registering Worker plugin shuffle\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:52563'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:52555'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:52557'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:52559'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:52553'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:52551'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:52561'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:52549'\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:52583', name: 1, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:52583\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52589\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:52582', name: 6, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:52582\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52594\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:52584', name: 5, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:52584\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52593\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:52586', name: 0, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:52586\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52596\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:52585', name: 2, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:52585\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52598\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:52587', name: 3, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:52587\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52601\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:52590', name: 4, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:52590\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52603\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:52599', name: 7, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:52599\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52605\n",
      "INFO:distributed.scheduler:Receive client connection: Client-0080c216-d068-11ef-be5c-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52606\n",
      "INFO:distributed.scheduler:Receive client connection: Client-worker-099fbf36-d068-11ef-8f68-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52613\n",
      "INFO:distributed.scheduler:Receive client connection: Client-worker-099cad4e-d068-11ef-b300-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52614\n",
      "INFO:distributed.scheduler:Receive client connection: Client-worker-099dbfe5-d068-11ef-be20-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52612\n",
      "INFO:distributed.scheduler:Receive client connection: Client-worker-099f20f4-d068-11ef-9610-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52615\n",
      "INFO:distributed.scheduler:Receive client connection: Client-worker-099e5da2-d068-11ef-b9e4-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52625\n",
      "INFO:distributed.scheduler:Receive client connection: Client-worker-099e84aa-d068-11ef-bae8-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52624\n",
      "INFO:distributed.scheduler:Receive client connection: Client-worker-099ab116-d068-11ef-96c4-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52623\n",
      "INFO:distributed.scheduler:Receive client connection: Client-worker-099ab116-d068-11ef-9560-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred. Temp data deleted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\formanj\\GitHub\\AngelFISH\\src\\GeneralStep.py\", line 15, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\formanj\\GitHub\\AngelFISH\\src\\GeneralStep.py\", line 295, in run\n",
      "    result = future.result()\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\formanj\\GitHub\\AngelFISH\\.venv\\Lib\\site-packages\\distributed\\client.py\", line 402, in result\n",
      "    return self.client.sync(self._result, callback_timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\formanj\\GitHub\\AngelFISH\\src\\SequentialSteps\\SpotDetection_Steps.py\", line 411, in main\n",
      "    spots, clusters = self.standardize_df(cell_results, spots_px, spots_subpx, sub_pixel_fitting, clusters, FISHChannel[c], timepoint, fov, independent_params)\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\formanj\\GitHub\\AngelFISH\\src\\SequentialSteps\\SpotDetection_Steps.py\", line 638, in standardize_df\n",
      "    df_spotresults = pd.DataFrame(spots_px, columns=['z_px', 'y_px', 'x_px', 'cluster_index', 'is_nuc', 'cell_label', 'snr', 'signal'])\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\formanj\\GitHub\\AngelFISH\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 420, in _check_values_indices_shape_match\n",
      "    raise ValueError(f\"Shape of passed values is {passed}, indices imply {implied}\")\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "ValueError: Shape of passed values is (941, 6), indices imply (941, 8)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (941, 6), indices imply (941, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mBIGFISH_SpotDetection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\formanj\\GitHub\\AngelFISH\\src\\GeneralStep.py:21\u001b[0m, in \u001b[0;36mhandle_errors.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred. Temp data deleted.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\formanj\\GitHub\\AngelFISH\\src\\GeneralStep.py:15\u001b[0m, in \u001b[0;36mhandle_errors.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 15\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m DataContainer()\u001b[38;5;241m.\u001b[39mclear_after_error:\n",
      "File \u001b[1;32mc:\\Users\\formanj\\GitHub\\AngelFISH\\src\\GeneralStep.py:295\u001b[0m, in \u001b[0;36mSequentialStepsClass.run\u001b[1;34m(self, p, t)\u001b[0m\n\u001b[0;32m    292\u001b[0m         count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):\n\u001b[1;32m--> 295\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     DataContainer()\u001b[38;5;241m.\u001b[39msave_results(result, p, t)\n\u001b[0;32m    298\u001b[0m client\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\formanj\\GitHub\\AngelFISH\\.venv\\Lib\\site-packages\\distributed\\client.py:402\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_initialized()\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\formanj\\GitHub\\AngelFISH\\src\\SequentialSteps\\SpotDetection_Steps.py:411\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    405\u001b[0m     cell_results, spots_px, clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_cell_level_results(image, spots_px, clusters, nucChannel, FISHChannel[c], \n\u001b[0;32m    406\u001b[0m                                                     nuc_mask, cell_mask, timepoint, fov,\n\u001b[0;32m    407\u001b[0m                                                     verbose, display_plots)\n\u001b[0;32m    409\u001b[0m     spots_px \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_spot_properties(rna, spots_px, voxel_size_yx, voxel_size_z, spot_yx, spot_z, display_plots, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 411\u001b[0m     spots, clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstandardize_df(cell_results, spots_px, spots_subpx, sub_pixel_fitting, clusters, FISHChannel[c], timepoint, fov, independent_params)\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;66;03m# output = SpotDetectionOutputClass(cell_results, spots, clusters, threshold)\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcellresults\u001b[39m\u001b[38;5;124m'\u001b[39m: cell_results, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspotresults\u001b[39m\u001b[38;5;124m'\u001b[39m: spots, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclusterresults\u001b[39m\u001b[38;5;124m'\u001b[39m: clusters, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindividual_spotdetection_thresholds\u001b[39m\u001b[38;5;124m'\u001b[39m: threshold}\n",
      "File \u001b[1;32mc:\\Users\\formanj\\GitHub\\AngelFISH\\src\\SequentialSteps\\SpotDetection_Steps.py:638\u001b[0m, in \u001b[0;36mstandardize_df\u001b[1;34m()\u001b[0m\n\u001b[0;32m    635\u001b[0m         df_clusterresults \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(clusters, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz_px\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_px\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_px\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb_spots\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_index\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_nuc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcell_label\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    637\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 638\u001b[0m         df_spotresults \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(spots_px, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz_px\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_px\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_px\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_index\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_nuc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcell_label\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignal\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    639\u001b[0m         df_clusterresults \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(clusters, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz_px\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_px\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_px\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb_spots\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_index\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_nuc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcell_label\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\formanj\\GitHub\\AngelFISH\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m()\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (941, 6), indices imply (941, 8)"
     ]
    }
   ],
   "source": [
    "BIGFISH_SpotDetection().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see the parameters in each of these classes by printing them\n",
    "print(experiment)\n",
    "print(settings)\n",
    "print(scope)\n",
    "print(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
