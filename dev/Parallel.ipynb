{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs available: 2\n",
      "GPU 0: NVIDIA GeForce RTX 2070\n",
      "GPU 1: NVIDIA GeForce RTX 2070\n",
      "GPU 0 memory allocated: 0.00 GB\n",
      "GPU 0 memory reserved: 0.00 GB\n",
      "GPU 1 memory allocated: 0.00 GB\n",
      "GPU 1 memory reserved: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    # Get the number of GPUs available\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "\n",
    "    # Get the name of each GPU\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "\n",
    "    # Get the current GPU memory usage\n",
    "    for i in range(num_gpus):\n",
    "        gpu_memory_allocated = torch.cuda.memory_allocated(i)\n",
    "        gpu_memory_reserved = torch.cuda.memory_reserved(i)\n",
    "        print(f\"GPU {i} memory allocated: {gpu_memory_allocated / (1024 ** 3):.2f} GB\")\n",
    "        print(f\"GPU {i} memory reserved: {gpu_memory_reserved / (1024 ** 3):.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 16 threads.\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import numba\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)\n",
    "\n",
    "matplotlib_logger = logging.getLogger('matplotlib')\n",
    "matplotlib_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Add the src directory to sys.path\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.IndependentSteps import Pycromanager2NativeDataType, FFF2NativeDataType\n",
    "\n",
    "from src.SequentialSteps import BIGFISH_SpotDetection, SimpleCellposeSegmentaion, Calculate_BIGFISH_Threshold\n",
    "\n",
    "from src.FinalizationSteps import Save_Outputs, Save_Images, Save_Parameters, Save_Masks, return_to_NAS, remove_local_data_but_keep_h5\n",
    "\n",
    "from src.Parameters import Parameters, Experiment, Settings, ScopeClass, DataContainer\n",
    "\n",
    "from src.Displays import Display\n",
    "\n",
    "from src.GUI import GUI, StepGUI\n",
    "\n",
    "from src.Pipeline import Pipeline\n",
    "\n",
    "from src.GeneralStep import SequentialStepsClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you initialize the parameters\n",
    "scope = ScopeClass() \n",
    "data = DataContainer(clear_after_error=False) # you can also initialize these with parameters, but it is not necessary due to defaults\n",
    "settings = Settings(name='test') # you also must give a name for the analysis your are doing\n",
    "experiment = Experiment()\n",
    "\n",
    "SequentialStepsClass.order = 'parallel'\n",
    "\n",
    "experiment.initial_data_location = ['smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224']\n",
    "                                    # 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_10min_20220224']\n",
    "data.local_dataset_location = None # [r'C:\\Users\\formanj\\GitHub\\FISH_Processing\\Demos\\DUSP1_Dex_10min_20220224', r'C:\\Users\\formanj\\GitHub\\FISH_Processing\\Demos\\DUSP1_Dex_0min_20220224']\n",
    "experiment.FISHChannel = 0\n",
    "experiment.nucChannel = 2\n",
    "experiment.cytoChannel = 1\n",
    "experiment.voxel_size_z = 500\n",
    "\n",
    "settings.num_chunks_to_run = 1000 # this is the limit to how many chunks you want to run and it will stop after that\n",
    "settings.display_plots = False\n",
    "\n",
    "scope.spot_yx = 130\n",
    "scope.spot_z = 360\n",
    "scope.voxel_size_yx = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment:\n",
      "initial_data_location: ['smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224'] \n",
      "index_dict: None \n",
      "nucChannel: 2 \n",
      "cytoChannel: 1 \n",
      "FISHChannel: 0 \n",
      "voxel_size_z: 500 \n",
      "independent_params: None \n",
      "kwargs: None \n",
      "timestep_s: None \n",
      "\n",
      "Settings:\n",
      "name: test \n",
      "return_data_to_NAS: True \n",
      "NUMBER_OF_CORES: 4 \n",
      "save_files: True \n",
      "num_chunks_to_run: 1000 \n",
      "download_data_from_NAS: True \n",
      "connection_config_location: c:\\Users\\formanj\\GitHub\\AngelFISH\\config_nas.yml \n",
      "share_name: share \n",
      "display_plots: False \n",
      "load_in_mask: False \n",
      "mask_structure: {'masks': ('ptczyx', None, None), 'cell_mask': ('zyx', 'cytoChannel', 'masks'), 'nuc_mask': ('zyx', 'nucChannel', 'masks')} \n",
      "\n",
      "ScopeClass:\n",
      "voxel_size_yx: 100 \n",
      "spot_z: 360 \n",
      "spot_yx: 130 \n",
      "microscope_saving_format: pycromanager \n",
      "\n",
      "DataContainer:\n",
      "local_dataset_location: None \n",
      "h5_file: None \n",
      "total_num_chunks: None \n",
      "images: None \n",
      "masks: None \n",
      "temp: <TemporaryDirectory 'c:\\\\Users\\\\formanj\\\\GitHub\\\\AngelFISH\\\\dev\\\\tmp4e0j838k'> \n",
      "clear_after_error: False \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can see the parameters in each of these classes by printing them\n",
    "print(experiment)\n",
    "print(settings)\n",
    "print(scope)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'voxel_size_yx': 100,\n",
       " 'spot_z': 360,\n",
       " 'spot_yx': 130,\n",
       " 'microscope_saving_format': 'pycromanager',\n",
       " 'local_dataset_location': None,\n",
       " 'h5_file': None,\n",
       " 'total_num_chunks': None,\n",
       " 'images': None,\n",
       " 'masks': None,\n",
       " 'temp': <TemporaryDirectory 'c:\\\\Users\\\\formanj\\\\GitHub\\\\AngelFISH\\\\dev\\\\tmp4e0j838k'>,\n",
       " 'clear_after_error': False,\n",
       " 'name': 'test',\n",
       " 'return_data_to_NAS': True,\n",
       " 'NUMBER_OF_CORES': 4,\n",
       " 'save_files': True,\n",
       " 'num_chunks_to_run': 1000,\n",
       " 'download_data_from_NAS': True,\n",
       " 'connection_config_location': 'c:\\\\Users\\\\formanj\\\\GitHub\\\\AngelFISH\\\\config_nas.yml',\n",
       " 'share_name': 'share',\n",
       " 'display_plots': False,\n",
       " 'load_in_mask': False,\n",
       " 'mask_structure': {'masks': ('ptczyx', None, None),\n",
       "  'cell_mask': ('zyx', 'cytoChannel', 'masks'),\n",
       "  'nuc_mask': ('zyx', 'nucChannel', 'masks')},\n",
       " 'initial_data_location': ['smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224'],\n",
       " 'index_dict': None,\n",
       " 'nucChannel': 2,\n",
       " 'cytoChannel': 1,\n",
       " 'FISHChannel': 0,\n",
       " 'voxel_size_z': 500,\n",
       " 'independent_params': None,\n",
       " 'kwargs': None,\n",
       " 'timestep_s': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can get all of the parameters that you have initialized by calling get_parameters\n",
    "Parameters.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# You can check that all the manditory parameters are set by calling validate\n",
    "Parameters.validate()\n",
    "\n",
    "# this will give you two type of response, one if its a warning like this one below\n",
    "# this is just a warning because you may not have a cytoChannel,\n",
    "# but it is not manditory so the pipeline will still run\n",
    "# there are also errors that will stop the pipeline from running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting local_dataset_location in DataContainer\n",
      "Overwriting h5_file in DataContainer\n",
      "Overwriting total_num_chunks in DataContainer\n",
      "Overwriting independent_params in Experiment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'local_dataset_location': ['c:\\\\Users\\\\formanj\\\\GitHub\\\\AngelFISH\\\\dataBases\\\\DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'],\n",
       " 'h5_file': [<HDF5 file \"DUSP1_Dex_0min_20220224.h5\" (mode r)>],\n",
       " 'total_num_chunks': 30,\n",
       " 'images': dask.array<rechunk-merge, shape=(30, 1, 3, 27, 936, 640), dtype=float32, chunksize=(1, 1, 3, 27, 936, 640), chunktype=numpy.ndarray>,\n",
       " 'masks': dask.array<rechunk-merge, shape=(30, 1, 3, 27, 936, 640), dtype=int8, chunksize=(1, 1, 3, 27, 936, 640), chunktype=numpy.ndarray>,\n",
       " 'independent_params': {0: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  1: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  2: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  3: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  4: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  5: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  6: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  7: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  8: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  9: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  10: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  11: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  12: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  13: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  14: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  15: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  16: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  17: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  18: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  19: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  20: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  21: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  22: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  23: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  24: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  25: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  26: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  27: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  28: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'},\n",
       "  29: {'NAS_location': 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224\\\\DUSP1_Dex_0min_20220224.h5'}},\n",
       " 'position_indexs': array([30])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want this to load in the previous made masks\n",
    "settings.load_in_mask = False\n",
    "FFF2NativeDataType().run() # this will run the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you would like to remove the original data from disk\n",
    "remove_local_data_but_keep_h5().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:asyncio:Using selector: SelectSelector\n",
      "INFO:distributed.scheduler:State start\n",
      "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:57429\n",
      "INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:8787/status\n",
      "INFO:distributed.scheduler:Registering Worker plugin shuffle\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:57438'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:57446'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:57440'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:57444'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:57432'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:57442'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:57434'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:57436'\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:57465', name: 3, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:57465\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57472\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:57469', name: 0, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:57469\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57475\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:57466', name: 1, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:57466\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57479\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:57470', name: 7, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:57470\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57483\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:57467', name: 6, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:57467\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57482\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:57468', name: 5, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:57468\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57478\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:57473', name: 4, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:57473\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57487\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:57484', name: 2, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:57484\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57489\n",
      "INFO:distributed.scheduler:Receive client connection: Client-6f87abf4-d1dc-11ef-8fd0-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57490\n",
      "INFO:distributed.scheduler:Receive client connection: Client-worker-7a889d54-d1dc-11ef-8398-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57511\n",
      "INFO:distributed.scheduler:Receive client connection: Client-worker-7a9bdc6c-d1dc-11ef-8abc-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57512\n",
      "INFO:distributed.scheduler:Receive client connection: Client-worker-7acf970c-d1dc-11ef-8c3c-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57513\n",
      "INFO:distributed.scheduler:Receive client connection: Client-worker-7ae1d28e-d1dc-11ef-8f34-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57514\n",
      "INFO:distributed.scheduler:Receive client connection: Client-worker-7b09b391-d1dc-11ef-867c-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57515\n",
      "INFO:distributed.scheduler:Receive client connection: Client-worker-7b1755c8-d1dc-11ef-acf0-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57516\n",
      "INFO:distributed.scheduler:Receive client connection: Client-worker-7b187ec2-d1dc-11ef-8d34-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57517\n",
      "INFO:distributed.scheduler:Receive client connection: Client-worker-7b191330-d1dc-11ef-890c-b46921fe8fcf\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:57518\n"
     ]
    }
   ],
   "source": [
    "settings.cellpose_min_size = 500\n",
    "settings.cellpose_diameter = [180, 90]\n",
    "settings.cellpose_pretrained_model = [\"GAPDH_cyto\", 'DAPI_nuclei'] \n",
    "\n",
    "SimpleCellposeSegmentaion().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIGFISH_SpotDetection().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see the parameters in each of these classes by printing them\n",
    "print(experiment)\n",
    "print(settings)\n",
    "print(scope)\n",
    "print(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
