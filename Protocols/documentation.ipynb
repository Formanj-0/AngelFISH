{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11daa49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import logging\n",
    "import os\n",
    "sys.path.append('..')\n",
    "sys.path.append(os.path.join('..','..'))\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "logging.getLogger('napari').setLevel(logging.WARNING)\n",
    "logging.getLogger('in_n_out').setLevel(logging.WARNING)\n",
    "logging.getLogger('numcodecs').setLevel(logging.WARNING)\n",
    "logging.getLogger('numba').setLevel(logging.WARNING)\n",
    "\n",
    "from src import Receipt, load_data\n",
    "from src.Steps import (download_data, segment, detect_spots, get_cell_properties, \n",
    "                       return_data, match_masks, export_images, filter_csv, \n",
    "                       calculate_sharpness, reconcile_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a09971e",
   "metadata": {},
   "source": [
    "### Initialize Receipt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26e43fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "receipt = Receipt(\n",
    "    analysis_name = 'default_name',\n",
    "    nas_location = r'Users\\Jack\\_ImageDatasets\\IntronDiffusion\\08072025_TriptolideTimeSeries_JF001\\JF001_15min_5uM_3',\n",
    "    local_location = None,\n",
    "    data_loader = 'pycromanager_data_loader'\n",
    "    )\n",
    "\n",
    "## This is a formated dictionary that contains all the information on the \n",
    "# data to be processed and how to process it.\n",
    "# Primary keys of interest:\n",
    "#   meta_arguments - parameter relating to the data\n",
    "#   steps - parameters of each step\n",
    "#   step_order - order of the steps \n",
    "#   dirs - key directories \n",
    "\n",
    "# if nas_location is provided and local_location is not, a local location will be calculated in database dir\n",
    "# the data_loader decribes which format your data is in. We will treat the file structure of your data\n",
    "# as a data structures. 'pycromanager_data_loader' use the ndtiff and extends it so we can save result to the \n",
    "# directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25de5a2d",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fe19880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local file already exist\n"
     ]
    }
   ],
   "source": [
    "dd = download_data(receipt, 'download_data')\n",
    "receipt = dd.process()\n",
    "\n",
    "## This downloads the data from a nas with connections established in config_cluster.yml\n",
    "# It will download the data from the shared folder on the nas so\n",
    "# Z:\\Users\\Jack\\_ImageDatasets\\IntronDiffusion\\04102025_Triptolidetimeseries_JF001\\JF001_5min_5uM_1 becomes\n",
    "# Users\\Jack\\_ImageDatasets\\IntronDiffusion\\04102025_Triptolidetimeseries_JF001\\JF001_5min_5uM_1 because \n",
    "# the Z drive on my computer refers to the shared directory on the nas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dbf8a9",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "375a648e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset opened                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: QWindowsWindow::setGeometry: Unable to set geometry 3840x2018+640+284 (frame: 3862x2074+629+239) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY1\". Resulting geometry: 2564x1570+640+284 (frame: 2586x1626+629+239) margins: 11, 45, 11, 11 minimum size: 385x491 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=792,1038 maxtrack=0,0)\n",
      "WARNING:vispy:QWindowsWindow::setGeometry: Unable to set geometry 3840x2018+640+284 (frame: 3862x2074+629+239) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY1\". Resulting geometry: 2564x1570+640+284 (frame: 2586x1626+629+239) margins: 11, 45, 11, 11 minimum size: 385x491 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=792,1038 maxtrack=0,0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "running image processing\n",
      "0 0\n",
      "running image processing\n",
      "0 0\n",
      "running image processing\n",
      "0 0\n",
      "running image processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jack\\Documents\\GitHub\\AngelFISH\\.venv\\Lib\\site-packages\\cellpose\\resnet_torch.py:276: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(filename, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "running image processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jack\\Documents\\GitHub\\AngelFISH\\.venv\\Lib\\site-packages\\cellpose\\resnet_torch.py:276: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(filename, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up\n"
     ]
    }
   ],
   "source": [
    "nuc_seg = segment(receipt, 'segment_nuc')\n",
    "receipt = nuc_seg.gui()\n",
    "\n",
    "## Uses cellpose 4 to segment cells and displays them in a gui\n",
    "# pretrained_model_name: str = None - model name in models directory\n",
    "# diameter: float = 180 - size of cells\n",
    "# invert: bool = False - inverts image\n",
    "# normalize: bool = True - normalizes cells from precentiles\n",
    "# do_3D:bool=False, \n",
    "# min_size:float=500,\n",
    "# flow_threshold:float=0, \n",
    "# cellprob_threshold:float=0, \n",
    "\n",
    "# -> 'mask_name'.tif in results dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad738730",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_cyto_and_nuc = match_masks(receipt, 'match_cyto_and_nuc')\n",
    "receipt = match_cyto_and_nuc.process()\n",
    "\n",
    "## matches any cytoplasmic and nuclear masks to have the same labels\n",
    "# nuc_mask_name - name of nuc masks, 'nuc_masks' by default\n",
    "# cyto_mask_name - name of cyto masks, 'cyto_masks' by default\n",
    "# single_nuc - allows for lone nucleus, True by default\n",
    "# cell_alone - allows for cells without nucleus, False by default\n",
    "\n",
    "# -> rewrites masks in there tifs location on the drive using memmap(file_path, mode='r+')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707bfe31",
   "metadata": {},
   "source": [
    "### Detect Spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcb8156",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = detect_spots(receipt, 'detect_dusp1')\n",
    "receipt = ds.gui()\n",
    "\n",
    "## Uses big fish to detect spots \n",
    "# spot_name:str - name of the spots (i.e. dusp1)\n",
    "# image - czyx shaped image\n",
    "# FISHChannel: int - channel index with fish images\n",
    "# voxel_size_yx: float - calculated from metadata (nm)\n",
    "# voxel_size_z: float - calculated from metadata (nm)\n",
    "# spot_yx: float - spot size in xy (nm)\n",
    "# spot_z: float - spot size in z (nm)\n",
    "# timepoint:int - give by iteration\n",
    "# fov:int - given by iteration\n",
    "# nucChannel: int = None - nuc channel index\n",
    "# nuc_mask:np.array=None - zyx nuc mask from 'nuc_masks'\n",
    "# cell_mask:np.array=None - zyx cyto mask from 'cyto_masks'\n",
    "# threshold: Union[int, str] = None, \n",
    "# snr_threshold: float = None, \n",
    "# snr_ratio: float = None,\n",
    "# alpha: float = 0.7, \n",
    "# beta:float = 1, \n",
    "# gamma:float = 5, \n",
    "# cluster_radius:int = 500, \n",
    "# min_num_spot_per_cluster:int = 4, \n",
    "# use_log_hook:bool = False, \n",
    "# verbose:bool = False, \n",
    "# display_plots: bool = False, \n",
    "# use_pca: bool = False,\n",
    "# sub_pixel_fitting: bool = False, \n",
    "# minDistance:Union[float, list] = None,\n",
    "\n",
    "# -> save 'spot_name'_cellresults.csv, 'spot_name'_spotresults.csv, 'spot_name'_clusterresulsts.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b6068",
   "metadata": {},
   "outputs": [],
   "source": [
    "receipt = reconcile_data(receipt, 'reconcile_spots')\n",
    "\n",
    "## Recalculates cell results\n",
    "# cell_key:str - cell props key\n",
    "# spot_key:str - spot props key\n",
    "\n",
    "# -> cellresults_reconciled_data.csv which will have all the cell props and RNA counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04489052",
   "metadata": {},
   "source": [
    "### Get Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2107948",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_cell_props = get_cell_properties(receipt, 'measure_cell_props')\n",
    "receipt = measure_cell_props.process()\n",
    "\n",
    "\n",
    "## Calculates cell props \n",
    "# image, \n",
    "# cell_mask=None, \n",
    "# nuc_mask=None, \n",
    "# middle_zs:int = None - trims to middle 3 zs # TODO make this based on focal plane\n",
    "# props_to_measure= ['label', 'bbox', 'area', 'centroid', 'intensity_max', 'intensity_mean', 'intensity_min', 'intensity_std']\n",
    "\n",
    "# -> cellproperties.csv with measurements made for every channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7656eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = calculate_sharpness(receipt, 'calc_sharpness')\n",
    "receipt = cs.process({\n",
    "    'channel': 0\n",
    "})\n",
    "\n",
    "\n",
    "## calculates the sharpness of every z in dataset\n",
    "# zyx_image: np.array,\n",
    "# sharpness_metric: Union[list,str]=None\n",
    "\n",
    "# -> sharpnesses.json - dict of format [p][t][z][metric]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292757cd",
   "metadata": {},
   "source": [
    "### Manipulate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1300aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "receipt = return_data(receipt, 'return_data').process()\n",
    "\n",
    "## returns data to nas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ffdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = filter_csv(receipt, 'filter_csv')\n",
    "receipt = fc.gui()\n",
    "\n",
    "## Filters csv based on set filters\n",
    "# csv_to_filter - name of data to filter\n",
    "# columns_to_filter_on - list of column names to filter on \n",
    "# values_to_filter_on - list of (min value, max value) to filter data on\n",
    "\n",
    "# -> f'{csv_to_filter}_filtered.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95e1367",
   "metadata": {},
   "outputs": [],
   "source": [
    "receipt = export_images(receipt, 'export_tifs')\n",
    "\n",
    "# Export images into different formats\n",
    "# channel_order - channel order\n",
    "# export_format - file format to export as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a5b1b7",
   "metadata": {},
   "source": [
    "### Receipt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40eca501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta Arguments: \n",
      "\n",
      "    \"nas_location\": \"Users\\\\Jack\\\\_ImageDatasets\\\\IntronDiffusion\\\\08072025_TriptolideTimeSeries_JF001\\\\JF001_15min_5uM_3\",\n",
      "    \"local_location\": \"c:\\\\Users\\\\Jack\\\\Documents\\\\GitHub\\\\AngelFISH\\\\database\\\\JF001_15min_5uM_3\",\n",
      "    \"data_loader\": \"pycromanager_data_loader\",\n",
      "    \"analysis_name\": \"default_name\"\n",
      "\n",
      "Step Order: \n",
      "\t1) download_data\n",
      "\t2) segment_nuc\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print('Meta Arguments: ')\n",
    "meta_args_str = json.dumps(receipt['meta_arguments'], indent=4)\n",
    "print(meta_args_str[1:-1])\n",
    "\n",
    "print('Step Order: ')\n",
    "for i, step in enumerate(receipt['step_order'], 1):\n",
    "    print(f\"\\t{i}) {step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "receipt.save('new_pipeline.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ba467e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_last_step(receipt):\n",
    "    last_step_name = receipt['step_order'].pop()\n",
    "    del receipt['steps'][last_step_name]\n",
    "    return receipt\n",
    "\n",
    "receipt = remove_last_step(receipt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91216765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
