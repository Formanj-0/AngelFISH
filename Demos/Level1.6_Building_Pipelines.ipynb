{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    # Get the number of GPUs available\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "\n",
    "    # Get the name of each GPU\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "\n",
    "    # Get the current GPU memory usage\n",
    "    for i in range(num_gpus):\n",
    "        gpu_memory_allocated = torch.cuda.memory_allocated(i)\n",
    "        gpu_memory_reserved = torch.cuda.memory_reserved(i)\n",
    "        print(f\"GPU {i} memory allocated: {gpu_memory_allocated / (1024 ** 3):.2f} GB\")\n",
    "        print(f\"GPU {i} memory reserved: {gpu_memory_reserved / (1024 ** 3):.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import numba\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)\n",
    "\n",
    "matplotlib_logger = logging.getLogger('matplotlib')\n",
    "matplotlib_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Add the src directory to sys.path\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.IndependentSteps import Pycromanager2NativeDataType, FFF2NativeDataType, Make_Output_Dir_JF, Make_Analysis_Dir_JF, \\\n",
    "                                    ConsolidateImageShapes, TrimZSlices, AutomaticSpotDetection_JF\n",
    "\n",
    "from src.SequentialSteps import CellSegmentationStepClass_JF, BIGFISH_SpotDetection, SimpleCellposeSegmentaion\n",
    "\n",
    "from src.FinalizationSteps import Save_Outputs, Save_Images, Save_Parameters, Save_Masks, return_to_NAS\n",
    "\n",
    "from src.Parameters import Parameters, Experiment, Settings, ScopeClass, DataContainer\n",
    "\n",
    "from src.GeneralOutput import OutputClass\n",
    "\n",
    "from src.Displays import Display\n",
    "\n",
    "from src.GUI import GUI, StepGUI\n",
    "\n",
    "from src.Pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Parameters\n",
    "scope = ScopeClass() \n",
    "data = DataContainer() # you can also initialize these with parameters, but it is not necessary due to defaults\n",
    "settings = Settings(name='demo') # you also must give a name for the analysis your are doing\n",
    "experiment = Experiment()\n",
    "\n",
    "settings.load_in_mask = True\n",
    "\n",
    "settings.cellpose_min_size = 500\n",
    "settings.cellpose_diameter = [180, 90] # most of these options can be done for individually cyto and nuc segmentation, \n",
    "                                        # and a list can be or a single float can be passed for both\n",
    "                                        # always in the order cyto, nuc\n",
    "settings.cellpose_pretrained_model = [r\"C:\\Users\\Jack\\Documents\\GitHub\\FISH_Processing\\models\\GAPDH_cyto\", r'C:\\Users\\Jack\\Documents\\GitHub\\FISH_Processing\\models\\DAPI_nuclei'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check that all the manditory parameters are set by calling validate\n",
    "Parameters.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF2NativeDataType()\n",
    "SimpleCellposeSegmentaion()\n",
    "BIGFISH_SpotDetection()\n",
    "Save_Masks()\n",
    "Save_Parameters()\n",
    "Save_Outputs()\n",
    "return_to_NAS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.save_pipeline(name='demo')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
