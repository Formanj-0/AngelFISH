{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check torck is installed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    # Get the number of GPUs available\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "\n",
    "    # Get the name of each GPU\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "\n",
    "    # Get the current GPU memory usage\n",
    "    for i in range(num_gpus):\n",
    "        gpu_memory_allocated = torch.cuda.memory_allocated(i)\n",
    "        gpu_memory_reserved = torch.cuda.memory_reserved(i)\n",
    "        print(f\"GPU {i} memory allocated: {gpu_memory_allocated / (1024 ** 3):.2f} GB\")\n",
    "        print(f\"GPU {i} memory reserved: {gpu_memory_reserved / (1024 ** 3):.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import numba\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)\n",
    "\n",
    "matplotlib_logger = logging.getLogger('matplotlib')\n",
    "matplotlib_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Add the src directory to sys.path\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.IndependentSteps import Pycromanager2NativeDataType, FFF2NativeDataType\n",
    "\n",
    "from src.SequentialSteps import BIGFISH_SpotDetection, SimpleCellposeSegmentaion\n",
    "\n",
    "from src.FinalizationSteps import Save_Outputs, Save_Images, Save_Parameters, Save_Masks, return_to_NAS, remove_local_data_but_keep_h5, \\\n",
    "                                    remove_all_temp, remove_temp\n",
    "\n",
    "from src.Parameters import Parameters, Experiment, Settings, ScopeClass, DataContainer\n",
    "\n",
    "from src.Displays import Display\n",
    "\n",
    "from src.GUI import GUI, StepGUI\n",
    "\n",
    "from src.Pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These need to be initialized every time\n",
    "These classes can only be initialized once, all future  \n",
    "All future initializations will return these classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These classes are used to isolate the source of the parameter\n",
    "scope = ScopeClass() # these come from the microscope\n",
    "data = DataContainer() # these hold the data as it is being generated\n",
    "                        # it employ a temp file that is used to keep data out of \n",
    "                        # memory, This trys and grabs all sources of large memory\n",
    "                        # memory variables and saves them\n",
    "settings = Settings(name='PUT_YOUR_PIPELINENAME_HERE') # this is how you alter the \n",
    "                                                        # the settings of the pipeline,\n",
    "                                                        # it is also the overflow\n",
    "experiment = Experiment() # This data is specific to the experiment that you are doing.\n",
    "                          # In theory this along with the scope class are the physical\n",
    "                          # experiment parts need to run all image processing on that \n",
    "                          # data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example\n",
    "Display some attribute of the settings object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Settings().name) # this will show your name\n",
    "# this is equivelent print(settings.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alter some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.initial_data_location = ['smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224']\n",
    "                                    # 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_10min_20220224']\n",
    "# this data is of the experiment class because it is the initial saving location of the\n",
    "# data. once it is local in the DataContainer. This intial data location will be overwriten\n",
    "# with whatever you send back, so only add what you think is useful\n",
    "# you can also trim older datasets this way. It can be a list[str] or str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these properties are classic important paramters for the types of analysis this is\n",
    "# built for. Primarily ICC, FISH, and live cells single molecule experiments. \n",
    "# diffusion are future used\n",
    "experiment.FISHChannel = 0\n",
    "experiment.nucChannel = 2\n",
    "experiment.cytoChannel = 1\n",
    "experiment.voxel_size_z = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this specifies the number of chunck should be passed through the sequential steps.\n",
    "# sequential steps, mean the step is taking in a single set of p, t pairs in a specified order\n",
    "# p then t or t then p\n",
    "# and all results from this will be concatinated (vetically if df)\n",
    "settings.num_chunks_to_run = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classic propeties of the microscope itself. \n",
    "# please take note that the z step is in the experiment object\n",
    "scope.spot_yx = 130\n",
    "scope.spot_z = 360\n",
    "scope.voxel_size_yx = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  You can get all the parameter objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameters._instances \n",
    "# returns a list of all of the scope, data, settings, experiment objects "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can also get a dictionary of them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can get all of the parameters that you have initialized by calling get_parameters\n",
    "Parameters.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check that all the manditory parameters are set by calling validate\n",
    "Parameters.validate()\n",
    "\n",
    "# this will give you two type of response, one if its a warning like this one below\n",
    "# this is just a warning because you may not have a cytoChannel,\n",
    "# but it is not manditory so the pipeline will still run\n",
    "# there are also errors that will stop the pipeline from running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next lets import some data from the NAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want this to load in the previous made masks\n",
    "settings.load_in_mask = True\n",
    "FFF2NativeDataType().run() # this will run the step\n",
    "\n",
    "# current assumptions about your databridges:\n",
    "# it exist in a folder, this can have many things in it.\n",
    "# this function looks at the folder, and loads it. It \n",
    "# will mostly populate the datacontainer, and possibly parameters.\n",
    "\n",
    "# if a import is large consider make sure it ends up \n",
    "# in the data container\n",
    "# all this data should be converted to h5 format for future ease of use,\n",
    "# and for saving of results, original will remain unaltered. Aside from new h5 \n",
    "# file inside\n",
    "\n",
    "# NativeDataType().run() should be used if already meet this criteria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear up unneeded space on the disk\n",
    "remove_local_data_but_keep_h5().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets look at what we got "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Display().displayImage_maxProject(0, 0, 0) # Display is a class of common plots, it interacts with the paramters to display data\n",
    "                                            # specifically for the user, not really used further in the pipeline.\n",
    "\n",
    "# future plots created by steps should be able to be turned off by display_plots in Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets try tuning some steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with segmentation. ( this is a sequential step)\n",
    "# these steps are built with ther own logic in mind so read the doc string to see all the options\n",
    "# this class assume that if you are running it you want to overide the previous masks\n",
    "# there are also several other options that you can set by adding them to the settings object\n",
    "# if you want to alter any propety of the step, make it an input to the step, then pass what you want it to be into \n",
    "# settings and your good to go. Save any outputs of the step as a dictionary, and it will be save properly. \n",
    "settings.cellpose_min_size = 500\n",
    "settings.cellpose_diameter = [180, 90] # most of these options can be done for individually cyto and nuc segmentation, \n",
    "                                        # and a list can be or a single float can be passed for both\n",
    "                                        # always in the order cyto, nuc\n",
    "settings.cellpose_pretrained_model = [\"GAPDH_cyto\", 'DAPI_nuclei'] \n",
    "\n",
    "SimpleCellposeSegmentaion().run(p=None, t=None) # You can select \n",
    "\n",
    "# this code will overwrite the previous masks and a warning will be given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (This is also a sequential step, we will explain there exact difference later)\n",
    "# We already specified the parameters we wanted earlier, and the results of the segmentation were added to the data container.\n",
    "# now were going to do spot detection using the data from above\n",
    "\n",
    "# examples of settings to change for big fish are:\n",
    "# scope.spot_yx = 130\n",
    "# scope.spot_z = 360\n",
    "# ...\n",
    "BIGFISH_SpotDetection().run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
