{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs available: 2\n",
      "GPU 0: NVIDIA GeForce RTX 2070\n",
      "GPU 1: NVIDIA GeForce RTX 2070\n",
      "GPU 0 memory allocated: 0.00 GB\n",
      "GPU 0 memory reserved: 0.00 GB\n",
      "GPU 1 memory allocated: 0.00 GB\n",
      "GPU 1 memory reserved: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    # Get the number of GPUs available\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "\n",
    "    # Get the name of each GPU\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "\n",
    "    # Get the current GPU memory usage\n",
    "    for i in range(num_gpus):\n",
    "        gpu_memory_allocated = torch.cuda.memory_allocated(i)\n",
    "        gpu_memory_reserved = torch.cuda.memory_reserved(i)\n",
    "        print(f\"GPU {i} memory allocated: {gpu_memory_allocated / (1024 ** 3):.2f} GB\")\n",
    "        print(f\"GPU {i} memory reserved: {gpu_memory_reserved / (1024 ** 3):.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 16 threads.\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import numba\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)\n",
    "\n",
    "matplotlib_logger = logging.getLogger('matplotlib')\n",
    "matplotlib_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Add the src directory to sys.path\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.IndependentSteps import Pycromanager2NativeDataType, FFF2NativeDataType, Make_Output_Dir_JF, Make_Analysis_Dir_JF, \\\n",
    "                                    ConsolidateImageShapes, TrimZSlices, AutomaticSpotDetection_JF\n",
    "\n",
    "from src.SequentialSteps import CellSegmentationStepClass_JF, BIGFISH_SpotDetection, SimpleCellposeSegmentaion\n",
    "\n",
    "from src.FinalizationSteps import Save_Outputs, Save_Images, Save_Parameters, Save_Masks, return_to_NAS\n",
    "\n",
    "from src.Parameters import Parameters, Experiment, Settings, ScopeClass, DataContainer\n",
    "\n",
    "from src.GeneralOutput import OutputClass\n",
    "\n",
    "from src.Displays import Display\n",
    "\n",
    "from src.GUI import GUI, StepGUI\n",
    "\n",
    "from src.Pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Parameters\n",
    "scope = ScopeClass() \n",
    "data = DataContainer() # you can also initialize these with parameters, but it is not necessary due to defaults\n",
    "settings = Settings(name='demo', connection_config_location=None) # you also must give a name for the analysis your are doing\n",
    "experiment = Experiment(initial_data_location=r'smFISH_images\\Eric_smFISH_images\\20230511\\DUSP1_DexTimeConcSweep_10nM_75min_041223')\n",
    "\n",
    "settings.load_in_mask = True\n",
    "experiment.FISHChannel = 0\n",
    "experiment.nucChannel = 2\n",
    "experiment.voxel_size_z = 500\n",
    "\n",
    "settings.cellpose_min_size = 500\n",
    "settings.cellpose_diameter = [180, 90] # most of these options can be done for individually cyto and nuc segmentation, \n",
    "                                        # and a list can be or a single float can be passed for both\n",
    "                                        # always in the order cyto, nuc\n",
    "settings.cellpose_pretrained_model = [r\"GAPDH_cyto\", r'DAPI_nuclei'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "cytoChannel not set\n"
     ]
    }
   ],
   "source": [
    "# You can check that all the manditory parameters are set by calling validate\n",
    "Parameters.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.FinalizationSteps.Moving_Data.return_to_NAS at 0x199eb816840>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FFF2NativeDataType()\n",
    "SimpleCellposeSegmentaion()\n",
    "BIGFISH_SpotDetection()\n",
    "Save_Masks()\n",
    "Save_Parameters()\n",
    "Save_Outputs()\n",
    "return_to_NAS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:paramiko.transport:starting thread (client mode): 0x2f9fbf0\n",
      "DEBUG:paramiko.transport:Local version/idstring: SSH-2.0-paramiko_3.5.0\n",
      "DEBUG:paramiko.transport:Remote version/idstring: SSH-2.0-OpenSSH_8.0\n",
      "INFO:paramiko.transport:Connected (version 2.0, client OpenSSH_8.0)\n",
      "DEBUG:paramiko.transport:=== Key exchange possibilities ===\n",
      "DEBUG:paramiko.transport:kex algos: curve25519-sha256, curve25519-sha256@libssh.org, ecdh-sha2-nistp256, ecdh-sha2-nistp384, ecdh-sha2-nistp521, diffie-hellman-group-exchange-sha256, diffie-hellman-group14-sha256, diffie-hellman-group16-sha512, diffie-hellman-group18-sha512, diffie-hellman-group-exchange-sha1, diffie-hellman-group14-sha1\n",
      "DEBUG:paramiko.transport:server key: rsa-sha2-512, rsa-sha2-256, ssh-rsa, ecdsa-sha2-nistp256, ssh-ed25519\n",
      "DEBUG:paramiko.transport:client encrypt: aes256-gcm@openssh.com, chacha20-poly1305@openssh.com, aes256-ctr, aes256-cbc, aes128-gcm@openssh.com, aes128-ctr, aes128-cbc\n",
      "DEBUG:paramiko.transport:server encrypt: aes256-gcm@openssh.com, chacha20-poly1305@openssh.com, aes256-ctr, aes256-cbc, aes128-gcm@openssh.com, aes128-ctr, aes128-cbc\n",
      "DEBUG:paramiko.transport:client mac: hmac-sha2-256-etm@openssh.com, hmac-sha1-etm@openssh.com, umac-128-etm@openssh.com, hmac-sha2-512-etm@openssh.com, hmac-sha2-256, hmac-sha1, umac-128@openssh.com, hmac-sha2-512\n",
      "DEBUG:paramiko.transport:server mac: hmac-sha2-256-etm@openssh.com, hmac-sha1-etm@openssh.com, umac-128-etm@openssh.com, hmac-sha2-512-etm@openssh.com, hmac-sha2-256, hmac-sha1, umac-128@openssh.com, hmac-sha2-512\n",
      "DEBUG:paramiko.transport:client compress: none, zlib@openssh.com\n",
      "DEBUG:paramiko.transport:server compress: none, zlib@openssh.com\n",
      "DEBUG:paramiko.transport:client lang: <none>\n",
      "DEBUG:paramiko.transport:server lang: <none>\n",
      "DEBUG:paramiko.transport:kex follows: False\n",
      "DEBUG:paramiko.transport:=== Key exchange agreements ===\n",
      "DEBUG:paramiko.transport:Kex: curve25519-sha256@libssh.org\n",
      "DEBUG:paramiko.transport:HostKey: ssh-ed25519\n",
      "DEBUG:paramiko.transport:Cipher: aes128-ctr\n",
      "DEBUG:paramiko.transport:MAC: hmac-sha2-256\n",
      "DEBUG:paramiko.transport:Compression: none\n",
      "DEBUG:paramiko.transport:=== End of kex handshake ===\n",
      "DEBUG:paramiko.transport:kex engine KexCurve25519 specified hash_algo <built-in function openssl_sha256>\n",
      "DEBUG:paramiko.transport:Switch to new keys ...\n",
      "DEBUG:paramiko.transport:Adding ssh-ed25519 host key for keck.engr.colostate.edu: b'38926ebfa15334d940b5b39187c964b8'\n",
      "DEBUG:paramiko.transport:Got EXT_INFO: {'server-sig-algs': b'ssh-ed25519,ssh-rsa,rsa-sha2-256,rsa-sha2-512,ssh-dss,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521'}\n",
      "DEBUG:paramiko.transport:userauth is OK\n",
      "INFO:paramiko.transport:Authentication (password) successful!\n",
      "DEBUG:paramiko.transport:[chan 0] Max packet in: 32768 bytes\n",
      "DEBUG:paramiko.transport:Received global request \"hostkeys-00@openssh.com\"\n",
      "DEBUG:paramiko.transport:Rejecting \"hostkeys-00@openssh.com\" global request from server.\n",
      "DEBUG:paramiko.transport:[chan 0] Max packet out: 32768 bytes\n",
      "DEBUG:paramiko.transport:Secsh channel 0 opened.\n",
      "DEBUG:paramiko.transport:[chan 0] Sesch channel 0 request ok\n",
      "INFO:paramiko.transport.sftp:[chan 0] Opened sftp connection (server version 3)\n",
      "DEBUG:paramiko.transport.sftp:[chan 0] open(b'/home/formanj/Github/FISH_Processing/cluster/Demo.txt', 'wb')\n",
      "DEBUG:paramiko.transport.sftp:[chan 0] open(b'/home/formanj/Github/FISH_Processing/cluster/Demo.txt', 'wb') -> 00000000\n",
      "DEBUG:paramiko.transport.sftp:[chan 0] close(00000000)\n",
      "DEBUG:paramiko.transport.sftp:[chan 0] stat(b'/home/formanj/Github/FISH_Processing/cluster/Demo.txt')\n",
      "INFO:paramiko.transport.sftp:[chan 0] sftp session closed.\n",
      "DEBUG:paramiko.transport:[chan 0] EOF sent (0)\n",
      "DEBUG:paramiko.transport:[chan 1] Max packet in: 32768 bytes\n",
      "DEBUG:paramiko.transport:[chan 0] EOF received (0)\n",
      "DEBUG:paramiko.transport:[chan 1] Max packet out: 32768 bytes\n",
      "DEBUG:paramiko.transport:Secsh channel 1 opened.\n",
      "DEBUG:paramiko.transport:[chan 1] Sesch channel 1 request ok\n",
      "DEBUG:paramiko.transport:[chan 1] EOF received (1)\n",
      "DEBUG:paramiko.transport:[chan 1] EOF sent (1)\n",
      "DEBUG:paramiko.transport:Dropping user packet because connection is dead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 22566\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline.run_on_cluster('/home/formanj/Github/FISH_Processing/cluster', name='Demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
