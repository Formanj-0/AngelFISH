{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    # Get the number of GPUs available\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "\n",
    "    # Get the name of each GPU\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "\n",
    "    # Get the current GPU memory usage\n",
    "    for i in range(num_gpus):\n",
    "        gpu_memory_allocated = torch.cuda.memory_allocated(i)\n",
    "        gpu_memory_reserved = torch.cuda.memory_reserved(i)\n",
    "        print(f\"GPU {i} memory allocated: {gpu_memory_allocated / (1024 ** 3):.2f} GB\")\n",
    "        print(f\"GPU {i} memory reserved: {gpu_memory_reserved / (1024 ** 3):.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import numba\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)\n",
    "\n",
    "matplotlib_logger = logging.getLogger('matplotlib')\n",
    "matplotlib_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Add the src directory to sys.path\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.IndependentSteps import Pycromanager2H5, FFF2H5\n",
    "\n",
    "from src.SequentialSteps import BIGFISH_SpotDetection, SimpleCellposeSegmentaion\n",
    "\n",
    "from src.FinalizationSteps import Save_Outputs, Save_Images, Save_Parameters, Save_Masks, return_to_NAS, remove_local_data_but_keep_h5, \\\n",
    "                                    remove_all_temp, remove_temp\n",
    "\n",
    "from src.Parameters import Parameters, Experiment, Settings, ScopeClass, DataContainer\n",
    "\n",
    "from src.Displays import Display\n",
    "\n",
    "from src.GUI import GUI, StepGUI\n",
    "\n",
    "from src.Pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal:  \n",
    "This is to introduce you to the fundamentals of this package.  \n",
    "  \n",
    "The main concepts we will go over is:  \n",
    "How to change parameters  \n",
    "How to load in data  \n",
    "How to run image processing steps on this data  \n",
    "How to save this data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:  \n",
    "One of the fundamental classes in this package is the Parameters class.  \n",
    "This class is designed to hold all of the parameters that you can wish to use.  \n",
    "Parameters are generated at different points through a datasets lifespane.  \n",
    "For instance some parameters are generated by the microscope (e.g., voxel size)  \n",
    "or by the experiment, (e.g., spots size due to the particle that you are measuring has its own unique size)  \n",
    "  \n",
    "In order to fascilate the creation of parameters multiple children classes to the parameter class have been made.  \n",
    "These classes are singletons so only one of each can exist at any point. This removes the issue of accidently trying to  \n",
    "create multiple of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you initialize the parameters\n",
    "scope = ScopeClass() \n",
    "data = DataContainer() # you can also initialize these with parameters, but it is not necessary due to defaults\n",
    "settings = Settings(name='demo') # you also must give a name for the analysis your are doing\n",
    "experiment = Experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see the parameters in each of these classes by printing them\n",
    "print(experiment)\n",
    "print(settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can see all the parameters in the pipeline by printing the parameters object\n",
    "Parameters._instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can get all of the parameters that you have initialized by calling get_parameters\n",
    "Parameters().get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can change the parameters\n",
    "experiment.initial_data_location = ['smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_0min_20220224']\n",
    "                                    # 'smFISH_images/Eric_smFISH_images/20220225/DUSP1_Dex_10min_20220224']\n",
    "\n",
    "data.local_dataset_location = None\n",
    "experiment.FISHChannel = 0\n",
    "experiment.nucChannel = 2\n",
    "experiment.cytoChannel = 1\n",
    "experiment.voxel_size_z = 500\n",
    "\n",
    "settings.num_chunks_to_run = 1 # this is the limit to how many chunks you want to run and it will stop after that\n",
    "\n",
    "scope.spot_yx = 130\n",
    "scope.spot_z = 360\n",
    "scope.voxel_size_yx = 100\n",
    "\n",
    "Parameters().get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check that all the manditory parameters are set by calling validate\n",
    "Parameters.validate()\n",
    "\n",
    "# this will give you two type of response, one if its a warning like this one below\n",
    "# this is just a warning because you may not have a cytoChannel,\n",
    "# but it is not manditory so the pipeline will still run\n",
    "# there are also errors that will stop the pipeline from running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next fundamental class is the step class.  \n",
    "These are intellegentlty written wrappers for a image processing step.  \n",
    "Alone they are nothing unique because they just duplicate already made functialility.  \n",
    "However, they are used to generate standardized outputs that can feed into other steps.  \n",
    "For instance spot detection is a ongoing field of research and new ones are being made.  \n",
    "So being able to substitute in new spot detection algorithems and have them integrate directly into  \n",
    "trackpy is a useful feature, and is what this package aims to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First you will need to import your data\n",
    "# This will require you to have a data bridge that will convert\n",
    "# the data from your microscope to a format that the pipeline can use\n",
    "# This is done by creating a class that inherits from the DataBridge class\n",
    "\n",
    "# Here is one that I have made for eric's data\n",
    "# FFF2H5().run()\n",
    "\n",
    "# These are made intelligently so that it will only convert your data if it cannot find it.\n",
    "# and will only download it if it cannot find it on the local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will load in your data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want this to load in the previous made masks\n",
    "settings.load_in_mask = True\n",
    "FFF2H5().run() # this will run the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will load in your data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you would like to remove the original data from disk\n",
    "remove_local_data_but_keep_h5().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Display().displayImage_maxProject(0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display().displayMask(channel=2, position=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let run some Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with segmentation. \n",
    "# these steps are built with ther own logic in mind so read the doc string to see all the options\n",
    "# this class assume that if you are running it you want to overide the previous masks\n",
    "# there are also several other options that you can set by adding them to the settings object\n",
    "settings.cellpose_min_size = 500\n",
    "settings.cellpose_diameter = [180, 90] # most of these options can be done for individually cyto and nuc segmentation, \n",
    "                                        # and a list can be or a single float can be passed for both\n",
    "                                        # always in the order cyto, nuc\n",
    "settings.cellpose_pretrained_model = [\"GAPDH_cyto\", 'DAPI_nuclei'] \n",
    "\n",
    "SimpleCellposeSegmentaion().run() # this will run the step\n",
    "\n",
    "# this code will overwrite the previous masks and a warning will be given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do spot detection\n",
    "BIGFISH_SpotDetection().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the generated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Masks\n",
    "# this has to be a dedicated step because overwriting the masks is a big deal\n",
    "# this needs to be ran first before h5_file are closed\n",
    "Save_Masks().run()\n",
    "\n",
    "# IF YOU EVER GET A ERROR CODE WINERROR 33, YOU PROBABLY HAVE THE H5 FILE OPEN IN ANOTHER PROGRAM.\n",
    "# I.E., YOU HAVE ANOTHER FILE OPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will save the data to the H5 file that is the standard data format\n",
    "# It will save them to the Analysis group with the name of the analysis and todays data\n",
    "Save_Outputs().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parameters\n",
    "Save_Parameters().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images\n",
    "# this is not recommended to do unless you want to save the images that you have processed\n",
    "# this will be save to the analysis group in the H5 file and will not overwrite the raw images\n",
    "# Save_Images().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send back to NAS\n",
    "return_to_NAS().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_all_temp().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear outputs\n",
    "\n",
    "Parameters().clear_instances()\n",
    "print(Parameters().get_parameters())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we have to set up our parameters\n",
    "scope = ScopeClass(spot_yx = 130, \n",
    "    spot_z = 360, \n",
    "    voxel_size_yx = 100\n",
    ") \n",
    "data = DataContainer()\n",
    "settings = Settings(\n",
    "    name='demo',\n",
    "    num_chunks_to_run = 1\n",
    ")\n",
    "experiment = Experiment(\n",
    "    initial_data_location = r'smFISH_images\\Eric_smFISH_images\\20230511\\DUSP1_DexTimeConcSweep_10nM_75min_041223',\n",
    "    FISHChannel = 0,\n",
    "    cytoChannel= 0,\n",
    "    nucChannel = 2,\n",
    "    voxel_size_z = 500\n",
    ")\n",
    "# we can add additional parameters\n",
    "settings.cellpose_min_size = 500\n",
    "settings.cellpose_diameter = [180, 90] # most of these options can be done for individually cyto and nuc segmentation, \n",
    "                                        # and a list can be or a single float can be passed for both\n",
    "                                        # always in the order cyto, nuc\n",
    "settings.cellpose_pretrained_model = [r\"C:\\Users\\Jack\\Documents\\GitHub\\FISH_Processing\\models\\GAPDH_cyto\", r'C:\\Users\\Jack\\Documents\\GitHub\\FISH_Processing\\models\\DAPI_nuclei'] \n",
    "\n",
    "# we can also check the parameters and make sure they will work\n",
    "Parameters.validate()\n",
    "\n",
    "# these parameter will find there way into the steps we wish to run\n",
    "FFF2H5().run()\n",
    "SimpleCellposeSegmentaion().run()\n",
    "BIGFISH_SpotDetection().run()\n",
    "\n",
    "# Save ( you would normally want to run this but it will duplicate data if you do it all at once i.e., hitting run all)\n",
    "# Save_Masks().run() \n",
    "# Save_Outputs().run()\n",
    "# Save_Parameters().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_all_temp().run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
