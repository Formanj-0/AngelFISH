{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8882958d",
   "metadata": {},
   "source": [
    "## DUSP1 smiFISH Classification Workflow\n",
    "\n",
    "This notebook processes experimental data from BigFish and CellProperties CSV files to classify DUSP1 smiFISH spots. Below is an outline of the workflow:\n",
    "\n",
    "### Input:\n",
    "- BigFish CSV files\n",
    "- CellProperties CSV files\n",
    "\n",
    "### Workflow Steps:\n",
    "1. **Merge Experimental Data**  \n",
    "    Combine data from the input CSV files for unified analysis.\n",
    "\n",
    "2. **Signal-to-Noise Ratio (SNR) Analysis**  \n",
    "    Perform SNR analysis to classify and filter spots based on signal quality.\n",
    "\n",
    "3. **Measurement Analysis**  \n",
    "    Conduct measurement analysis to extract relevant features from the data.\n",
    "\n",
    "4. **Data Merging**  \n",
    "    Merge all processed data into a single dataset for further analysis.\n",
    "\n",
    "5. **Create Training Spot Crops (11px x 11px)**  \n",
    "    Generate training data for machine learning models:\n",
    "    - Select 1000 spots from each `h5_idx`, ensuring variation across cells and fields of view (FOVs).\n",
    "    - Use the DUSP1 Display Manager to safely load spot channel images.\n",
    "    - Perform max projection of images along the z-axis to create 2D (x, y) representations.\n",
    "    - Extract 11px x 11px crops centered on each spot.\n",
    "    - Rescale intensity for visualization purposes.\n",
    "    - Display 100 sample spot crops for quality inspection before saving all crops to a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "# Today's date\n",
    "today = datetime.date.today()\n",
    "# Format date as 'Mar21' (for example)\n",
    "date_str = today.strftime(\"%b%d\")\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)\n",
    "\n",
    "matplotlib_logger = logging.getLogger('matplotlib')\n",
    "matplotlib_logger.setLevel(logging.WARNING)\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "print(src_path)\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.Analysis_DUSP1_v2 import DUSP1AnalysisManager, SNRAnalysis, DUSP1Measurement, DUSP1DisplayManager, SpotCropSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33388bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = None\n",
    "log_location = r'/Volumes/share/Users/Eric/GR_DUSP1_reruns'\n",
    "save_dir = r'/Volumes/share/Users/Eric/DUSP1_SpotCrops'\n",
    "\n",
    "# Define Thresholds\n",
    "abs_threshold = 4\n",
    "mg_threshold = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a88c7",
   "metadata": {},
   "source": [
    "    # DUSP1 Replica D 3hr 100nM time-sweep R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a84491",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = DUSP1AnalysisManager(location=loc, log_location=log_location, mac=True) \n",
    "am.select_analysis('DUSP1_D_Final')\n",
    "\n",
    "spots_df = am.select_datasets(\"spotresults\", dtype=\"dataframe\")\n",
    "clusters_df = am.select_datasets(\"clusterresults\", dtype=\"dataframe\")\n",
    "props_df = am.select_datasets(\"cell_properties\", dtype=\"dataframe\")\n",
    "\n",
    "snr_df = SNRAnalysis(spots_df, props_df, clusters_df, abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "merged_spots_df, merged_clusters_df, merged_cellprops_df = snr_df.get_results()\n",
    "\n",
    "# Create an instance of the DUSP1Measurement class.\n",
    "dusp = DUSP1Measurement(merged_spots_df, merged_clusters_df, merged_cellprops_df)\n",
    "\n",
    "# Process the data with a chosen threshold method\n",
    "cell_level_results = dusp.measure(abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "# Add replica level unique IDs for 'unique_cell_id', 'unique_spot_id', and 'unique_cluster_id'\n",
    "# Get number of digits in the max unique_cell_id\n",
    "max_id = merged_cellprops_df['unique_cell_id'].max()\n",
    "num_digits = len(str(max_id))\n",
    "\n",
    "# Calculate multiplier to add a '1' followed by the right number of zeroes - prefix is specific for each experiment (e.g., repD:1, repE:2, etc.)\n",
    "rep_prefix = 10\n",
    "prefix = rep_prefix ** num_digits  # e.g., if max_id = 30245 → prefix = 100000\n",
    "\n",
    "# Apply prefix to all related DataFrames\n",
    "merged_spots_df['unique_cell_id'] += prefix\n",
    "merged_clusters_df['unique_cell_id'] += prefix\n",
    "merged_cellprops_df['unique_cell_id'] += prefix\n",
    "cell_level_results['unique_cell_id'] += prefix\n",
    "\n",
    "# Repeat for unique_spot_id and unique_cluster_id\n",
    "max_spot_id = merged_spots_df['unique_spot_id'].max()\n",
    "spot_prefix = rep_prefix ** len(str(max_spot_id))\n",
    "merged_spots_df['unique_spot_id'] += spot_prefix\n",
    "\n",
    "max_cluster_id = merged_clusters_df['unique_cluster_id'].max()\n",
    "cluster_prefix = rep_prefix ** len(str(max_cluster_id))\n",
    "merged_clusters_df['unique_cluster_id'] += cluster_prefix\n",
    "\n",
    "# Save all results to CSV\n",
    "rep_string = 'DUSP1_D_Final'\n",
    "output_dir = '/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/Classification'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "cell_level_results.to_csv(os.path.join(output_dir, f\"{rep_string}_cell_level_results_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_spots_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_spots_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_clusters_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_clusters_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_cellprops_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_cellprops_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "\n",
    "# instantiate sampler\n",
    "sampler = SpotCropSampler(\n",
    "    spots_df=merged_spots_df,\n",
    "    clusters_df=merged_clusters_df,\n",
    "    cellprops_df=merged_cellprops_df,\n",
    "    mount_prefix=\"/Volumes/share\"\n",
    ")\n",
    "\n",
    "# # — TEST RUN: only 3 displays, no files written —\n",
    "# crops, meta = sampler.run(\n",
    "#     save_dir=save_dir,\n",
    "#     display=3,\n",
    "#     save_individual=False,\n",
    "#     save_summary=False,\n",
    "#     pad=5,\n",
    "#     cells_per_quad=1,\n",
    "#     spots_per_cell=20,\n",
    "#     spotChannel=0\n",
    "# )\n",
    "\n",
    "# choose a prefix for this experiment\n",
    "prefix = \"DUSP1_D_Final_MG3_Abs4\"\n",
    "\n",
    "# full run, no per-spot files, but summary files with prefix\n",
    "crops, meta = sampler.run(\n",
    "    save_dir=save_dir,\n",
    "    display=0,\n",
    "    save_individual=False,\n",
    "    save_summary=True,\n",
    "    file_prefix=prefix,\n",
    "    pad=5,\n",
    "    cells_per_quad=1,\n",
    "    spots_per_cell=20,\n",
    "    spotChannel=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245e219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Directory where you saved the summary files\n",
    "# save_dir = \"/Volumes/share/Users/Eric/DUSP1_SpotCrops\"\n",
    "\n",
    "# # 1) Load the data\n",
    "# crops = np.load(os.path.join(save_dir, f\"{prefix}_all_crops.npy\"))  # shape: (N, 7, 7)\n",
    "# meta  = pd.read_csv(os.path.join(save_dir, f\"{prefix}_all_crop_metadata.csv\"))\n",
    "\n",
    "# # 2) Choose a few random examples (up to 5)\n",
    "# num_examples = min(5, len(crops))\n",
    "# indices = np.random.choice(len(crops), size=num_examples, replace=False)\n",
    "\n",
    "# # 3) Display them\n",
    "# fig, axes = plt.subplots(1, num_examples, figsize=(num_examples * 3, 3))\n",
    "# for ax, idx in zip(axes, indices):\n",
    "#     patch = crops[idx]\n",
    "#     info  = meta.iloc[idx]\n",
    "    \n",
    "#     ax.imshow(patch, cmap='gray')\n",
    "#     ax.set_title(\n",
    "#         f\"Cell {info.unique_cell_id}\\n\"\n",
    "#         f\"Spot {info.unique_spot_id}\\n\"\n",
    "#         f\"MG_SNR={info.MG_SNR:.1f}, SNR={info.snr:.1f}\\n\"\n",
    "#         f\"MG_pass={info.MG_pass}\"\n",
    "#     )\n",
    "#     ax.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f8e5d6",
   "metadata": {},
   "source": [
    "    # DUSP1 Replica E 3hr 100nM time-sweep R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91985ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = DUSP1AnalysisManager(location=loc, log_location=log_location, mac=True) \n",
    "am.select_analysis('DUSP1_E_Final')\n",
    "\n",
    "spots_df = am.select_datasets(\"spotresults\", dtype=\"dataframe\")\n",
    "clusters_df = am.select_datasets(\"clusterresults\", dtype=\"dataframe\")\n",
    "props_df = am.select_datasets(\"cell_properties\", dtype=\"dataframe\")\n",
    "\n",
    "snr_df = SNRAnalysis(spots_df, props_df, clusters_df, abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "merged_spots_df, merged_clusters_df, merged_cellprops_df = snr_df.get_results()\n",
    "\n",
    "# Create an instance of the DUSP1Measurement class.\n",
    "dusp = DUSP1Measurement(merged_spots_df, merged_clusters_df, merged_cellprops_df)\n",
    "\n",
    "# Process the data with a chosen threshold method\n",
    "cell_level_results = dusp.measure(abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "# Add replica level unique IDs for 'unique_cell_id', 'unique_spot_id', and 'unique_cluster_id'\n",
    "# Get number of digits in the max unique_cell_id\n",
    "max_id = merged_cellprops_df['unique_cell_id'].max()\n",
    "num_digits = len(str(max_id))\n",
    "\n",
    "# Calculate multiplier to add a '1' followed by the right number of zeroes - prefix is specific for each experiment (e.g., repD:1, repE:2, etc.)\n",
    "rep_prefix = 20\n",
    "prefix = rep_prefix ** num_digits  # e.g., if max_id = 30245 → prefix = 100000\n",
    "\n",
    "# Apply prefix to all related DataFrames\n",
    "merged_spots_df['unique_cell_id'] += prefix\n",
    "merged_clusters_df['unique_cell_id'] += prefix\n",
    "merged_cellprops_df['unique_cell_id'] += prefix\n",
    "cell_level_results['unique_cell_id'] += prefix\n",
    "\n",
    "# Repeat for unique_spot_id and unique_cluster_id\n",
    "max_spot_id = merged_spots_df['unique_spot_id'].max()\n",
    "spot_prefix = rep_prefix ** len(str(max_spot_id))\n",
    "merged_spots_df['unique_spot_id'] += spot_prefix\n",
    "\n",
    "max_cluster_id = merged_clusters_df['unique_cluster_id'].max()\n",
    "cluster_prefix = rep_prefix ** len(str(max_cluster_id))\n",
    "merged_clusters_df['unique_cluster_id'] += cluster_prefix\n",
    "\n",
    "# Save all results to CSV\n",
    "rep_string = 'DUSP1_E_Final'\n",
    "output_dir = '/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/Classification'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "cell_level_results.to_csv(os.path.join(output_dir, f\"{rep_string}_cell_level_results_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_spots_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_spots_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_clusters_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_clusters_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_cellprops_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_cellprops_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "\n",
    "# instantiate sampler\n",
    "sampler = SpotCropSampler(\n",
    "    spots_df=merged_spots_df,\n",
    "    clusters_df=merged_clusters_df,\n",
    "    cellprops_df=merged_cellprops_df,\n",
    "    mount_prefix=\"/Volumes/share\"\n",
    ")\n",
    "\n",
    "# # — TEST RUN: only 3 displays, no files written —\n",
    "# crops, meta = sampler.run(\n",
    "#     save_dir=save_dir,\n",
    "#     display=3,\n",
    "#     save_individual=False,\n",
    "#     save_summary=False,\n",
    "#     pad=5,\n",
    "#     cells_per_quad=1,\n",
    "#     spots_per_cell=20,\n",
    "#     spotChannel=0\n",
    "# )\n",
    "\n",
    "# choose a prefix for this experiment\n",
    "prefix = \"DUSP1_E_Final_MG3_Abs4\"\n",
    "\n",
    "# full run, no per-spot files, but summary files with prefix\n",
    "crops, meta = sampler.run(\n",
    "    save_dir=save_dir,\n",
    "    display=0,\n",
    "    save_individual=False,\n",
    "    save_summary=True,\n",
    "    file_prefix=prefix,\n",
    "    pad=5,\n",
    "    cells_per_quad=1,\n",
    "    spots_per_cell=20,\n",
    "    spotChannel=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb75311",
   "metadata": {},
   "source": [
    "    # DUSP1 Replica F 3hr 100nM time-sweep R3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab04089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = DUSP1AnalysisManager(location=loc, log_location=log_location, mac=True) \n",
    "am.select_analysis('DUSP1_F_Final')\n",
    "\n",
    "spots_df = am.select_datasets(\"spotresults\", dtype=\"dataframe\")\n",
    "clusters_df = am.select_datasets(\"clusterresults\", dtype=\"dataframe\")\n",
    "props_df = am.select_datasets(\"cell_properties\", dtype=\"dataframe\")\n",
    "\n",
    "snr_df = SNRAnalysis(spots_df, props_df, clusters_df, abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "merged_spots_df, merged_clusters_df, merged_cellprops_df = snr_df.get_results()\n",
    "\n",
    "# Create an instance of the DUSP1Measurement class.\n",
    "dusp = DUSP1Measurement(merged_spots_df, merged_clusters_df, merged_cellprops_df)\n",
    "\n",
    "# Process the data with a chosen threshold method\n",
    "cell_level_results = dusp.measure(abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "# Add replica level unique IDs for 'unique_cell_id', 'unique_spot_id', and 'unique_cluster_id'\n",
    "# Get number of digits in the max unique_cell_id\n",
    "max_id = merged_cellprops_df['unique_cell_id'].max()\n",
    "num_digits = len(str(max_id))\n",
    "\n",
    "# Calculate multiplier to add a '1' followed by the right number of zeroes - prefix is specific for each experiment (e.g., repD:1, repE:2, etc.)\n",
    "rep_prefix = 30\n",
    "prefix = rep_prefix ** num_digits  # e.g., if max_id = 30245 → prefix = 100000\n",
    "\n",
    "# Apply prefix to all related DataFrames\n",
    "merged_spots_df['unique_cell_id'] += prefix\n",
    "merged_clusters_df['unique_cell_id'] += prefix\n",
    "merged_cellprops_df['unique_cell_id'] += prefix\n",
    "cell_level_results['unique_cell_id'] += prefix\n",
    "\n",
    "# Repeat for unique_spot_id and unique_cluster_id\n",
    "max_spot_id = merged_spots_df['unique_spot_id'].max()\n",
    "spot_prefix = rep_prefix ** len(str(max_spot_id))\n",
    "merged_spots_df['unique_spot_id'] += spot_prefix\n",
    "\n",
    "max_cluster_id = merged_clusters_df['unique_cluster_id'].max()\n",
    "cluster_prefix = rep_prefix ** len(str(max_cluster_id))\n",
    "merged_clusters_df['unique_cluster_id'] += cluster_prefix\n",
    "\n",
    "# Save all results to CSV\n",
    "rep_string = 'DUSP1_F_Final'\n",
    "output_dir = '/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/Classification'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "cell_level_results.to_csv(os.path.join(output_dir, f\"{rep_string}_cell_level_results_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_spots_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_spots_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_clusters_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_clusters_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_cellprops_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_cellprops_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "\n",
    "# instantiate sampler\n",
    "sampler = SpotCropSampler(\n",
    "    spots_df=merged_spots_df,\n",
    "    clusters_df=merged_clusters_df,\n",
    "    cellprops_df=merged_cellprops_df,\n",
    "    mount_prefix=\"/Volumes/share\"\n",
    ")\n",
    "\n",
    "# # — TEST RUN: only 3 displays, no files written —\n",
    "# crops, meta = sampler.run(\n",
    "#     save_dir=save_dir,\n",
    "#     display=3,\n",
    "#     save_individual=False,\n",
    "#     save_summary=False,\n",
    "#     pad=5,\n",
    "#     cells_per_quad=1,\n",
    "#     spots_per_cell=20,\n",
    "#     spotChannel=0\n",
    "# )\n",
    "\n",
    "# choose a prefix for this experiment\n",
    "prefix = f\"DUSP1_F_Final_MG3_Abs4\"\n",
    "\n",
    "# full run, no per-spot files, but summary files with prefix\n",
    "crops, meta = sampler.run(\n",
    "    save_dir=save_dir,\n",
    "    display=0,\n",
    "    save_individual=False,\n",
    "    save_summary=True,\n",
    "    file_prefix=prefix,\n",
    "    pad=5,\n",
    "    cells_per_quad=1,\n",
    "    spots_per_cell=20,\n",
    "    spotChannel=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8234fd1e",
   "metadata": {},
   "source": [
    "    # DUSP1 Replica M 3hr 100nM time-sweep Partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = DUSP1AnalysisManager(location=loc, log_location=log_location, mac=True) \n",
    "am.select_analysis('DUSP1_M_Final')\n",
    "\n",
    "spots_df = am.select_datasets(\"spotresults\", dtype=\"dataframe\")\n",
    "clusters_df = am.select_datasets(\"clusterresults\", dtype=\"dataframe\")\n",
    "props_df = am.select_datasets(\"cell_properties\", dtype=\"dataframe\")\n",
    "\n",
    "snr_df = SNRAnalysis(spots_df, props_df, clusters_df, abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "merged_spots_df, merged_clusters_df, merged_cellprops_df = snr_df.get_results()\n",
    "\n",
    "# Create an instance of the DUSP1Measurement class.\n",
    "dusp = DUSP1Measurement(merged_spots_df, merged_clusters_df, merged_cellprops_df)\n",
    "\n",
    "# Process the data with a chosen threshold method\n",
    "cell_level_results = dusp.measure(abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "# Add replica level unique IDs for 'unique_cell_id', 'unique_spot_id', and 'unique_cluster_id'\n",
    "# Get number of digits in the max unique_cell_id\n",
    "max_id = merged_cellprops_df['unique_cell_id'].max()\n",
    "num_digits = len(str(max_id))\n",
    "\n",
    "# Calculate multiplier to add a '1' followed by the right number of zeroes - prefix is specific for each experiment (e.g., repD:1, repE:2, etc.)\n",
    "rep_prefix = 40\n",
    "prefix = rep_prefix ** num_digits  # e.g., if max_id = 30245 → prefix = 100000\n",
    "\n",
    "# Apply prefix to all related DataFrames\n",
    "merged_spots_df['unique_cell_id'] += prefix\n",
    "merged_clusters_df['unique_cell_id'] += prefix\n",
    "merged_cellprops_df['unique_cell_id'] += prefix\n",
    "cell_level_results['unique_cell_id'] += prefix\n",
    "\n",
    "# Repeat for unique_spot_id and unique_cluster_id\n",
    "max_spot_id = merged_spots_df['unique_spot_id'].max()\n",
    "spot_prefix = rep_prefix ** len(str(max_spot_id))\n",
    "merged_spots_df['unique_spot_id'] += spot_prefix\n",
    "\n",
    "max_cluster_id = merged_clusters_df['unique_cluster_id'].max()\n",
    "cluster_prefix = rep_prefix ** len(str(max_cluster_id))\n",
    "merged_clusters_df['unique_cluster_id'] += cluster_prefix\n",
    "\n",
    "# Save all results to CSV\n",
    "rep_string = 'DUSP1_M_Final'\n",
    "output_dir = '/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/Classification'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "cell_level_results.to_csv(os.path.join(output_dir, f\"{rep_string}_cell_level_results_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_spots_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_spots_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_clusters_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_clusters_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_cellprops_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_cellprops_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "\n",
    "# instantiate sampler\n",
    "sampler = SpotCropSampler(\n",
    "    spots_df=merged_spots_df,\n",
    "    clusters_df=merged_clusters_df,\n",
    "    cellprops_df=merged_cellprops_df,\n",
    "    mount_prefix=\"/Volumes/share\"\n",
    ")\n",
    "\n",
    "# # — TEST RUN: only 3 displays, no files written —\n",
    "# crops, meta = sampler.run(\n",
    "#     save_dir=save_dir,\n",
    "#     display=3,\n",
    "#     save_individual=False,\n",
    "#     save_summary=False,\n",
    "#     pad=5,\n",
    "#     cells_per_quad=1,\n",
    "#     spots_per_cell=20,\n",
    "#     spotChannel=0\n",
    "# )\n",
    "\n",
    "# choose a prefix for this experiment\n",
    "prefix = f\"DUSP1_M_Final_MG3_Abs4\"\n",
    "\n",
    "# full run, no per-spot files, but summary files with prefix\n",
    "crops, meta = sampler.run(\n",
    "    save_dir=save_dir,\n",
    "    display=0,\n",
    "    save_individual=False,\n",
    "    save_summary=True,\n",
    "    file_prefix=prefix,\n",
    "    pad=5,\n",
    "    cells_per_quad=1,\n",
    "    spots_per_cell=20,\n",
    "    spotChannel=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcafe0e9",
   "metadata": {},
   "source": [
    "    # DUSP1 Replica N 3hr 100nM time-sweep Partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a614db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = DUSP1AnalysisManager(location=loc, log_location=log_location, mac=True) \n",
    "am.select_analysis('DUSP1_N_Final2')\n",
    "\n",
    "spots_df = am.select_datasets(\"spotresults\", dtype=\"dataframe\")\n",
    "clusters_df = am.select_datasets(\"clusterresults\", dtype=\"dataframe\")\n",
    "props_df = am.select_datasets(\"cell_properties\", dtype=\"dataframe\")\n",
    "\n",
    "snr_df = SNRAnalysis(spots_df, props_df, clusters_df, abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "merged_spots_df, merged_clusters_df, merged_cellprops_df = snr_df.get_results()\n",
    "\n",
    "# Create an instance of the DUSP1Measurement class.\n",
    "dusp = DUSP1Measurement(merged_spots_df, merged_clusters_df, merged_cellprops_df)\n",
    "\n",
    "# Process the data with a chosen threshold method\n",
    "cell_level_results = dusp.measure(abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "# Add replica level unique IDs for 'unique_cell_id', 'unique_spot_id', and 'unique_cluster_id'\n",
    "# Get number of digits in the max unique_cell_id\n",
    "max_id = merged_cellprops_df['unique_cell_id'].max()\n",
    "num_digits = len(str(max_id))\n",
    "\n",
    "# Calculate multiplier to add a '1' followed by the right number of zeroes - prefix is specific for each experiment (e.g., repD:1, repE:2, etc.)\n",
    "rep_prefix = 50\n",
    "prefix = rep_prefix ** num_digits  # e.g., if max_id = 30245 → prefix = 100000\n",
    "\n",
    "# Apply prefix to all related DataFrames\n",
    "merged_spots_df['unique_cell_id'] += prefix\n",
    "merged_clusters_df['unique_cell_id'] += prefix\n",
    "merged_cellprops_df['unique_cell_id'] += prefix\n",
    "cell_level_results['unique_cell_id'] += prefix\n",
    "\n",
    "# Repeat for unique_spot_id and unique_cluster_id\n",
    "max_spot_id = merged_spots_df['unique_spot_id'].max()\n",
    "spot_prefix = rep_prefix ** len(str(max_spot_id))\n",
    "merged_spots_df['unique_spot_id'] += spot_prefix\n",
    "\n",
    "max_cluster_id = merged_clusters_df['unique_cluster_id'].max()\n",
    "cluster_prefix = rep_prefix ** len(str(max_cluster_id))\n",
    "merged_clusters_df['unique_cluster_id'] += cluster_prefix\n",
    "\n",
    "# Save all results to CSV\n",
    "rep_string = 'DUSP1_N_Final'\n",
    "output_dir = '/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/Classification'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "cell_level_results.to_csv(os.path.join(output_dir, f\"{rep_string}_cell_level_results_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_spots_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_spots_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_clusters_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_clusters_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_cellprops_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_cellprops_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "\n",
    "# instantiate sampler\n",
    "sampler = SpotCropSampler(\n",
    "    spots_df=merged_spots_df,\n",
    "    clusters_df=merged_clusters_df,\n",
    "    cellprops_df=merged_cellprops_df,\n",
    "    mount_prefix=\"/Volumes/share\"\n",
    ")\n",
    "\n",
    "# # — TEST RUN: only 3 displays, no files written —\n",
    "# crops, meta = sampler.run(\n",
    "#     save_dir=save_dir,\n",
    "#     display=3,\n",
    "#     save_individual=False,\n",
    "#     save_summary=False,\n",
    "#     pad=5,\n",
    "#     cells_per_quad=1,\n",
    "#     spots_per_cell=20,\n",
    "#     spotChannel=0\n",
    "# )\n",
    "\n",
    "# choose a prefix for this experiment\n",
    "prefix = f\"DUSP1_N_Final_MG3_Abs4\"\n",
    "\n",
    "# full run, no per-spot files, but summary files with prefix\n",
    "crops, meta = sampler.run(\n",
    "    save_dir=save_dir,\n",
    "    display=0,\n",
    "    save_individual=False,\n",
    "    save_summary=True,\n",
    "    file_prefix=prefix,\n",
    "    pad=5,\n",
    "    cells_per_quad=1,\n",
    "    spots_per_cell=20,\n",
    "    spotChannel=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb73587",
   "metadata": {},
   "source": [
    "    DUSP1 75min Concentration-sweep Replica 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d4c99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = DUSP1AnalysisManager(location=loc, log_location=log_location, mac=True) \n",
    "am.select_analysis('DUSP1_CS_R1_Final3')\n",
    "\n",
    "spots_df = am.select_datasets(\"spotresults\", dtype=\"dataframe\")\n",
    "clusters_df = am.select_datasets(\"clusterresults\", dtype=\"dataframe\")\n",
    "props_df = am.select_datasets(\"cell_properties\", dtype=\"dataframe\")\n",
    "\n",
    "snr_df = SNRAnalysis(spots_df, props_df, clusters_df, abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "merged_spots_df, merged_clusters_df, merged_cellprops_df = snr_df.get_results()\n",
    "\n",
    "# Create an instance of the DUSP1Measurement class.\n",
    "dusp = DUSP1Measurement(merged_spots_df, merged_clusters_df, merged_cellprops_df)\n",
    "\n",
    "# Process the data with a chosen threshold method\n",
    "cell_level_results = dusp.measure(abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "# Add replica level unique IDs for 'unique_cell_id', 'unique_spot_id', and 'unique_cluster_id'\n",
    "# Get number of digits in the max unique_cell_id\n",
    "max_id = merged_cellprops_df['unique_cell_id'].max()\n",
    "num_digits = len(str(max_id))\n",
    "\n",
    "# Calculate multiplier to add a '1' followed by the right number of zeroes - prefix is specific for each experiment (e.g., repD:1, repE:2, etc.)\n",
    "rep_prefix = 60\n",
    "prefix = rep_prefix ** num_digits  # e.g., if max_id = 30245 → prefix = 100000\n",
    "\n",
    "# Apply prefix to all related DataFrames\n",
    "merged_spots_df['unique_cell_id'] += prefix\n",
    "merged_clusters_df['unique_cell_id'] += prefix\n",
    "merged_cellprops_df['unique_cell_id'] += prefix\n",
    "cell_level_results['unique_cell_id'] += prefix\n",
    "\n",
    "# Repeat for unique_spot_id and unique_cluster_id\n",
    "max_spot_id = merged_spots_df['unique_spot_id'].max()\n",
    "spot_prefix = rep_prefix ** len(str(max_spot_id))\n",
    "merged_spots_df['unique_spot_id'] += spot_prefix\n",
    "\n",
    "max_cluster_id = merged_clusters_df['unique_cluster_id'].max()\n",
    "cluster_prefix = rep_prefix ** len(str(max_cluster_id))\n",
    "merged_clusters_df['unique_cluster_id'] += cluster_prefix\n",
    "\n",
    "# Save all results to CSV\n",
    "rep_string = 'DUSP1_G_Final'\n",
    "output_dir = '/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/Classification'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "cell_level_results.to_csv(os.path.join(output_dir, f\"{rep_string}_cell_level_results_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_spots_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_spots_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_clusters_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_clusters_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_cellprops_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_cellprops_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "\n",
    "# instantiate sampler\n",
    "sampler = SpotCropSampler(\n",
    "    spots_df=merged_spots_df,\n",
    "    clusters_df=merged_clusters_df,\n",
    "    cellprops_df=merged_cellprops_df,\n",
    "    mount_prefix=\"/Volumes/share\"\n",
    ")\n",
    "\n",
    "# # — TEST RUN: only 3 displays, no files written —\n",
    "# crops, meta = sampler.run(\n",
    "#     save_dir=save_dir,\n",
    "#     display=3,\n",
    "#     save_individual=False,\n",
    "#     save_summary=False,\n",
    "#     pad=5,\n",
    "#     cells_per_quad=1,\n",
    "#     spots_per_cell=20,\n",
    "#     spotChannel=0\n",
    "# )\n",
    "\n",
    "# choose a prefix for this experiment\n",
    "prefix = f\"DUSP1_G_Final_MG3_Abs4\"\n",
    "\n",
    "# full run, no per-spot files, but summary files with prefix\n",
    "crops, meta = sampler.run(\n",
    "    save_dir=save_dir,\n",
    "    display=0,\n",
    "    save_individual=False,\n",
    "    save_summary=True,\n",
    "    file_prefix=prefix,\n",
    "    pad=5,\n",
    "    cells_per_quad=1,\n",
    "    spots_per_cell=20,\n",
    "    spotChannel=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e6253",
   "metadata": {},
   "source": [
    "    DUSP1 75min Concentration-sweep Replica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = DUSP1AnalysisManager(location=loc, log_location=log_location, mac=True) \n",
    "am.select_analysis('DUSP1_H_Final')\n",
    "\n",
    "spots_df = am.select_datasets(\"spotresults\", dtype=\"dataframe\")\n",
    "clusters_df = am.select_datasets(\"clusterresults\", dtype=\"dataframe\")\n",
    "props_df = am.select_datasets(\"cell_properties\", dtype=\"dataframe\")\n",
    "\n",
    "snr_df = SNRAnalysis(spots_df, props_df, clusters_df, abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "merged_spots_df, merged_clusters_df, merged_cellprops_df = snr_df.get_results()\n",
    "\n",
    "# Create an instance of the DUSP1Measurement class.\n",
    "dusp = DUSP1Measurement(merged_spots_df, merged_clusters_df, merged_cellprops_df)\n",
    "\n",
    "# Process the data with a chosen threshold method\n",
    "cell_level_results = dusp.measure(abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "# Add replica level unique IDs for 'unique_cell_id', 'unique_spot_id', and 'unique_cluster_id'\n",
    "# Get number of digits in the max unique_cell_id\n",
    "max_id = merged_cellprops_df['unique_cell_id'].max()\n",
    "num_digits = len(str(max_id))\n",
    "\n",
    "# Calculate multiplier to add a '1' followed by the right number of zeroes - prefix is specific for each experiment (e.g., repD:1, repE:2, etc.)\n",
    "rep_prefix = 70\n",
    "prefix = rep_prefix ** num_digits  # e.g., if max_id = 30245 → prefix = 100000\n",
    "\n",
    "# Apply prefix to all related DataFrames\n",
    "merged_spots_df['unique_cell_id'] += prefix\n",
    "merged_clusters_df['unique_cell_id'] += prefix\n",
    "merged_cellprops_df['unique_cell_id'] += prefix\n",
    "cell_level_results['unique_cell_id'] += prefix\n",
    "\n",
    "# Repeat for unique_spot_id and unique_cluster_id\n",
    "max_spot_id = merged_spots_df['unique_spot_id'].max()\n",
    "spot_prefix = rep_prefix ** len(str(max_spot_id))\n",
    "merged_spots_df['unique_spot_id'] += spot_prefix\n",
    "\n",
    "max_cluster_id = merged_clusters_df['unique_cluster_id'].max()\n",
    "cluster_prefix = rep_prefix ** len(str(max_cluster_id))\n",
    "merged_clusters_df['unique_cluster_id'] += cluster_prefix\n",
    "\n",
    "# Save all results to CSV\n",
    "rep_string = 'DUSP1_H_Final'\n",
    "output_dir = '/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/Classification'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "cell_level_results.to_csv(os.path.join(output_dir, f\"{rep_string}_cell_level_results_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_spots_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_spots_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_clusters_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_clusters_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_cellprops_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_cellprops_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "\n",
    "# instantiate sampler\n",
    "sampler = SpotCropSampler(\n",
    "    spots_df=merged_spots_df,\n",
    "    clusters_df=merged_clusters_df,\n",
    "    cellprops_df=merged_cellprops_df,\n",
    "    mount_prefix=\"/Volumes/share\"\n",
    ")\n",
    "\n",
    "# # — TEST RUN: only 3 displays, no files written —\n",
    "# crops, meta = sampler.run(\n",
    "#     save_dir=save_dir,\n",
    "#     display=3,\n",
    "#     save_individual=False,\n",
    "#     save_summary=False,\n",
    "#     pad=5,\n",
    "#     cells_per_quad=1,\n",
    "#     spots_per_cell=20,\n",
    "#     spotChannel=0\n",
    "# )\n",
    "\n",
    "# choose a prefix for this experiment\n",
    "prefix = f\"DUSP1_H_Final_MG3_Abs4\"\n",
    "\n",
    "# full run, no per-spot files, but summary files with prefix\n",
    "crops, meta = sampler.run(\n",
    "    save_dir=save_dir,\n",
    "    display=0,\n",
    "    save_individual=False,\n",
    "    save_summary=True,\n",
    "    file_prefix=prefix,\n",
    "    pad=5,\n",
    "    cells_per_quad=1,\n",
    "    spots_per_cell=20,\n",
    "    spotChannel=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afee3a73",
   "metadata": {},
   "source": [
    "    DUSP1 75min Concentration-sweep Replica 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe4c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = DUSP1AnalysisManager(location=loc, log_location=log_location, mac=True) \n",
    "am.select_analysis('DUSP1_I_Final')\n",
    "\n",
    "spots_df = am.select_datasets(\"spotresults\", dtype=\"dataframe\")\n",
    "clusters_df = am.select_datasets(\"clusterresults\", dtype=\"dataframe\")\n",
    "props_df = am.select_datasets(\"cell_properties\", dtype=\"dataframe\")\n",
    "\n",
    "snr_df = SNRAnalysis(spots_df, props_df, clusters_df, abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "merged_spots_df, merged_clusters_df, merged_cellprops_df = snr_df.get_results()\n",
    "\n",
    "# Create an instance of the DUSP1Measurement class.\n",
    "dusp = DUSP1Measurement(merged_spots_df, merged_clusters_df, merged_cellprops_df)\n",
    "\n",
    "# Process the data with a chosen threshold method\n",
    "cell_level_results = dusp.measure(abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "# Add replica level unique IDs for 'unique_cell_id', 'unique_spot_id', and 'unique_cluster_id'\n",
    "# Get number of digits in the max unique_cell_id\n",
    "max_id = merged_cellprops_df['unique_cell_id'].max()\n",
    "num_digits = len(str(max_id))\n",
    "\n",
    "# Calculate multiplier to add a '1' followed by the right number of zeroes - prefix is specific for each experiment (e.g., repD:1, repE:2, etc.)\n",
    "rep_prefix = 80\n",
    "prefix = rep_prefix ** num_digits  # e.g., if max_id = 30245 → prefix = 100000\n",
    "\n",
    "# Apply prefix to all related DataFrames\n",
    "merged_spots_df['unique_cell_id'] += prefix\n",
    "merged_clusters_df['unique_cell_id'] += prefix\n",
    "merged_cellprops_df['unique_cell_id'] += prefix\n",
    "cell_level_results['unique_cell_id'] += prefix\n",
    "\n",
    "# Repeat for unique_spot_id and unique_cluster_id\n",
    "max_spot_id = merged_spots_df['unique_spot_id'].max()\n",
    "spot_prefix = rep_prefix ** len(str(max_spot_id))\n",
    "merged_spots_df['unique_spot_id'] += spot_prefix\n",
    "\n",
    "max_cluster_id = merged_clusters_df['unique_cluster_id'].max()\n",
    "cluster_prefix = rep_prefix ** len(str(max_cluster_id))\n",
    "merged_clusters_df['unique_cluster_id'] += cluster_prefix\n",
    "\n",
    "# Save all results to CSV\n",
    "rep_string = 'DUSP1_I_Final'\n",
    "output_dir = '/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/Classification'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "cell_level_results.to_csv(os.path.join(output_dir, f\"{rep_string}_cell_level_results_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_spots_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_spots_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_clusters_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_clusters_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_cellprops_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_cellprops_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "\n",
    "# instantiate sampler\n",
    "sampler = SpotCropSampler(\n",
    "    spots_df=merged_spots_df,\n",
    "    clusters_df=merged_clusters_df,\n",
    "    cellprops_df=merged_cellprops_df,\n",
    "    mount_prefix=\"/Volumes/share\"\n",
    ")\n",
    "\n",
    "# # — TEST RUN: only 3 displays, no files written —\n",
    "# crops, meta = sampler.run(\n",
    "#     save_dir=save_dir,\n",
    "#     display=3,\n",
    "#     save_individual=False,\n",
    "#     save_summary=False,\n",
    "#     pad=5,\n",
    "#     cells_per_quad=1,\n",
    "#     spots_per_cell=20,\n",
    "#     spotChannel=0\n",
    "# )\n",
    "\n",
    "# choose a prefix for this experiment\n",
    "prefix = f\"DUSP1_I_Final_MG3_Abs4\"\n",
    "\n",
    "# full run, no per-spot files, but summary files with prefix\n",
    "crops, meta = sampler.run(\n",
    "    save_dir=save_dir,\n",
    "    display=0,\n",
    "    save_individual=False,\n",
    "    save_summary=True,\n",
    "    file_prefix=prefix,\n",
    "    pad=5,\n",
    "    cells_per_quad=1,\n",
    "    spots_per_cell=20,\n",
    "    spotChannel=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8efb890",
   "metadata": {},
   "source": [
    "    DUSP1 0.3, 1, 10nM Dex 3hr Time-sweep Replica 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dced7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = DUSP1AnalysisManager(location=loc, log_location=log_location, mac=True) \n",
    "am.select_analysis('DUSP1_TCS_R1_Final3')\n",
    "\n",
    "spots_df = am.select_datasets(\"spotresults\", dtype=\"dataframe\")\n",
    "clusters_df = am.select_datasets(\"clusterresults\", dtype=\"dataframe\")\n",
    "props_df = am.select_datasets(\"cell_properties\", dtype=\"dataframe\")\n",
    "\n",
    "snr_df = SNRAnalysis(spots_df, props_df, clusters_df, abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "merged_spots_df, merged_clusters_df, merged_cellprops_df = snr_df.get_results()\n",
    "\n",
    "# Create an instance of the DUSP1Measurement class.\n",
    "dusp = DUSP1Measurement(merged_spots_df, merged_clusters_df, merged_cellprops_df)\n",
    "\n",
    "# Process the data with a chosen threshold method\n",
    "cell_level_results = dusp.measure(abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "# Add replica level unique IDs for 'unique_cell_id', 'unique_spot_id', and 'unique_cluster_id'\n",
    "# Get number of digits in the max unique_cell_id\n",
    "max_id = merged_cellprops_df['unique_cell_id'].max()\n",
    "num_digits = len(str(max_id))\n",
    "\n",
    "# Calculate multiplier to add a '1' followed by the right number of zeroes - prefix is specific for each experiment (e.g., repD:1, repE:2, etc.)\n",
    "rep_prefix = 90\n",
    "prefix = rep_prefix ** num_digits  # e.g., if max_id = 30245 → prefix = 100000\n",
    "\n",
    "# Apply prefix to all related DataFrames\n",
    "merged_spots_df['unique_cell_id'] += prefix\n",
    "merged_clusters_df['unique_cell_id'] += prefix\n",
    "merged_cellprops_df['unique_cell_id'] += prefix\n",
    "cell_level_results['unique_cell_id'] += prefix\n",
    "\n",
    "# Repeat for unique_spot_id and unique_cluster_id\n",
    "max_spot_id = merged_spots_df['unique_spot_id'].max()\n",
    "spot_prefix = rep_prefix ** len(str(max_spot_id))\n",
    "merged_spots_df['unique_spot_id'] += spot_prefix\n",
    "\n",
    "max_cluster_id = merged_clusters_df['unique_cluster_id'].max()\n",
    "cluster_prefix = rep_prefix ** len(str(max_cluster_id))\n",
    "merged_clusters_df['unique_cluster_id'] += cluster_prefix\n",
    "\n",
    "# Save all results to CSV\n",
    "rep_string = 'DUSP1_J_Final'\n",
    "output_dir = '/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/Classification'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "cell_level_results.to_csv(os.path.join(output_dir, f\"{rep_string}_cell_level_results_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_spots_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_spots_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_clusters_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_clusters_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_cellprops_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_cellprops_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "\n",
    "# instantiate sampler\n",
    "sampler = SpotCropSampler(\n",
    "    spots_df=merged_spots_df,\n",
    "    clusters_df=merged_clusters_df,\n",
    "    cellprops_df=merged_cellprops_df,\n",
    "    mount_prefix=\"/Volumes/share\"\n",
    ")\n",
    "\n",
    "# # — TEST RUN: only 3 displays, no files written —\n",
    "# crops, meta = sampler.run(\n",
    "#     save_dir=save_dir,\n",
    "#     display=3,\n",
    "#     save_individual=False,\n",
    "#     save_summary=False,\n",
    "#     pad=5,\n",
    "#     cells_per_quad=1,\n",
    "#     spots_per_cell=20,\n",
    "#     spotChannel=0\n",
    "# )\n",
    "\n",
    "# choose a prefix for this experiment\n",
    "prefix = f\"DUSP1_J_Final_MG3_Abs4\"\n",
    "\n",
    "# full run, no per-spot files, but summary files with prefix\n",
    "crops, meta = sampler.run(\n",
    "    save_dir=save_dir,\n",
    "    display=0,\n",
    "    save_individual=False,\n",
    "    save_summary=True,\n",
    "    file_prefix=prefix,\n",
    "    pad=5,\n",
    "    cells_per_quad=1,\n",
    "    spots_per_cell=20,\n",
    "    spotChannel=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7afb5a3",
   "metadata": {},
   "source": [
    "    DUSP1 0.3, 1, 10nM Dex 3hr Time-sweep Replica 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e9370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = DUSP1AnalysisManager(location=loc, log_location=log_location, mac=True) \n",
    "am.select_analysis('DUSP1_K_Final')\n",
    "\n",
    "spots_df = am.select_datasets(\"spotresults\", dtype=\"dataframe\")\n",
    "clusters_df = am.select_datasets(\"clusterresults\", dtype=\"dataframe\")\n",
    "props_df = am.select_datasets(\"cell_properties\", dtype=\"dataframe\")\n",
    "\n",
    "snr_df = SNRAnalysis(spots_df, props_df, clusters_df, abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "merged_spots_df, merged_clusters_df, merged_cellprops_df = snr_df.get_results()\n",
    "\n",
    "# Create an instance of the DUSP1Measurement class.\n",
    "dusp = DUSP1Measurement(merged_spots_df, merged_clusters_df, merged_cellprops_df)\n",
    "\n",
    "# Process the data with a chosen threshold method\n",
    "cell_level_results = dusp.measure(abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "# Add replica level unique IDs for 'unique_cell_id', 'unique_spot_id', and 'unique_cluster_id'\n",
    "# Get number of digits in the max unique_cell_id\n",
    "max_id = merged_cellprops_df['unique_cell_id'].max()\n",
    "num_digits = len(str(max_id))\n",
    "\n",
    "# Calculate multiplier to add a '1' followed by the right number of zeroes - prefix is specific for each experiment (e.g., repD:1, repE:2, etc.)\n",
    "rep_prefix = 11\n",
    "prefix = rep_prefix * (10** num_digits)  # e.g., if max_id = 30245 → prefix = 1100000\n",
    "\n",
    "# Apply prefix to all related DataFrames\n",
    "merged_spots_df['unique_cell_id'] += prefix\n",
    "merged_clusters_df['unique_cell_id'] += prefix\n",
    "merged_cellprops_df['unique_cell_id'] += prefix\n",
    "cell_level_results['unique_cell_id'] += prefix\n",
    "\n",
    "# Repeat for unique_spot_id and unique_cluster_id\n",
    "max_spot_id = merged_spots_df['unique_spot_id'].max()\n",
    "spot_prefix = rep_prefix ** len(str(max_spot_id))\n",
    "merged_spots_df['unique_spot_id'] += spot_prefix\n",
    "\n",
    "max_cluster_id = merged_clusters_df['unique_cluster_id'].max()\n",
    "cluster_prefix = rep_prefix ** len(str(max_cluster_id))\n",
    "merged_clusters_df['unique_cluster_id'] += cluster_prefix\n",
    "\n",
    "# Save all results to CSV\n",
    "rep_string = 'DUSP1_k_Final'\n",
    "output_dir = '/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/Classification'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "cell_level_results.to_csv(os.path.join(output_dir, f\"{rep_string}_cell_level_results_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_spots_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_spots_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_clusters_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_clusters_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_cellprops_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_cellprops_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "\n",
    "# instantiate sampler\n",
    "sampler = SpotCropSampler(\n",
    "    spots_df=merged_spots_df,\n",
    "    clusters_df=merged_clusters_df,\n",
    "    cellprops_df=merged_cellprops_df,\n",
    "    mount_prefix=\"/Volumes/share\"\n",
    ")\n",
    "\n",
    "# # — TEST RUN: only 3 displays, no files written —\n",
    "# crops, meta = sampler.run(\n",
    "#     save_dir=save_dir,\n",
    "#     display=3,\n",
    "#     save_individual=False,\n",
    "#     save_summary=False,\n",
    "#     pad=5,\n",
    "#     cells_per_quad=1,\n",
    "#     spots_per_cell=20,\n",
    "#     spotChannel=0\n",
    "# )\n",
    "\n",
    "# choose a prefix for this experiment\n",
    "prefix = f\"DUSP1_K_Final_MG3_Abs4\"\n",
    "\n",
    "# full run, no per-spot files, but summary files with prefix\n",
    "crops, meta = sampler.run(\n",
    "    save_dir=save_dir,\n",
    "    display=0,\n",
    "    save_individual=False,\n",
    "    save_summary=True,\n",
    "    file_prefix=prefix,\n",
    "    pad=5,\n",
    "    cells_per_quad=1,\n",
    "    spots_per_cell=20,\n",
    "    spotChannel=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67524882",
   "metadata": {},
   "source": [
    "    DUSP1 0.3, 1, 10nM Dex 3hr Time-sweep Replica 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5bc433",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = DUSP1AnalysisManager(location=loc, log_location=log_location, mac=True) \n",
    "am.select_analysis('DUSP1_L_Final')\n",
    "\n",
    "spots_df = am.select_datasets(\"spotresults\", dtype=\"dataframe\")\n",
    "clusters_df = am.select_datasets(\"clusterresults\", dtype=\"dataframe\")\n",
    "props_df = am.select_datasets(\"cell_properties\", dtype=\"dataframe\")\n",
    "\n",
    "snr_df = SNRAnalysis(spots_df, props_df, clusters_df, abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "merged_spots_df, merged_clusters_df, merged_cellprops_df = snr_df.get_results()\n",
    "\n",
    "# Create an instance of the DUSP1Measurement class.\n",
    "dusp = DUSP1Measurement(merged_spots_df, merged_clusters_df, merged_cellprops_df)\n",
    "\n",
    "# Process the data with a chosen threshold method\n",
    "cell_level_results = dusp.measure(abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "# Add replica level unique IDs for 'unique_cell_id', 'unique_spot_id', and 'unique_cluster_id'\n",
    "# Get number of digits in the max unique_cell_id\n",
    "max_id = merged_cellprops_df['unique_cell_id'].max()\n",
    "num_digits = len(str(max_id))\n",
    "\n",
    "# Calculate multiplier to add a '1' followed by the right number of zeroes - prefix is specific for each experiment (e.g., repD:1, repE:2, etc.)\n",
    "rep_prefix = 12\n",
    "prefix = rep_prefix * (10** num_digits)  # e.g., if max_id = 30245 → prefix = 100000\n",
    "\n",
    "# Apply prefix to all related DataFrames\n",
    "merged_spots_df['unique_cell_id'] += prefix\n",
    "merged_clusters_df['unique_cell_id'] += prefix\n",
    "merged_cellprops_df['unique_cell_id'] += prefix\n",
    "cell_level_results['unique_cell_id'] += prefix\n",
    "\n",
    "# Repeat for unique_spot_id and unique_cluster_id\n",
    "max_spot_id = merged_spots_df['unique_spot_id'].max()\n",
    "spot_prefix = rep_prefix ** len(str(max_spot_id))\n",
    "merged_spots_df['unique_spot_id'] += spot_prefix\n",
    "\n",
    "max_cluster_id = merged_clusters_df['unique_cluster_id'].max()\n",
    "cluster_prefix = rep_prefix ** len(str(max_cluster_id))\n",
    "merged_clusters_df['unique_cluster_id'] += cluster_prefix\n",
    "\n",
    "# Save all results to CSV\n",
    "rep_string = 'DUSP1_L_Final'\n",
    "output_dir = '/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/Classification'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "cell_level_results.to_csv(os.path.join(output_dir, f\"{rep_string}_cell_level_results_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_spots_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_spots_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_clusters_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_clusters_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_cellprops_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_cellprops_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "\n",
    "# instantiate sampler\n",
    "sampler = SpotCropSampler(\n",
    "    spots_df=merged_spots_df,\n",
    "    clusters_df=merged_clusters_df,\n",
    "    cellprops_df=merged_cellprops_df,\n",
    "    mount_prefix=\"/Volumes/share\"\n",
    ")\n",
    "\n",
    "# # — TEST RUN: only 3 displays, no files written —\n",
    "# crops, meta = sampler.run(\n",
    "#     save_dir=save_dir,\n",
    "#     display=3,\n",
    "#     save_individual=False,\n",
    "#     save_summary=False,\n",
    "#     pad=5,\n",
    "#     cells_per_quad=1,\n",
    "#     spots_per_cell=20,\n",
    "#     spotChannel=0\n",
    "# )\n",
    "\n",
    "# choose a prefix for this experiment\n",
    "prefix = f\"DUSP1_L_Final_MG3_Abs4\"\n",
    "\n",
    "# full run, no per-spot files, but summary files with prefix\n",
    "crops, meta = sampler.run(\n",
    "    save_dir=save_dir,\n",
    "    display=0,\n",
    "    save_individual=False,\n",
    "    save_summary=True,\n",
    "    file_prefix=prefix,\n",
    "    pad=5,\n",
    "    cells_per_quad=1,\n",
    "    spots_per_cell=20,\n",
    "    spotChannel=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1562b05b",
   "metadata": {},
   "source": [
    "    DUSP1 100nM Dex & 5µM TPL Time-sweep Replica 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3be592",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = DUSP1AnalysisManager(location=loc, log_location=log_location, mac=True) \n",
    "am.select_analysis('DUSP1_O_Final')\n",
    "\n",
    "spots_df = am.select_datasets(\"spotresults\", dtype=\"dataframe\")\n",
    "clusters_df = am.select_datasets(\"clusterresults\", dtype=\"dataframe\")\n",
    "props_df = am.select_datasets(\"cell_properties\", dtype=\"dataframe\")\n",
    "\n",
    "snr_df = SNRAnalysis(spots_df, props_df, clusters_df, abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "merged_spots_df, merged_clusters_df, merged_cellprops_df = snr_df.get_results()\n",
    "\n",
    "# Create an instance of the DUSP1Measurement class.\n",
    "dusp = DUSP1Measurement(merged_spots_df, merged_clusters_df, merged_cellprops_df)\n",
    "\n",
    "# Process the data with a chosen threshold method\n",
    "cell_level_results = dusp.measure(abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "# Add replica level unique IDs for 'unique_cell_id', 'unique_spot_id', and 'unique_cluster_id'\n",
    "# Get number of digits in the max unique_cell_id\n",
    "max_id = merged_cellprops_df['unique_cell_id'].max()\n",
    "num_digits = len(str(max_id))\n",
    "\n",
    "# Calculate multiplier to add a '1' followed by the right number of zeroes - prefix is specific for each experiment (e.g., repD:1, repE:2, etc.)\n",
    "rep_prefix = 13\n",
    "prefix = rep_prefix * (10** num_digits)  # e.g., if max_id = 30245 → prefix = 100000\n",
    "\n",
    "# Apply prefix to all related DataFrames\n",
    "merged_spots_df['unique_cell_id'] += prefix\n",
    "merged_clusters_df['unique_cell_id'] += prefix\n",
    "merged_cellprops_df['unique_cell_id'] += prefix\n",
    "cell_level_results['unique_cell_id'] += prefix\n",
    "\n",
    "# Repeat for unique_spot_id and unique_cluster_id\n",
    "max_spot_id = merged_spots_df['unique_spot_id'].max()\n",
    "spot_prefix = rep_prefix ** len(str(max_spot_id))\n",
    "merged_spots_df['unique_spot_id'] += spot_prefix\n",
    "\n",
    "max_cluster_id = merged_clusters_df['unique_cluster_id'].max()\n",
    "cluster_prefix = rep_prefix ** len(str(max_cluster_id))\n",
    "merged_clusters_df['unique_cluster_id'] += cluster_prefix\n",
    "\n",
    "# Save all results to CSV\n",
    "rep_string = 'DUSP1_O_Final'\n",
    "output_dir = '/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/Classification'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "cell_level_results.to_csv(os.path.join(output_dir, f\"{rep_string}_cell_level_results_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_spots_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_spots_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_clusters_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_clusters_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_cellprops_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_cellprops_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "\n",
    "# instantiate sampler\n",
    "sampler = SpotCropSampler(\n",
    "    spots_df=merged_spots_df,\n",
    "    clusters_df=merged_clusters_df,\n",
    "    cellprops_df=merged_cellprops_df,\n",
    "    mount_prefix=\"/Volumes/share\"\n",
    ")\n",
    "\n",
    "# # — TEST RUN: only 3 displays, no files written —\n",
    "# crops, meta = sampler.run(\n",
    "#     save_dir=save_dir,\n",
    "#     display=3,\n",
    "#     save_individual=False,\n",
    "#     save_summary=False,\n",
    "#     pad=5,\n",
    "#     cells_per_quad=1,\n",
    "#     spots_per_cell=20,\n",
    "#     spotChannel=0\n",
    "# )\n",
    "\n",
    "# choose a prefix for this experiment\n",
    "prefix = f\"DUSP1_O_Final_MG3_Abs4\"\n",
    "\n",
    "# full run, no per-spot files, but summary files with prefix\n",
    "crops, meta = sampler.run(\n",
    "    save_dir=save_dir,\n",
    "    display=0,\n",
    "    save_individual=False,\n",
    "    save_summary=True,\n",
    "    file_prefix=prefix,\n",
    "    pad=5,\n",
    "    cells_per_quad=1,\n",
    "    spots_per_cell=20,\n",
    "    spotChannel=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800091ac",
   "metadata": {},
   "source": [
    "    DUSP1 100nM Dex & 5µM TPL Time-sweep Replica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87ed789",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = DUSP1AnalysisManager(location=loc, log_location=log_location, mac=True) \n",
    "am.select_analysis('DUSP1_P_Final2')\n",
    "\n",
    "spots_df = am.select_datasets(\"spotresults\", dtype=\"dataframe\")\n",
    "clusters_df = am.select_datasets(\"clusterresults\", dtype=\"dataframe\")\n",
    "props_df = am.select_datasets(\"cell_properties\", dtype=\"dataframe\")\n",
    "\n",
    "snr_df = SNRAnalysis(spots_df, props_df, clusters_df, abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "merged_spots_df, merged_clusters_df, merged_cellprops_df = snr_df.get_results()\n",
    "\n",
    "# Create an instance of the DUSP1Measurement class.\n",
    "dusp = DUSP1Measurement(merged_spots_df, merged_clusters_df, merged_cellprops_df)\n",
    "\n",
    "# Process the data with a chosen threshold method\n",
    "cell_level_results = dusp.measure(abs_threshold=abs_threshold, mg_threshold=mg_threshold)\n",
    "\n",
    "# Add replica level unique IDs for 'unique_cell_id', 'unique_spot_id', and 'unique_cluster_id'\n",
    "# Get number of digits in the max unique_cell_id\n",
    "max_id = merged_cellprops_df['unique_cell_id'].max()\n",
    "num_digits = len(str(max_id))\n",
    "\n",
    "# Calculate multiplier to add a '1' followed by the right number of zeroes - prefix is specific for each experiment (e.g., repD:1, repE:2, etc.)\n",
    "rep_prefix = 14\n",
    "prefix = rep_prefix * (10** num_digits)  # e.g., if max_id = 30245 → prefix = 100000\n",
    "\n",
    "# Apply prefix to all related DataFrames\n",
    "merged_spots_df['unique_cell_id'] += prefix\n",
    "merged_clusters_df['unique_cell_id'] += prefix\n",
    "merged_cellprops_df['unique_cell_id'] += prefix\n",
    "cell_level_results['unique_cell_id'] += prefix\n",
    "\n",
    "# Repeat for unique_spot_id and unique_cluster_id\n",
    "max_spot_id = merged_spots_df['unique_spot_id'].max()\n",
    "spot_prefix = rep_prefix ** len(str(max_spot_id))\n",
    "merged_spots_df['unique_spot_id'] += spot_prefix\n",
    "\n",
    "max_cluster_id = merged_clusters_df['unique_cluster_id'].max()\n",
    "cluster_prefix = rep_prefix ** len(str(max_cluster_id))\n",
    "merged_clusters_df['unique_cluster_id'] += cluster_prefix\n",
    "\n",
    "# Save all results to CSV\n",
    "rep_string = 'DUSP1_P_Final'\n",
    "output_dir = '/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/Classification'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "cell_level_results.to_csv(os.path.join(output_dir, f\"{rep_string}_cell_level_results_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_spots_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_spots_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_clusters_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_clusters_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "merged_cellprops_df.to_csv(os.path.join(output_dir, f\"{rep_string}_merged_cellprops_df_MG{mg_threshold}_Abs{abs_threshold}_{date_str}.csv\"), index=False)\n",
    "\n",
    "# instantiate sampler\n",
    "sampler = SpotCropSampler(\n",
    "    spots_df=merged_spots_df,\n",
    "    clusters_df=merged_clusters_df,\n",
    "    cellprops_df=merged_cellprops_df,\n",
    "    mount_prefix=\"/Volumes/share\"\n",
    ")\n",
    "\n",
    "# # — TEST RUN: only 3 displays, no files written —\n",
    "# crops, meta = sampler.run(\n",
    "#     save_dir=save_dir,\n",
    "#     display=3,\n",
    "#     save_individual=False,\n",
    "#     save_summary=False,\n",
    "#     pad=5,\n",
    "#     cells_per_quad=1,\n",
    "#     spots_per_cell=20,\n",
    "#     spotChannel=0\n",
    "# )\n",
    "\n",
    "# choose a prefix for this experiment\n",
    "prefix = f\"DUSP1_P_Final_MG3_Abs4\"\n",
    "\n",
    "# full run, no per-spot files, but summary files with prefix\n",
    "crops, meta = sampler.run(\n",
    "    save_dir=save_dir,\n",
    "    display=0,\n",
    "    save_individual=False,\n",
    "    save_summary=True,\n",
    "    file_prefix=prefix,\n",
    "    pad=5,\n",
    "    cells_per_quad=1,\n",
    "    spots_per_cell=20,\n",
    "    spotChannel=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5509a497",
   "metadata": {},
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ce2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use interactive matplotlib backend\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a19174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650cab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualLabeler:\n",
    "    def __init__(self, crops_path, meta_path, output_path=None):\n",
    "        self.crops = np.load(crops_path)\n",
    "        self.meta = pd.read_csv(meta_path)\n",
    "        self.replica_name = os.path.basename(meta_path).replace(\"_all_crop_metadata.csv\", \"\")\n",
    "        self.output_path = output_path or meta_path.replace(\".csv\", \"_labeled.csv\")\n",
    "\n",
    "        if \"manual_label\" not in self.meta.columns:\n",
    "            self.meta[\"manual_label\"] = np.nan\n",
    "\n",
    "        self.batch_size = 25\n",
    "        self.current_idx = 0\n",
    "        self.fig, self.axes = None, None\n",
    "        self.rects = {}\n",
    "        self.labels = {}\n",
    "\n",
    "    def get_next_batch_indices(self):\n",
    "        return self.meta[self.meta[\"manual_label\"].isna()].index[:self.batch_size]\n",
    "\n",
    "    def onclick(self, event):\n",
    "        for i, ax in enumerate(self.axes.flat):\n",
    "            if event.inaxes == ax:\n",
    "                idx = self.indices[i]\n",
    "                if event.button == 1:\n",
    "                    self.labels[idx] = 1\n",
    "                elif event.button == 3:\n",
    "                    self.labels[idx] = 0\n",
    "                self.update_border(i, self.labels[idx])\n",
    "                break\n",
    "\n",
    "    def update_border(self, plot_idx, label):\n",
    "        ax = self.axes.flat[plot_idx]\n",
    "        if self.rects.get(plot_idx):\n",
    "            self.rects[plot_idx].remove()\n",
    "        color = \"green\" if label == 1 else \"red\"\n",
    "        self.rects[plot_idx] = ax.add_patch(Rectangle((0, 0), 1, 1, transform=ax.transAxes,\n",
    "                                                    fill=False, edgecolor=color, linewidth=3))\n",
    "        symbol = \"[SPOT]\" if label == 1 else \"[NOT]\"\n",
    "        idx = self.indices[plot_idx]\n",
    "        ax.set_title(f\"Idx {idx}\\n{symbol}\")\n",
    "        self.fig.canvas.draw_idle()\n",
    "\n",
    "    def label_batch(self):\n",
    "        self.indices = self.get_next_batch_indices()\n",
    "        if len(self.indices) == 0:\n",
    "            print(\"All crops labeled.\")\n",
    "            return\n",
    "\n",
    "        self.labels = {}\n",
    "        self.rects = {}\n",
    "\n",
    "        self.fig, self.axes = plt.subplots(5, 5, figsize=(10, 10))\n",
    "        self.fig.suptitle(f\"Replica: {self.replica_name}  |  Left Click = [SPOT]  |  Right Click = [NOT]\")\n",
    "        cid = self.fig.canvas.mpl_connect(\"button_press_event\", self.onclick)\n",
    "\n",
    "        for i, idx in enumerate(self.indices):\n",
    "            crop = self.crops[idx]\n",
    "            ax = self.axes.flat[i]\n",
    "            ax.imshow(crop, cmap=\"gray\")\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.set_title(f\"Idx {idx}\\nNo label\")\n",
    "\n",
    "        for j in range(len(self.indices), 25):\n",
    "            self.axes.flat[j].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # ✅ Wait for user confirmation in terminal/cell\n",
    "        input(\"👆 Done labeling? Press ENTER here to save and continue...\")\n",
    "\n",
    "        self.fig.canvas.mpl_disconnect(cid)\n",
    "        plt.close(self.fig)\n",
    "\n",
    "        labeled_count = 0\n",
    "        for plot_idx, ax in enumerate(self.axes.flat):\n",
    "            if plot_idx >= len(self.indices):\n",
    "                continue\n",
    "            crop_idx = self.indices[plot_idx]\n",
    "            if crop_idx in self.labels:\n",
    "                self.meta.at[crop_idx, \"manual_label\"] = self.labels[crop_idx]\n",
    "                labeled_count += 1\n",
    "\n",
    "        self.meta.to_csv(self.output_path, index=False)\n",
    "\n",
    "        if labeled_count > 0:\n",
    "            print(f\"✅ Saved {labeled_count} manual labels to: {self.output_path}\")\n",
    "        else:\n",
    "            print(\"⚠️ No labels were recorded. Did you click any crops?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc15257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "crops_path = \"/Volumes/share/Users/Eric/DUSP1_SpotCrops/DUSP1_D_Final_MG3_Abs4_all_crops.npy\"\n",
    "meta_path = \"/Volumes/share/Users/Eric/DUSP1_SpotCrops/DUSP1_D_Final_MG3_Abs4_all_crop_metadata.csv\"\n",
    "\n",
    "labeler = ManualLabeler(crops_path, meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34477f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler.label_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1280ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6229926652a440f7a89aa75488f94f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Test Button', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import Button\n",
    "from IPython.display import display\n",
    "\n",
    "btn = Button(description=\"Test Button\")\n",
    "\n",
    "def on_click(b):\n",
    "    print(\"✅ Button clicked!\")\n",
    "\n",
    "btn.on_click(on_click)\n",
    "display(btn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d338e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
