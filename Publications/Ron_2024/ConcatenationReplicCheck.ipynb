{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41294859",
   "metadata": {},
   "source": [
    "## DUSP1 Dataframe Concatenation and Replica Check\n",
    "- Concatenate experimental dataframes based on specific conditions:\n",
    "    - **100nM 3hr Time-Sweep (TS):** Data collected over a 3-hour time period with a fixed concentration of 100nM.\n",
    "    - **75min Concentration-Sweep:** Data collected over varying concentrations during a 75-minute time period.\n",
    "    - **3hr Time-Concentration Sweep (TCS):** Data collected over a 3-hour period with varying concentrations.\n",
    "    - **Triptiolide (TPL):** Data collected under conditions involving Triptiolide treatment.\n",
    "- Perform a replica check to ensure data consistency and identify any discrepancies across experimental replicates.\n",
    "- Document and visualize the concatenated data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd2852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import h5py\n",
    "import dask.array as da\n",
    "\n",
    "# src_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "# print(src_path)\n",
    "# sys.path.append(src_path)\n",
    "\n",
    "# from src.Analysis_DUSP1_v2 import DUSP1DisplayManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3b7662",
   "metadata": {},
   "source": [
    "## DUSP1 Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d7e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your directory\n",
    "df_directory = '/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/Classification'\n",
    "\n",
    "# Initialize containers\n",
    "spots_total = []\n",
    "clusters_total = []\n",
    "cellprops_total = []\n",
    "cellresults_total = []\n",
    "\n",
    "# List all files\n",
    "all_files = os.listdir(df_directory)\n",
    "\n",
    "# Sort files into categories\n",
    "for file in all_files:\n",
    "    filepath = os.path.join(df_directory, file)\n",
    "    \n",
    "    if file.endswith('merged_spots_df_MG3_Abs4_Apr24.csv'):\n",
    "        spots_total.append(pd.read_csv(filepath))\n",
    "    elif file.endswith('merged_clusters_df_MG3_Abs4_Apr24.csv'):\n",
    "        clusters_total.append(pd.read_csv(filepath))\n",
    "    elif file.endswith('merged_cellprops_df_MG3_Abs4_Apr24.csv'):\n",
    "        cellprops_total.append(pd.read_csv(filepath))\n",
    "    elif file.endswith('cell_level_results_MG3_Abs4_Apr24.csv'):\n",
    "        cellresults_total.append(pd.read_csv(filepath))\n",
    "\n",
    "# Concatenate into single DataFrames\n",
    "spots_total = pd.concat(spots_total, ignore_index=True)\n",
    "clusters_total = pd.concat(clusters_total, ignore_index=True)\n",
    "cellprops_total = pd.concat(cellprops_total, ignore_index=True)\n",
    "cellresults_total = pd.concat(cellresults_total, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the DUSP1 data\n",
    "DUSP1_data = cellresults_total.copy()\n",
    "\n",
    "# Experiment 1: 100 nM Dex time sweep with 12 timepoints\n",
    "df_expt1 = DUSP1_data[DUSP1_data['replica'].isin(['D', 'E', 'F', 'M', 'N'])]\n",
    "expt1_timepoints = [10, 20, 30, 40, 50, 60, 75, 90, 120, 150, 180]\n",
    "expt1_concs = [100]\n",
    "\n",
    "# Experiment 2: 75min concentration sweep with 8 concentrations\n",
    "df_expt2 = DUSP1_data[DUSP1_data['replica'].isin(['G', 'H', 'I'])]\n",
    "expt2_timepoints = [75]\n",
    "expt2_concs = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "# Experiment 3: 0.3, 1, 10nM Dex time sweep with 6 timepoints\n",
    "df_expt3 = DUSP1_data[DUSP1_data['replica'].isin(['J', 'K', 'L'])]\n",
    "expt3_timepoints = [30, 50, 75, 90, 120, 180]\n",
    "expt3_concs = [0.3, 1, 10]\n",
    "\n",
    "# Calculate means for each replica\n",
    "replica_means = DUSP1_data.groupby(['dex_conc', 'time', 'replica']).agg({\n",
    "    'nuc_MG_count': 'mean',\n",
    "    'cyto_MG_count': 'mean',\n",
    "    'MG_count': 'mean',\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate the mean and standard deviation of the replica means\n",
    "summary_stats = replica_means.groupby(['dex_conc', 'time']).agg({\n",
    "    'nuc_MG_count': ['mean', 'std'],\n",
    "    'cyto_MG_count': ['mean', 'std'],\n",
    "    'MG_count': ['mean', 'std'],\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for easier access\n",
    "summary_stats.columns = [\n",
    "    'dex_conc', 'time',\n",
    "    'mean_nuc_count', 'std_nuc_count',\n",
    "    'mean_cyto_count', 'std_cyto_count',\n",
    "    'mean_MG_count', 'std_MG_count'\n",
    "]\n",
    "\n",
    "# Calculate overall mean and standard deviation for each concentration and time point\n",
    "overall_stats = DUSP1_data.groupby(['dex_conc', 'time']).agg({\n",
    "    'nuc_MG_count': ['mean', 'std'],\n",
    "    'cyto_MG_count': ['mean', 'std'],\n",
    "    'MG_count': ['mean', 'std'],\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for easier access\n",
    "overall_stats.columns = [\n",
    "    'dex_conc', 'time',\n",
    "    'overall_mean_nuc', 'overall_std_nuc',\n",
    "    'overall_mean_cyto', 'overall_std_cyto',\n",
    "    'overall_mean_MG', 'overall_std_MG'\n",
    "]\n",
    "\n",
    "# Extract 0 min data (shared baseline from dex_conc == 0)\n",
    "zero_min_summary = summary_stats[summary_stats['time'] == 0]\n",
    "zero_min_overall = overall_stats[overall_stats['time'] == 0]\n",
    "\n",
    "# Set Style\n",
    "sns.set_theme(style=\"ticks\", palette=\"colorblind\", context=\"poster\", font='times new roman')\n",
    "\n",
    "# Define the color palette for Nuclear and Cytoplasmic intensities\n",
    "colors_nuc_cyto = sns.color_palette(\"colorblind\", 2)  # Two colors: one for Nuclear, one for Cytoplasmic\n",
    "\n",
    "# Loop through the three experiments\n",
    "experiments = {\n",
    "    \"Experiment 1: 100 nM Time Sweep\": (expt1_concs, expt1_timepoints),\n",
    "    # \"Experiment 2: 75 min Concentration Sweep\": (expt2_concs, expt2_timepoints),\n",
    "    \"Experiment 3: 0.3, 1, 10 nM Time Sweep\": (expt3_concs, expt3_timepoints)\n",
    "}\n",
    "\n",
    "for expt_name, (concs, timepoints) in experiments.items():\n",
    "    for conc in concs:\n",
    "        # Filter data for plotting\n",
    "        subset_summary = summary_stats[(summary_stats['dex_conc'] == conc) & (summary_stats['time'].isin(timepoints))]\n",
    "        subset_overall = overall_stats[(overall_stats['dex_conc'] == conc) & (overall_stats['time'].isin(timepoints))]\n",
    "\n",
    "        # Add 0 min time point to all subsets if not already present\n",
    "        if 0 not in subset_summary['time'].values:\n",
    "            subset_summary = pd.concat([zero_min_summary, subset_summary], ignore_index=True)\n",
    "        if 0 not in subset_overall['time'].values:\n",
    "            subset_overall = pd.concat([zero_min_overall, subset_overall], ignore_index=True)\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        # Plot Nuclear mRNA Count Mean with Error Bars\n",
    "        plt.errorbar(subset_summary['time'], subset_summary['mean_nuc_count'],\n",
    "                     yerr=subset_summary['std_nuc_count'], fmt='-o', color=colors_nuc_cyto[0], capsize=5,\n",
    "                     label='Nuclear mRNA Count Replicas')\n",
    "\n",
    "        # Filling between std deviations for overall data - Nuclear\n",
    "        plt.fill_between(subset_overall['time'],\n",
    "                         subset_overall['overall_mean_nuc'] - subset_overall['overall_std_nuc'],\n",
    "                         subset_overall['overall_mean_nuc'] + subset_overall['overall_std_nuc'],\n",
    "                         color=colors_nuc_cyto[0], alpha=0.2, label='Total Data Spread - Nuclear')\n",
    "\n",
    "        # Plot Cytoplasmic mRNA Count Mean with Error Bars\n",
    "        plt.errorbar(subset_summary['time'], subset_summary['mean_cyto_count'],\n",
    "                     yerr=subset_summary['std_cyto_count'], fmt='-o', color=colors_nuc_cyto[1], capsize=5,\n",
    "                     label='Cytoplasmic mRNA Count Replicas')\n",
    "\n",
    "        # Filling between std deviations for overall data - Cytoplasmic\n",
    "        plt.fill_between(subset_overall['time'],\n",
    "                         subset_overall['overall_mean_cyto'] - subset_overall['overall_std_cyto'],\n",
    "                         subset_overall['overall_mean_cyto'] + subset_overall['overall_std_cyto'],\n",
    "                         color=colors_nuc_cyto[1], alpha=0.2, label='Total Data Spread - Cytoplasmic')\n",
    "        \n",
    "        # Plot the total mRNA Count Mean with Error Bars\n",
    "        plt.errorbar(subset_summary['time'], subset_summary['mean_MG_count'],\n",
    "                    yerr=subset_summary['std_MG_count'], fmt='-o', color='black', capsize=5,\n",
    "                    label='Total mRNA Count Replicas')\n",
    "        # Filling between std deviations for overall data - Total\n",
    "# After\n",
    "        plt.fill_between(subset_overall['time'],\n",
    "                        subset_overall['overall_mean_MG'] - subset_overall['overall_std_MG'],\n",
    "                        subset_overall['overall_mean_MG'] + subset_overall['overall_std_MG'],\n",
    "                        color='black', alpha=0.2, label='Total Data Spread - Total')\n",
    "        # Set x-ticks to be the time points\n",
    "        plt.xticks(subset_summary['time'], rotation=45)\n",
    "\n",
    "        # Customize the plot\n",
    "        plt.title(f\"{expt_name} - {conc} nM Dex\", fontsize=18, fontweight='bold')\n",
    "        plt.xlabel('Time (min)', fontsize=14)\n",
    "        plt.ylabel('mRNA Spot Count', fontsize=14)\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='upper left', fontsize=12, frameon=False, bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83152449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the three experiments\n",
    "experiments = {\n",
    "    \"Experiment 1: 100 nM Time Sweep\": (expt1_concs, expt1_timepoints),\n",
    "    # \"Experiment 2: 75 min Concentration Sweep\": (expt2_concs, expt2_timepoints),\n",
    "    \"Experiment 3: 0.3, 1, 10 nM Time Sweep\": (expt3_concs, expt3_timepoints)\n",
    "}\n",
    "\n",
    "for expt_name, (concs, timepoints) in experiments.items():\n",
    "    for conc in concs:\n",
    "        # Filter data for plotting\n",
    "        subset_summary = summary_stats[(summary_stats['dex_conc'] == conc) & (summary_stats['time'].isin(timepoints))]\n",
    "        subset_overall = overall_stats[(overall_stats['dex_conc'] == conc) & (overall_stats['time'].isin(timepoints))]\n",
    "\n",
    "        # Add 0 min time point to all subsets if not already present\n",
    "        if 0 not in subset_summary['time'].values:\n",
    "            subset_summary = pd.concat([zero_min_summary, subset_summary], ignore_index=True)\n",
    "        if 0 not in subset_overall['time'].values:\n",
    "            subset_overall = pd.concat([zero_min_overall, subset_overall], ignore_index=True)\n",
    "\n",
    "        # Create figure with three horizontal subplots\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(20, 5), sharey=False)\n",
    "\n",
    "        # Plot configs\n",
    "        titles = ['Nuclear', 'Cytoplasmic', 'Total']\n",
    "        colors = [colors_nuc_cyto[0], colors_nuc_cyto[1], 'black']\n",
    "        means = ['mean_nuc_count', 'mean_cyto_count', 'mean_MG_count']\n",
    "        stds = ['std_nuc_count', 'std_cyto_count', 'std_MG_count']\n",
    "        overall_means = ['overall_mean_nuc', 'overall_mean_cyto', 'overall_mean_MG']\n",
    "        overall_stds = ['overall_std_nuc', 'overall_std_cyto', 'overall_std_MG']\n",
    "        labels = ['Nuclear mRNA Count Replicas', 'Cytoplasmic mRNA Count Replicas', 'Total mRNA Count Replicas']\n",
    "\n",
    "        for i, ax in enumerate(axes):\n",
    "            # Plot mean with error bars\n",
    "            ax.errorbar(subset_summary['time'], subset_summary[means[i]],\n",
    "                        yerr=subset_summary[stds[i]], fmt='-o', color=colors[i], capsize=5,\n",
    "                        label=labels[i])\n",
    "\n",
    "            # Plot shaded region (overall mean ± std)\n",
    "            ax.fill_between(subset_overall['time'],\n",
    "                            subset_overall[overall_means[i]] - subset_overall[overall_stds[i]],\n",
    "                            subset_overall[overall_means[i]] + subset_overall[overall_stds[i]],\n",
    "                            color=colors[i], alpha=0.2)\n",
    "\n",
    "            ax.set_title(titles[i], fontsize=16)\n",
    "            ax.set_xlabel('Time (min)')\n",
    "            ax.grid(True)\n",
    "            ax.set_xticks(subset_summary['time'])\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "            if i == 0:\n",
    "                ax.set_ylabel('mRNA Count')\n",
    "\n",
    "        # # Put a **single legend** outside to the right\n",
    "        # handles, labels = axes[0].get_legend_handles_labels()\n",
    "        # fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1.05, 0.5), frameon=False, fontsize=12)\n",
    "\n",
    "        # Adjust title:\n",
    "        if \"Experiment 3\" in expt_name:\n",
    "            fig.suptitle(f\"{conc} nM Dex\", fontsize=18, fontweight='bold')\n",
    "        else:\n",
    "            fig.suptitle(f\"{expt_name} - {conc} nM Dex\", fontsize=18, fontweight='bold')\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout(rect=[0, 0, 0.9, 0.95])  # Leave space for suptitle and legend\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8878087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "# Now handling Experiment 2 separately\n",
    "expt2_name = \"Experiment 2: 75 min Concentration Sweep\"\n",
    "concs = expt2_concs\n",
    "timepoints = expt2_timepoints\n",
    "\n",
    "# Set a small value for 0 concentration\n",
    "zero_conc_value = 1e-3  # small fake value to represent 0 on log axis\n",
    "\n",
    "for timepoint in timepoints:\n",
    "    # Full subset including 0 nM\n",
    "    subset_summary = summary_stats[(summary_stats['time'] == timepoint) & (summary_stats['dex_conc'].isin(concs))]\n",
    "    subset_overall = overall_stats[(overall_stats['time'] == timepoint) & (overall_stats['dex_conc'].isin(concs))]\n",
    "\n",
    "    # Modify 0 nM entries\n",
    "    subset_summary = subset_summary.copy()\n",
    "    subset_overall = subset_overall.copy()\n",
    "    subset_summary.loc[subset_summary['dex_conc'] == 0, 'dex_conc'] = zero_conc_value\n",
    "    subset_overall.loc[subset_overall['dex_conc'] == 0, 'dex_conc'] = zero_conc_value\n",
    "\n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 5), sharey=False)\n",
    "\n",
    "    # Plot configs\n",
    "    titles = ['Nuclear', 'Cytoplasmic', 'Total']\n",
    "    colors = [colors_nuc_cyto[0], colors_nuc_cyto[1], 'black']\n",
    "    means = ['mean_nuc_count', 'mean_cyto_count', 'mean_MG_count']\n",
    "    stds = ['std_nuc_count', 'std_cyto_count', 'std_MG_count']\n",
    "    overall_means = ['overall_mean_nuc', 'overall_mean_cyto', 'overall_mean_MG']\n",
    "    overall_stds = ['overall_std_nuc', 'overall_std_cyto', 'overall_std_MG']\n",
    "    labels = ['Nuclear mRNA Count Replicas', 'Cytoplasmic mRNA Count Replicas', 'Total mRNA Count Replicas']\n",
    "\n",
    "    # All tested concentrations (after replacing 0)\n",
    "    all_concs_for_ticks = [zero_conc_value, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "    # Define the matching labels\n",
    "    tick_labels = ['0', '1 pM', '10 pM', '100 pM', '1 nM', '10 nM', '100 nM', '1 µM', '10 µM']\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        # Plot mean with error bars\n",
    "        ax.errorbar(subset_summary['dex_conc'], subset_summary[means[i]],\n",
    "                    yerr=subset_summary[stds[i]], fmt='-o', color=colors[i], capsize=5,\n",
    "                    label=labels[i])\n",
    "\n",
    "        # Shaded region\n",
    "        ax.fill_between(subset_overall['dex_conc'],\n",
    "                        subset_overall[overall_means[i]] - subset_overall[overall_stds[i]],\n",
    "                        subset_overall[overall_means[i]] + subset_overall[overall_stds[i]],\n",
    "                        color=colors[i], alpha=0.2)\n",
    "\n",
    "        ax.set_title(titles[i], fontsize=16)\n",
    "        ax.set_xlabel('Dex Concentration')\n",
    "        ax.set_xscale('log')\n",
    "\n",
    "        # Set manual ticks and labels\n",
    "        ax.set_xlim(left=zero_conc_value/2, right=1.2e4)\n",
    "        ax.set_xticks(all_concs_for_ticks)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "\n",
    "        # Only major gridlines\n",
    "        ax.grid(True, which='major', axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "        # Remove gridline at fake 0\n",
    "        for line in ax.get_xgridlines():\n",
    "            if np.isclose(line.get_xdata()[0], zero_conc_value, rtol=1e-2):\n",
    "                line.set_visible(False)\n",
    "\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('mRNA Count')\n",
    "\n",
    "    # Title\n",
    "    fig.suptitle(f\"{expt2_name} - {timepoint} min\", fontsize=18, fontweight='bold')\n",
    "\n",
    "    # Layout\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d6872f",
   "metadata": {},
   "source": [
    "## Replica comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfb0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp, wasserstein_distance, rankdata\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f38c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise comparison function\n",
    "def compute_pairwise_comparisons(df, metrics_to_compare):\n",
    "    pairwise_results = []\n",
    "    unique_conditions = df[['time', 'dex_conc']].drop_duplicates().sort_values(by=['time', 'dex_conc']).values\n",
    "    \n",
    "    for time_val, conc_val in unique_conditions:\n",
    "        condition_df = df[(df['time'] == time_val) & (df['dex_conc'] == conc_val)]\n",
    "        replicas_present = condition_df['replica'].unique()\n",
    "        \n",
    "        if len(replicas_present) < 2:\n",
    "            continue  # skip if only 1 replica present\n",
    "        \n",
    "        for rep_a, rep_b in combinations(replicas_present, 2):\n",
    "            df_a = condition_df[condition_df['replica'] == rep_a]\n",
    "            df_b = condition_df[condition_df['replica'] == rep_b]\n",
    "            \n",
    "            for metric, column in metrics_to_compare:\n",
    "                values_a = df_a[column].values\n",
    "                values_b = df_b[column].values\n",
    "                \n",
    "                ks_stat, ks_pvalue = ks_2samp(values_a, values_b)\n",
    "                wass_dist = wasserstein_distance(values_a, values_b)\n",
    "                \n",
    "                pairwise_results.append({\n",
    "                    'Time_min': time_val,\n",
    "                    'Dex_conc_nM': conc_val,\n",
    "                    'Replica_A': rep_a,\n",
    "                    'Replica_B': rep_b,\n",
    "                    'Metric': metric,\n",
    "                    'KS_pvalue': ks_pvalue,\n",
    "                    'Wasserstein_distance': wass_dist,\n",
    "                    'Num_cells_A': len(values_a),\n",
    "                    'Num_cells_B': len(values_b)\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(pairwise_results)\n",
    "\n",
    "\n",
    "# Heatmap plotting function\n",
    "def plot_wasserstein_heatmap(pairwise_df, time_val, conc_val, metric):\n",
    "    subset = pairwise_df[(pairwise_df['Time_min'] == time_val) & \n",
    "                         (pairwise_df['Dex_conc_nM'] == conc_val) & \n",
    "                         (pairwise_df['Metric'] == metric)]\n",
    "    \n",
    "    replicas = np.unique(np.concatenate([subset['Replica_A'].unique(), subset['Replica_B'].unique()]))\n",
    "    replicas_sorted = sorted(replicas)\n",
    "    \n",
    "    dist_matrix = pd.DataFrame(np.nan, index=replicas_sorted, columns=replicas_sorted)\n",
    "    \n",
    "    for _, row in subset.iterrows():\n",
    "        a, b = row['Replica_A'], row['Replica_B']\n",
    "        dist = row['Wasserstein_distance']\n",
    "        dist_matrix.loc[a, b] = dist\n",
    "        dist_matrix.loc[b, a] = dist\n",
    "    \n",
    "    np.fill_diagonal(dist_matrix.values, 0)\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(dist_matrix, annot=True, fmt=\".1f\", cmap='viridis', cbar_kws={'label': 'Wasserstein Distance'})\n",
    "    plt.title(f\"Wasserstein Distance Heatmap\\nTime={time_val} min, Conc={conc_val} nM, Metric={metric}\")\n",
    "    plt.xlabel(\"Replica\")\n",
    "    plt.ylabel(\"Replica\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def generate_summary_table(pairwise_df, distance_threshold=40.0):\n",
    "    summary_rows = []\n",
    "    unique_conditions = pairwise_df[['Time_min', 'Dex_conc_nM']].drop_duplicates().values\n",
    "    \n",
    "    for time_val, conc_val in unique_conditions:\n",
    "        subset = pairwise_df[(pairwise_df['Time_min'] == time_val) & \n",
    "                             (pairwise_df['Dex_conc_nM'] == conc_val)]\n",
    "        for metric in subset['Metric'].unique():\n",
    "            metric_subset = subset[subset['Metric'] == metric]\n",
    "            \n",
    "            if len(metric_subset) == 0:\n",
    "                continue\n",
    "            \n",
    "            max_dist_row = metric_subset.loc[metric_subset['Wasserstein_distance'].idxmax()]\n",
    "            max_dist = max_dist_row['Wasserstein_distance']\n",
    "            replica_a = max_dist_row['Replica_A']\n",
    "            replica_b = max_dist_row['Replica_B']\n",
    "            \n",
    "            num_high_dist = (metric_subset['Wasserstein_distance'] > distance_threshold).sum()\n",
    "            total_comparisons = len(metric_subset)\n",
    "            \n",
    "            summary_rows.append({\n",
    "                'Time_min': time_val,\n",
    "                'Dex_conc_nM': conc_val,\n",
    "                'Metric': metric,\n",
    "                'Max_Wasserstein_distance': max_dist,\n",
    "                'Replica_A_Max': replica_a,\n",
    "                'Replica_B_Max': replica_b,\n",
    "                'Num_high_distance_pairs': num_high_dist,\n",
    "                'Total_pairs': total_comparisons\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(summary_rows)\n",
    "\n",
    "\n",
    "def plot_ecdf_per_replica(df, time_val, conc_val, metric_name, column_name):\n",
    "    subset = df[(df['time'] == time_val) & (df['dex_conc'] == conc_val)]\n",
    "    replicas_present = subset['replica'].unique()\n",
    "    \n",
    "    plt.figure(figsize=(7, 5))\n",
    "    \n",
    "    for replica in sorted(replicas_present):\n",
    "        replica_values = subset[subset['replica'] == replica][column_name].values\n",
    "        x = np.sort(replica_values)\n",
    "        y = np.arange(1, len(x)+1) / len(x)\n",
    "        plt.step(x, y, where='post', label=f'Replica {replica}')\n",
    "    \n",
    "    plt.xlabel(metric_name)\n",
    "    plt.ylabel('ECDF')\n",
    "    plt.title(f'ECDF per Replica\\nTime={time_val} min, Conc={conc_val} nM, Metric={metric_name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Identify outlier cells based on replica disagreement\n",
    "def identify_outlier_cells(df, pairwise_df, metrics_to_compare, distance_threshold=40.0, percentile_cutoff=5):\n",
    "    \"\"\"\n",
    "    Identify individual outlier cells based on replica disagreement.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): full dataframe of cells, must include 'unique_cell_id', 'replica', 'time', 'dex_conc', metric columns.\n",
    "        pairwise_df (pd.DataFrame): output of compute_pairwise_comparisons function.\n",
    "        metrics_to_compare (list): list of tuples, e.g. [('nuc', 'num_nuc_spots'), ...]\n",
    "        distance_threshold (float): minimum Wasserstein distance required to trigger analysis of a (time, conc, metric).\n",
    "        percentile_cutoff (float): percentile cutoff for outliers (default 5 → flags top/bottom 5%).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: table of outlier cells with columns:\n",
    "            unique_cell_id, replica, time, dex_conc, metric, cell_value, percentile_rank\n",
    "    \"\"\"\n",
    "    outlier_cells = []\n",
    "    unique_conditions = pairwise_df[['Time_min', 'Dex_conc_nM']].drop_duplicates().values\n",
    "    \n",
    "    for time_val, conc_val in unique_conditions:\n",
    "        subset_pairwise = pairwise_df[(pairwise_df['Time_min'] == time_val) & \n",
    "                                      (pairwise_df['Dex_conc_nM'] == conc_val)]\n",
    "        \n",
    "        for metric, column_name in metrics_to_compare:\n",
    "            metric_subset = subset_pairwise[subset_pairwise['Metric'] == metric]\n",
    "            \n",
    "            if len(metric_subset) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Check if this condition is \"outlier-worthy\"\n",
    "            max_dist = metric_subset['Wasserstein_distance'].max()\n",
    "            if max_dist < distance_threshold:\n",
    "                continue  # skip non-outlier condition\n",
    "            \n",
    "            # Now analyze this condition + metric\n",
    "            condition_df = df[(df['time'] == time_val) & (df['dex_conc'] == conc_val)]\n",
    "            replicas_present = condition_df['replica'].unique()\n",
    "            \n",
    "            for replica in replicas_present:\n",
    "                this_replica_values = condition_df[condition_df['replica'] == replica][column_name].values\n",
    "                this_replica_cells = condition_df[condition_df['replica'] == replica]['unique_cell_id'].values\n",
    "                \n",
    "                other_replicas_values = condition_df[condition_df['replica'] != replica][column_name].values\n",
    "                \n",
    "                if len(other_replicas_values) == 0:\n",
    "                    continue  # skip if no other replicas\n",
    "                \n",
    "                # Compute percentile rank for each cell\n",
    "                for cell_id, value in zip(this_replica_cells, this_replica_values):\n",
    "                    # Append value to consensus and rank it\n",
    "                    rank = rankdata(np.append(other_replicas_values, value))\n",
    "                    percentile_rank = 100.0 * (rank[-1] - 1) / len(other_replicas_values)\n",
    "                    \n",
    "                    # Check if this is an outlier\n",
    "                    if percentile_rank < percentile_cutoff or percentile_rank > (100 - percentile_cutoff):\n",
    "                        outlier_cells.append({\n",
    "                            'unique_cell_id': cell_id,\n",
    "                            'replica': replica,\n",
    "                            'time': time_val,\n",
    "                            'dex_conc': conc_val,\n",
    "                            'metric': metric,\n",
    "                            'cell_value': value,\n",
    "                            'percentile_rank': percentile_rank\n",
    "                        })\n",
    "    \n",
    "    return pd.DataFrame(outlier_cells)\n",
    "\n",
    "def compute_replica_stability(pairwise_df):\n",
    "    \"\"\"\n",
    "    Compute replica stability scores: mean Wasserstein distance of each replica\n",
    "    to other replicas, per (time, conc, metric).\n",
    "\n",
    "    Args:\n",
    "        pairwise_df (pd.DataFrame): output of compute_pairwise_comparisons.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: stability scores with columns:\n",
    "            Time_min, Dex_conc_nM, Metric, Replica, Mean_Wasserstein_distance, Num_pairs\n",
    "    \"\"\"\n",
    "    stability_rows = []\n",
    "    unique_conditions = pairwise_df[['Time_min', 'Dex_conc_NM'] if 'Dex_conc_NM' in pairwise_df.columns else 'Dex_conc_nM'].drop_duplicates().values\n",
    "    \n",
    "    # Backward compatibility in case Dex_conc_NM typo appears\n",
    "    conc_col = 'Dex_conc_NM' if 'Dex_conc_NM' in pairwise_df.columns else 'Dex_conc_nM'\n",
    "\n",
    "    for time_val, conc_val in unique_conditions:\n",
    "        subset = pairwise_df[(pairwise_df['Time_min'] == time_val) & \n",
    "                             (pairwise_df[conc_col] == conc_val)]\n",
    "        \n",
    "        for metric in subset['Metric'].unique():\n",
    "            metric_subset = subset[subset['Metric'] == metric]\n",
    "            \n",
    "            # Get all replicas involved\n",
    "            replicas = np.unique(np.concatenate([metric_subset['Replica_A'].unique(), \n",
    "                                                 metric_subset['Replica_B'].unique()]))\n",
    "            \n",
    "            for replica in replicas:\n",
    "                # Select all rows where this replica is Replica_A or Replica_B\n",
    "                is_rep_a = metric_subset['Replica_A'] == replica\n",
    "                is_rep_b = metric_subset['Replica_B'] == replica\n",
    "                replica_rows = metric_subset[is_rep_a | is_rep_b]\n",
    "                \n",
    "                mean_dist = replica_rows['Wasserstein_distance'].mean()\n",
    "                num_pairs = len(replica_rows)\n",
    "                \n",
    "                stability_rows.append({\n",
    "                    'Time_min': time_val,\n",
    "                    'Dex_conc_nM': conc_val,\n",
    "                    'Metric': metric,\n",
    "                    'Replica': replica,\n",
    "                    'Mean_Wasserstein_distance': mean_dist,\n",
    "                    'Num_pairs': num_pairs\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(stability_rows)\n",
    "\n",
    "def plot_replica_stability_heatmap(stability_df, metric_filter=None):\n",
    "    \"\"\"\n",
    "    Plot heatmap of replica stability scores.\n",
    "\n",
    "    Args:\n",
    "        stability_df (pd.DataFrame): output of compute_replica_stability.\n",
    "        metric_filter (str or None): if specified, only plot this metric (e.g. 'nuc'). If None, plot all.\n",
    "\n",
    "    Returns:\n",
    "        None (displays heatmap)\n",
    "    \"\"\"\n",
    "    df_plot = stability_df.copy()\n",
    "    \n",
    "    # Optional: filter by metric\n",
    "    if metric_filter is not None:\n",
    "        df_plot = df_plot[df_plot['Metric'] == metric_filter]\n",
    "    \n",
    "    # Create a composite column for columns\n",
    "    df_plot['Condition'] = df_plot.apply(lambda row: f\"T{int(row['Time_min'])}_C{row['Dex_conc_nM']}_M{row['Metric']}\", axis=1)\n",
    "    \n",
    "    # Pivot table: rows = replica, columns = condition, values = mean distance\n",
    "    pivot = df_plot.pivot_table(index='Replica', columns='Condition', values='Mean_Wasserstein_distance')\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(max(8, len(pivot.columns) * 0.6), max(5, len(pivot.index) * 0.5)))\n",
    "    sns.heatmap(pivot, annot=True, fmt=\".1f\", cmap='Reds', cbar_kws={'label': 'Mean Wasserstein Distance'})\n",
    "    plt.title(f\"Replica Stability Heatmap{' - Metric: ' + metric_filter if metric_filter else ''}\")\n",
    "    plt.xlabel(\"Condition (Time_min, Conc_nM, Metric)\")\n",
    "    plt.ylabel(\"Replica\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a25eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics to compare\n",
    "metrics_to_compare = [\n",
    "    ('nuc', 'num_nuc_spots'),\n",
    "    ('cyto', 'num_cyto_spots'),\n",
    "    ('ts', 'num_ts'),\n",
    "    ('foci', 'num_foci')\n",
    "]\n",
    "\n",
    "# Run the pairwise comparison\n",
    "pairwise_results_df = compute_pairwise_comparisons(df, metrics_to_compare)\n",
    "\n",
    "# Save pairwise results (optional)\n",
    "# pairwise_results_df.to_csv(\"pairwise_results.csv\", index=False)\n",
    "\n",
    "# Plot an example heatmap\n",
    "plot_wasserstein_heatmap(pairwise_results_df, time_val=75, conc_val=100.0, metric='nuc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3691470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the summary table\n",
    "summary_df = generate_summary_table(pairwise_results_df, distance_threshold=40.0)\n",
    "\n",
    "# Save summary (optional)\n",
    "# summary_df.to_csv(\"summary_table.csv\", index=False)\n",
    "\n",
    "# Show top conditions with max distance\n",
    "summary_df.sort_values(by='Max_Wasserstein_distance', ascending=False).head(10)\n",
    "\n",
    "# Example ECDF plot\n",
    "plot_ecdf_per_replica(df, time_val=75, conc_val=100.0, metric_name='num_nuc_spots', column_name='num_nuc_spots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the outlier cell identification\n",
    "outlier_cells_df = identify_outlier_cells(df, pairwise_results_df, metrics_to_compare, \n",
    "                                          distance_threshold=40.0, percentile_cutoff=5)\n",
    "\n",
    "# Save or inspect\n",
    "outlier_cells_df.to_csv(\"identified_outlier_cells.csv\", index=False)\n",
    "outlier_cells_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096a18d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "replica_stability_df = compute_replica_stability(pairwise_results_extended_df)\n",
    "\n",
    "# Sort to find unstable replicas\n",
    "replica_stability_df.sort_values(by='Mean_Wasserstein_distance', ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
