{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUSP1 Confirmation Notebook\n",
    "The purpose of this notebook is to:\n",
    "1. Confirm successful segmentation.\n",
    "2. Confirm successful BigFISH spot and cluster detection.\n",
    "3. Refine spots and clusters through additional filtering (SNR) for gating and final dataframe preparation:  \n",
    "    a. Test predefined SNR thresholds.  \n",
    "    b. Test weighted SNR tresholding    \n",
    "    c. Filter `df_spots` with snr threshold if needed.  \n",
    "    d. Create final dataframes ('df_cellspots').    \n",
    "    e. Save the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)\n",
    "\n",
    "matplotlib_logger = logging.getLogger('matplotlib')\n",
    "matplotlib_logger.setLevel(logging.WARNING)\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "print(src_path)\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.Analysis import AnalysisManager, Analysis, SpotDetection_SNRConfirmation, Spot_Cluster_Analysis_WeightedSNR, GR_Confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the log file to search for analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = None \n",
    "log_location = r'/Volumes/share/Users/Eric/AngelFISH_data'  #  r'/Volumes/share/Users/Jack/All_Analysis'\n",
    "am1 = AnalysisManager(location=loc, log_location=log_location, mac=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all analysis done \n",
    "all_analysis_names = am1.list_analysis_names()\n",
    "print(\"All discovered analyses:\", all_analysis_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUSP1 100nM Dex 3hr Time-sweep Replica 1\n",
    "am1.select_analysis('DUSP1_D_Jan2125')\n",
    "am1.list_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis/confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the class\n",
    "SD1 = Spot_Cluster_Analysis_WeightedSNR(am1)\n",
    "# Load the data\n",
    "SD1.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Segmentation, BF_spotdetection, SNR thresholding (basic and weighted), Summary Stats and plots\n",
    "SD1.display(newFOV=True, newCell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the data to remove partial cells and high-noise spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove partial cells from dataset\n",
    "SD1.cellprops = SD1.cellprops[SD1.cellprops['touching_border'] == 0]\n",
    "\n",
    "# Remove spots that are less than the weighted snr threshold\n",
    "SD1.spots = SD1.spots[SD1.spots['keep_wsnr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique cell id for every cell\n",
    "SD1.cellprops['unique_cell_id'] = np.arange(len(SD1.cellprops))\n",
    "\n",
    "# Merge the spots and clusters dataframes by the unique cell ID\n",
    "SD1.spots = SD1.spots.merge(SD1.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "SD1.clusters = SD1.clusters.merge(SD1.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(spots, clusters, props) -> pd.DataFrame:\n",
    "    results = pd.DataFrame(columns=['cell_id', 'num_ts', 'num_spots_ts', 'num_foci', 'num_spots_foci', 'num_spots', 'num_nuc_spots', 'num_cyto_spots', \n",
    "                                    'nuc_area_px', 'cyto_area_px', 'avg_nuc_int', 'avg_cyto_int', 'time', 'Dex_conc', 'replica'])\n",
    "    \n",
    "    # Sort spots, clusters, and props by unique_cell_id\n",
    "    spots = spots.sort_values(by='unique_cell_id')\n",
    "    clusters = clusters.sort_values(by='unique_cell_id')\n",
    "    props = props.sort_values(by='unique_cell_id')\n",
    "\n",
    "    # unique cell id\n",
    "    cell_ids = props['unique_cell_id']\n",
    "\n",
    "    # num of ts\n",
    "    num_ts = clusters[clusters['is_nuc'] == 1].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of foci\n",
    "    num_foci = clusters[clusters['is_nuc'] == 0].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of ts spots\n",
    "    num_spots_ts = clusters[clusters['is_nuc'] == 1].groupby('unique_cell_id')['nb_spots'].sum().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of foci spots\n",
    "    num_spots_foci = clusters[clusters['is_nuc'] == 0].groupby('unique_cell_id')['nb_spots'].sum().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of spots\n",
    "    num_spots = spots.groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of spot in nuc\n",
    "    num_nuc_spots = spots[spots['is_nuc'] == 1].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of spot in cyto \n",
    "    num_cyto_spots = spots[spots['is_nuc'] == 0].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # nuc area\n",
    "    nuc_area = props['nuc_area']\n",
    "\n",
    "    # cyto area\n",
    "    cyto_area = props['cyto_area']\n",
    "\n",
    "    # avg int nuc\n",
    "    avg_nuc_int = props['nuc_intensity_mean-0']\n",
    "    \n",
    "    # avg int cyto\n",
    "    avg_cyto_int = props['cyto_intensity_mean-0']\n",
    "\n",
    "    # time (experiment)\n",
    "    time = props['time'] \n",
    "\n",
    "    # Dex conc\n",
    "    dex_conc = props['Dex_Conc']\n",
    "\n",
    "    # Replica\n",
    "    replica = spots['replica']\n",
    "\n",
    "    results['cell_id'] = cell_ids\n",
    "    results['num_ts'] = num_ts.values\n",
    "    results['num_foci'] = num_foci.values\n",
    "    results['num_spots_ts'] = num_spots_ts.values\n",
    "    results['num_spots_foci'] = num_spots_foci.values\n",
    "    results['num_spots'] = num_spots.values\n",
    "    results['num_nuc_spots'] = num_nuc_spots.values\n",
    "    results['num_cyto_spots'] = num_cyto_spots.values\n",
    "    results['nuc_area_px'] = nuc_area.values\n",
    "    results['cyto_area_px'] = cyto_area.values\n",
    "    results['avg_nuc_int'] = avg_nuc_int.values\n",
    "    results['avg_cyto_int'] = avg_cyto_int.values\n",
    "    results['time'] = time.values\n",
    "    results['Dex_conc'] = dex_conc.values\n",
    "    results['replica'] = replica.values\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUSP1_TS_R1_df = measure(SD1.spots, SD1.clusters, SD1.cellprops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure num_spots = num_nuc_spots + num_cyto_spots for all rows\n",
    "assert (DUSP1_TS_R1_df['num_spots'] == DUSP1_TS_R1_df['num_nuc_spots'] + DUSP1_TS_R1_df['num_cyto_spots']).all(), \"Mismatch in spot counts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUSP1_TS_R1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move to section before removing cells \n",
    "\n",
    "# SD1.cellspots = SD1.cellspots.merge(SD1.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "#                                     left_on=['NAS_location', 'cell_id', 'fov'], \n",
    "#                                     right_on=['NAS_location', 'cell_label', 'fov'], \n",
    "#                                     how='left')\n",
    "\n",
    "\n",
    "# # Align indices before performing the assertion\n",
    "# if 'cell_id' in DUSP1_TS_R1_df.keys():\n",
    "#     DUSP1_TS_R1_df = DUSP1_TS_R1_df.set_index('cell_id')\n",
    "\n",
    "# if 'unique_cell_id' in SD1.cellspots.keys():\n",
    "#     SD1.cellspots = SD1.cellspots.set_index('unique_cell_id')\n",
    "\n",
    "# aligned_nb_rna = SD1.cellspots['nb_rna']\n",
    "\n",
    "# aligned_num_spots = DUSP1_TS_R1_df['num_spots']\n",
    "# aligned_num_spots = aligned_num_spots - DUSP1_TS_R1_df['num_spots_ts']\n",
    "\n",
    "# # Ensure aligned_num_spots only contains indices present in aligned_nb_rna\n",
    "# aligned_num_spots = aligned_num_spots.loc[SD1.cellspots.index]\n",
    "\n",
    "# not_close_indices = np.where(~np.isclose(aligned_nb_rna, aligned_num_spots, rtol = 0.05))[0]\n",
    "# print(\"Indices where nb_rna and num_spots are not close:\", len(not_close_indices))\n",
    "\n",
    "# assert len(not_close_indices) == 0, \"Mismatch in nb_rna and num_spots counts\"\n",
    "\n",
    "\n",
    "# print(f\"{'cell_id':<10} {'my counting':<30} {'bigfish counting':<30} {'corrected':<30} {'ts spots':<30} {'foci spots':<30}\")\n",
    "# for cell_id, my, bf, cr, ts, foci in zip(aligned_nb_rna.iloc[not_close_indices].index, cell_spots.loc[aligned_nb_rna.index]['num_spots'].iloc[not_close_indices], \n",
    "#                                          aligned_nb_rna.iloc[not_close_indices], aligned_num_spots.iloc[not_close_indices], \n",
    "#                                          cell_spots.loc[aligned_nb_rna.index]['num_spots_ts'].iloc[not_close_indices], cell_spots.loc[aligned_nb_rna.index]['num_spots_foci'].iloc[not_close_indices] ):\n",
    "#     print(f\"{cell_id:<10} {my:<30} {bf:<30} {cr:<30} {ts:<30} {foci:<30}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "am1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
