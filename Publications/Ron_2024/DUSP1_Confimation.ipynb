{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUSP1 Confirmation Notebook\n",
    "The purpose of this notebook is to:\n",
    "1. Confirm successful segmentation.\n",
    "2. Confirm successful BigFISH spot and cluster detection.\n",
    "3. Refine spots and clusters through additional filtering (SNR) for gating and final dataframe preparation (determine if best before or after total concatenation):  \n",
    "    a. Find SNR threshold.  \n",
    "    b. Filter `df_spots`.  \n",
    "    c. (Optional) Check to see if removed spot was in a cluster (very unlikely due to how clusters are defined).  \n",
    "    d. Create final dataframes (`df_spots`, `df_clusters`, `df_cellspots`, `df_cellprops`).  \n",
    "    e. Save the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)\n",
    "\n",
    "matplotlib_logger = logging.getLogger('matplotlib')\n",
    "matplotlib_logger.setLevel(logging.WARNING)\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "print(src_path)\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.Analysis import AnalysisManager, Analysis, SpotDetection_SNRConfirmation, Spot_Cluster_Analysis_WeightedSNR, GR_Confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads in the data from specified location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = None \n",
    "log_location = r'/Volumes/share/Users/Eric/AngelFISH_data'  #  r'/Volumes/share/Users/Jack/All_Analysis'\n",
    "am = AnalysisManager(location=loc, log_location=log_location, mac=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all analysis done \n",
    "am.list_analysis_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can filter on naDe and dates\n",
    "am.select_analysis('DUSP1_D_Jan2125')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(am.analysis_names)\n",
    "am.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am.list_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does analysis/confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select DUSP1 spot detection\n",
    "# SD = SpotDetection_Confirmation(am)\n",
    "SD = Spot_Cluster_Analysis_WeightedSNR(am)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loads the data into memory \n",
    "SD.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this multiple times to see a new randomly selected cell\n",
    "SD.display(newFOV=True, newCell=True) # num_fovs_to_display=2,num_cells_to_display=2, num_spots_to_display=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spots = pd.DataFrame(SD.spots)\n",
    "df_clusters = pd.DataFrame(SD.clusters)\n",
    "df_cellspots = pd.DataFrame(SD.cellspots)\n",
    "df_cellprops = pd.DataFrame(SD.cellprops)\n",
    "\n",
    "# Print columns for each dataframe\n",
    "print(\"df_spots columns:\")\n",
    "print(\", \".join(df_spots.columns))\n",
    "\n",
    "print(\"\\ndf_clusters columns:\")\n",
    "print(\", \".join(df_clusters.columns))\n",
    "\n",
    "print(\"\\ndf_cellspots columns:\")\n",
    "print(\", \".join(df_cellspots.columns))\n",
    "\n",
    "print(\"\\ndf_cellprops columns:\")\n",
    "print(\", \".join(df_cellprops.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of timepoints in the dataset\n",
    "print(df_spots['time'].unique())\n",
    "print(df_spots['h5_idx'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics for all times\n",
    "stats = df_spots.groupby('time')['snr'].agg(['mean', 'median', 'std'])\n",
    "\n",
    "# Dynamic SNR thresholding based on mean Â± 2*std\n",
    "thresholds = {}\n",
    "for time, row in stats.iterrows():\n",
    "    thresholds[time] = (row['mean'] - 2 * row['std'], row['mean'] + 2 * row['std'])\n",
    "\n",
    "# Apply dynamic thresholding\n",
    "df_spots['threshold_pass'] = df_spots.apply(\n",
    "    lambda row: thresholds[row['time']][0] <= row['snr'] <= thresholds[row['time']][1],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Filtered DataFrame\n",
    "df_spots_filtered = df_spots[df_spots['threshold_pass']]\n",
    "\n",
    "# Categorize noise levels based on the paper's description\n",
    "def categorize_noise(snr):\n",
    "    if snr < 2:\n",
    "        return 'very_high_noise'\n",
    "    if 2 <= snr < 5:\n",
    "        return 'snr:2-5'\n",
    "    elif 8 <= snr <= 26:\n",
    "        return 'snr:8-26'\n",
    "    elif snr > 26:\n",
    "        return 'snr>26'\n",
    "    else:\n",
    "        return 'did this work?'\n",
    "\n",
    "df_spots['noise_level'] = df_spots['snr'].apply(categorize_noise)\n",
    "\n",
    "# Plot histograms of SNR for each time\n",
    "for time, group in df_spots.groupby('time'):\n",
    "    mean_snr = group['snr'].mean()\n",
    "    median_snr = group['snr'].median()\n",
    "    std_snr = group['snr'].std()\n",
    "    \n",
    "    plt.hist(group['snr'], bins=50, alpha=0.7, label=f'time: {time}')\n",
    "    plt.axvline(mean_snr, color='b', linestyle='dashed', linewidth=1, label=f'Mean: {mean_snr:.2f}')\n",
    "    plt.axvline(median_snr, color='g', linestyle='dashed', linewidth=1, label=f'Median: {median_snr:.2f}')\n",
    "    plt.title(f'SNR Histogram for time {time}min')\n",
    "    plt.xlabel('SNR')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Scatter Plot of Intensity vs SNR\n",
    "plt.scatter(df_spots['signal'], df_spots['snr'], s=1, alpha=0.7)\n",
    "plt.xlabel('Intensity')\n",
    "plt.ylabel('SNR')\n",
    "plt.title('Intensity vs SNR (All Spots)')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "# Noise Level Distribution\n",
    "noise_level_counts = df_spots['noise_level'].value_counts()\n",
    "plt.bar(noise_level_counts.index, noise_level_counts.values, alpha=0.7)\n",
    "plt.title('Noise Level Distribution')\n",
    "plt.xlabel('Noise Level')\n",
    "plt.ylabel('Spot Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spots_filtered = df_spots[(df_spots['cell_label'] > 0)] # & (df_spots['cluster_index'] > -1)]\n",
    "print(len(df_spots_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = pd.DataFrame(SD.clusters)\n",
    "df_clusters.columns\n",
    "df_clusters_filtered = df_clusters[(df_clusters['is_nuc'] > 0)]\n",
    "print(len(df_clusters_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters['is_nuc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD.cellprops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(SD.cellprops) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cellspots = pd.DataFrame(SD.cellspots)\n",
    "df_cellspots.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_TS = df_cellspots[(df_cellspots['nb_transcription_site'] > 0)]\n",
    "print(len(num_TS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find cells that have props but arent in the cell spots\n",
    "allcells = SD.cellprops\n",
    "cells_wSpots = SD.cellspots\n",
    "# Find cells that are in allcells but not in cells_wSpots\n",
    "merged = allcells.merge(cells_wSpots, how='left', left_on=['nuc_label', 'fov', 'NAS_location'], right_on=['cell_id', 'fov', 'NAS_location'], indicator=True)\n",
    "print(merged.shape)\n",
    "same_entries = merged[merged['_merge'] == 'both'].drop(columns=['cell_id', '_merge'])\n",
    "different_entries = merged[merged['_merge'] == 'left_only'].drop(columns=['cell_id', '_merge'])\n",
    "\n",
    "print(\"Same entries:\")\n",
    "print(same_entries.shape)\n",
    "print(\"\\nDifferent entries:\")\n",
    "print(different_entries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import dask.array as da\n",
    "print(f'There are {allcells.shape[0]} cells in this data set')\n",
    "print(f'There are {cells_wSpots.shape[0]} cells with spots')\n",
    "\n",
    "# how many are have bounded boxes touching the border\n",
    "print(f'{different_entries['touching_border'].sum()} cells are touching the border and are not counted')\n",
    "\n",
    "# Select a random row from the different_entries dataframe\n",
    "for _ in range(2):\n",
    "    random_row = different_entries[~different_entries['touching_border']].sample(n=1).iloc[0]\n",
    "\n",
    "    # Read the h5 file\n",
    "    h5_file = random_row['NAS_location']\n",
    "    h5_file = os.path.join(r'\\\\munsky-nas.engr.colostate.edu\\share', h5_file) # TODO this will need to be updated so you dont have to find it to get it to work\n",
    "    with h5py.File(h5_file, 'r') as f:\n",
    "        # Grab the mask and raw_image\n",
    "        masks = da.from_array(f['/masks'])\n",
    "        raw_images = da.from_array(f['/raw_images'])\n",
    "\n",
    "        # Extract the bounding box coordinates\n",
    "        bbox = [random_row['cell_bbox-0'], random_row['cell_bbox-1'], random_row['cell_bbox-2'], random_row['cell_bbox-3']]\n",
    "\n",
    "        img = raw_images[random_row['fov'], random_row['timepoint_x']].squeeze()\n",
    "        for c in range(img.shape[0]):\n",
    "            # Display the raw image with the selected cell highlighted\n",
    "            t = np.max(img[c, :, :,:], axis=0)\n",
    "            t.compute()\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "            ax.imshow(t, cmap='gray')\n",
    "            rect = plt.Rectangle((bbox[1], bbox[0]), bbox[3] - bbox[1], bbox[2] - bbox[0], edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of spots\n",
    "keys_to_plot = ['signal', 'snr']\n",
    "for k in SD.spots.keys():\n",
    "    if k in keys_to_plot:\n",
    "        # Plot histogram for 'area'\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.hist(SD.spots[k], bins=200, density=True)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title(f'Histogram of {k}')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD.cellspots.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spot counts as a function of time and dex\n",
    "keys_to_plot = ['nb_rna', 'nb_rna_in_nuc']\n",
    "\n",
    "\n",
    "tp_set = sorted(set(SD.cellspots['time']))\n",
    "dex_set = sorted(set(SD.cellspots['Dex_Conc']))\n",
    "for k in keys_to_plot:\n",
    "    fig, axs = plt.subplots(len(tp_set), len(dex_set), figsize=(15, 15))\n",
    "    fig.suptitle(f'{k} as a function of time and dex', fontsize=16)\n",
    "    for i_d, d in enumerate(dex_set):\n",
    "        data = SD.cellspots[SD.cellspots['Dex_Conc'] == d]\n",
    "        for i_t, t in enumerate(tp_set):\n",
    "            temp = data[data['time'] == t]\n",
    "            mean_val = temp[k].mean()\n",
    "            std_val = temp[k].std()\n",
    "            if d == 0 and t == 0:\n",
    "                for ax in axs[i_t, :]:\n",
    "                    ax.hist(temp[k], bins=200, density=True)\n",
    "                    ax.axvline(mean_val, color='r', linestyle='solid', linewidth=2)\n",
    "                    ax.axvline(mean_val + std_val, color='g', linestyle='dashed', linewidth=1)\n",
    "                    ax.axvline(mean_val - std_val, color='g', linestyle='dashed', linewidth=1)\n",
    "                    ax.set_xlim([0, SD.cellspots[k].max()])\n",
    "                    ax.grid(True)  # Turn on grid lines\n",
    "                    if i_t != len(tp_set) - 1:\n",
    "                        axs[i_t, i_d].set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "                axs[i_t, 0].set_ylabel(f'Time: {t}')\n",
    "            else:\n",
    "                axs[i_t, i_d].hist(temp[k], bins=200, density=True)\n",
    "                axs[i_t, i_d].axvline(mean_val, color='r', linestyle='solid', linewidth=2)\n",
    "                axs[i_t, i_d].axvline(mean_val + std_val, color='g', linestyle='dashed', linewidth=1)\n",
    "                axs[i_t, i_d].axvline(mean_val - std_val, color='g', linestyle='dashed', linewidth=1)\n",
    "                axs[i_t, i_d].set_xlim([0, SD.cellspots[k].max()])\n",
    "                axs[i_t, i_d].grid(True)  # Turn on grid lines\n",
    "                if i_t != len(tp_set) - 1:\n",
    "                    axs[i_t, i_d].set_xticks([])\n",
    "                axs[i_t, i_d].set_yticks([])\n",
    "                axs[i_t, 0].set_ylabel(f'Time: {t}')\n",
    "                axs[0, i_d].set_title(f'Dex: {d}')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
