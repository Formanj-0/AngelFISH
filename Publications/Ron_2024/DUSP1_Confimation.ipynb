{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUSP1 Confirmation Notebook\n",
    "The purpose of this notebook is to:\n",
    "1. Confirm successful segmentation.\n",
    "2. Confirm successful BigFISH spot and cluster detection.\n",
    "3. Refine spots and clusters through additional filtering (SNR) for gating and final dataframe preparation:  \n",
    "    a. Test predefined SNR thresholds.  \n",
    "    b. Test weighted SNR tresholding    \n",
    "    c. Filter `df_spots` with snr threshold if needed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)\n",
    "\n",
    "matplotlib_logger = logging.getLogger('matplotlib')\n",
    "matplotlib_logger.setLevel(logging.WARNING)\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "print(src_path)\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.Analysis import AnalysisManager, Analysis, SpotDetection_SNRConfirmation, Spot_Cluster_Analysis_WeightedSNR, GR_Confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the log file to search for analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = None \n",
    "log_location = r'/Volumes/share/Users/Eric/GR_DUSP1_2025'  #  r'/Volumes/share/Users/Jack/All_Analysis'\n",
    "am = AnalysisManager(location=loc, log_location=log_location, mac=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all analysis done \n",
    "all_analysis_names = am.list_analysis_names()\n",
    "all_analysis_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUSP1 Experiment Analysis List\n",
    "\n",
    "### DUSP1 100nM Dex 3hr Time-sweep\n",
    "- Replica D: `Analysis_DUSP1_D_JacksRunAll_2025-02-05`\n",
    "- Replica E: `Analysis_DUSP1_E_ERonRunAll_2025-02-06`\n",
    "- Replica F: `Analysis_DUSP1_F_ERonReRun_2025-02-08`\n",
    "- Replica M: `Analysis_DUSP1_M_ERonRunAll_2025-02-06`\n",
    "- Replica N: `Analysis_DUSP1_N_JacksRunAll_2025-02-06`\n",
    "\n",
    "### DUSP1 75min Concentration-sweep\n",
    "- Replica G: `Analysis_DUSP1_G_ERonReRun_2025-02-08`\n",
    "- Replica H: `Analysis_DUSP1_H_ERonRunAll_2025-02-06`\n",
    "- Replica I: `Analysis_DUSP1_I_JacksRunAll_2025-02-06`\n",
    "\n",
    "### DUSP1 0.3, 1, 10nM Dex 3hr Time-sweep\n",
    "- Replica J: `Analysis_DUSP1_J_ERonRunAll_2025-02-06`\n",
    "- Replica K: `Analysis_DUSP1_K_ERonReRun_2025-02-08`\n",
    "- Replica L: `Analysis_DUSP1_L_JacksRunAll_2025-02-06`\n",
    "\n",
    "### DUSP1 TPL\n",
    "- Replica O `Analysis_DUSP1_O_JacksRunAll_2025-02-06`\n",
    "- Replica P `Analysis_DUSP1_P_ERonReRun_2025-02-08`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # DUSP1 100nM Dex 3hr Time-sweep Replica 1\n",
    "# am.select_analysis('DUSP1_D_JacksRunAll')\n",
    "# # DUSP1 100nM Dex 3hr Time-sweep Replica 2\n",
    "# am.select_analysis('DUSP1_E_ERonRunAll')\n",
    "# # DUSP1 100nM Dex 3hr Time-sweep Replica 3\n",
    "# am.select_analysis('DUSP1_F_JacksRunAll')\n",
    "# # DUSP1 100nM Dex 3hr Time-sweep Replica 4\n",
    "# am.select_analysis('DUSP1_M_ERonRunAll')\n",
    "# # DUSP1 100nM Dex 3hr Time-sweep Replica 5\n",
    "# am.select_analysis('DUSP1_N_JacksRunAll')\n",
    "\n",
    "# # DUSP1 75min Concentration-sweep Replica 1\n",
    "# am.select_analysis('DUSP1_G_JacksRunAll')\n",
    "# # DUSP1 75min Concentration-sweep Replica 2\n",
    "# am.select_analysis('DUSP1_H_ERonRunAll')\n",
    "# # DUSP1 75min Concentration-sweep Replica 3\n",
    "# am.select_analysis('DUSP1_I_JacksRunAll')\n",
    "\n",
    "# # DUSP1 0.3, 1, 10nM Dex 3hr Time-sweep Replica 1\n",
    "# am.select_analysis('DUSP1_J_ERonRunAll')\n",
    "# # DUSP1 0.3, 1, 10nM Dex 3hr Time-sweep Replica 2\n",
    "# am.select_analysis('DUSP1_K_ERonReRun')\n",
    "# # DUSP1 0.3, 1, 10nM Dex 3hr Time-sweep Replica 2\n",
    "# am.select_analysis('DUSP1_L_JacksRunAll')\n",
    "\n",
    "# DUSP1 Dex Tpl replica 1\n",
    "# am.select_analysis('DUSP1_O_JacksRunAll')\n",
    "# DUSP1 Dex Tpl replica 2\n",
    "# am.select_analysis('DUSP1_P_ERonReRun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis/confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the class\n",
    "SD = Spot_Cluster_Analysis_WeightedSNR(am)\n",
    "# Load the data\n",
    "SD.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD.cellprops['NAS_location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Segmentation, BF_spotdetection, SNR thresholding (basic and weighted), Summary Stats and plots\n",
    "SD.display(newFOV=True, newCell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate DUSP1 spots, clusters, cellspots, and cellprops dataframe agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique cell id for every cell\n",
    "SD.cellprops['unique_cell_id'] = np.arange(len(SD.cellprops))\n",
    "\n",
    "# Merge the spots and clusters dataframes by the unique cell ID\n",
    "SD.spots = SD.spots.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "SD.clusters = SD.clusters.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD.spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the second largest value or default to 0\n",
    "def second_largest(series):\n",
    "    unique_vals = series.dropna().unique()  # Remove NaN and get unique values\n",
    "    if len(unique_vals) < 2:\n",
    "        return 0  # Return 0 if there's no second-largest value\n",
    "    return np.sort(unique_vals)[-2]  # Return the second-largest value\n",
    "\n",
    "\n",
    "def measure_DUSP1(spots, clusters, props) -> pd.DataFrame:\n",
    "    results = pd.DataFrame(columns=['cell_id', 'num_ts', 'num_spots_ts', 'largest_ts', 'second_largest_ts', 'num_foci', 'num_spots_foci', 'num_spots', 'num_nuc_spots', 'num_cyto_spots', \n",
    "                                    'nuc_area_px', 'cyto_area_px', 'avg_nuc_int', 'avg_cyto_int', 'time', 'Dex_conc', 'replica'])\n",
    "    \n",
    "    # Sort spots, clusters, and props by unique_cell_id\n",
    "    spots = spots.sort_values(by='unique_cell_id')\n",
    "    clusters = clusters.sort_values(by='unique_cell_id')\n",
    "    props = props.sort_values(by='unique_cell_id')\n",
    "\n",
    "    # unique cell id\n",
    "    cell_ids = props['unique_cell_id']\n",
    "\n",
    "    # num of ts\n",
    "    num_ts = clusters[clusters['is_nuc'] == 1].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of foci\n",
    "    num_foci = clusters[clusters['is_nuc'] == 0].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of ts spots\n",
    "    num_spots_ts = clusters[clusters['is_nuc'] == 1].groupby('unique_cell_id')['nb_spots'].sum().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # largest TS size\n",
    "    largest_ts = clusters[clusters['is_nuc'] == 1].groupby('unique_cell_id')['nb_spots'].max().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # Compute second-largest TS size per cell\n",
    "    second_largest_ts = (clusters[clusters['is_nuc'] == 1].groupby('unique_cell_id')['nb_spots'].apply(second_largest).reindex(cell_ids, fill_value=0))    \n",
    "\n",
    "    # num of foci spots\n",
    "    num_spots_foci = clusters[clusters['is_nuc'] == 0].groupby('unique_cell_id')['nb_spots'].sum().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of spots\n",
    "    num_spots = spots.groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of spot in nuc\n",
    "    num_nuc_spots = spots[spots['is_nuc'] == 1].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of spot in cyto \n",
    "    num_cyto_spots = spots[spots['is_nuc'] == 0].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # nuc area\n",
    "    nuc_area = props['nuc_area']\n",
    "\n",
    "    # cyto area\n",
    "    cyto_area = props['cyto_area']\n",
    "\n",
    "    # avg int nuc\n",
    "    avg_nuc_int = props['nuc_intensity_mean-0']\n",
    "    \n",
    "    # avg int cyto\n",
    "    avg_cyto_int = props['cyto_intensity_mean-0']\n",
    "\n",
    "    # time (experiment)\n",
    "    time = props['time'] \n",
    "\n",
    "    # Dex conc\n",
    "    dex_conc = props['Dex_Conc']\n",
    "\n",
    "    # Replica\n",
    "    replica = spots.groupby('unique_cell_id')['replica'].first().reindex(cell_ids, fill_value=np.nan)\n",
    "\n",
    "    results['cell_id'] = cell_ids\n",
    "    results['num_ts'] = num_ts.values\n",
    "    results['largest_ts'] = largest_ts.values\n",
    "    results['second_largest_ts'] = second_largest_ts.values\n",
    "    results['num_foci'] = num_foci.values\n",
    "    results['num_spots_ts'] = num_spots_ts.values\n",
    "    results['num_spots_foci'] = num_spots_foci.values\n",
    "    results['num_spots'] = num_spots.values\n",
    "    results['num_nuc_spots'] = num_nuc_spots.values\n",
    "    results['num_cyto_spots'] = num_cyto_spots.values\n",
    "    results['nuc_area_px'] = nuc_area.values\n",
    "    results['cyto_area_px'] = cyto_area.values\n",
    "    results['avg_nuc_int'] = avg_nuc_int.values\n",
    "    results['avg_cyto_int'] = avg_cyto_int.values\n",
    "    results['time'] = time.values\n",
    "    results['Dex_conc'] = dex_conc.values\n",
    "    results['replica'] = replica.values\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_spots = measure_DUSP1(SD.spots, SD.clusters, SD.cellprops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure num_spots = num_nuc_spots + num_cyto_spots for all rows\n",
    "assert (cell_spots['num_spots'] == cell_spots['num_nuc_spots'] + cell_spots['num_cyto_spots']).all(), \"Mismatch in spot counts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD.cellspots = SD.cellspots.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                                    left_on=['NAS_location', 'cell_id', 'fov'], \n",
    "                                    right_on=['NAS_location', 'cell_label', 'fov'], \n",
    "                                    how='left')\n",
    "\n",
    "\n",
    "# Align indices before performing the assertion\n",
    "if 'cell_id' in cell_spots.keys():\n",
    "    cell_spots = cell_spots.set_index('cell_id')\n",
    "\n",
    "if 'unique_cell_id' in SD.cellspots.keys():\n",
    "    SD.cellspots = SD.cellspots.set_index('unique_cell_id')\n",
    "\n",
    "aligned_nb_rna = SD.cellspots['nb_rna']\n",
    "\n",
    "aligned_num_spots = cell_spots['num_spots']\n",
    "aligned_num_spots = aligned_num_spots - cell_spots['num_spots_ts']\n",
    "\n",
    "# Ensure aligned_num_spots only contains indices present in aligned_nb_rna\n",
    "aligned_num_spots = aligned_num_spots.loc[SD.cellspots.index]\n",
    "\n",
    "not_close_indices = np.where(~np.isclose(aligned_nb_rna, aligned_num_spots, rtol = 0.05))[0]\n",
    "print(\"Indices where nb_rna and num_spots are not close:\", len(not_close_indices))\n",
    "\n",
    "assert len(not_close_indices) == 0, \"Mismatch in nb_rna and num_spots counts\"\n",
    "\n",
    "\n",
    "print(f\"{'cell_id':<10} {'my counting':<30} {'bigfish counting':<30} {'corrected':<30} {'ts spots':<30} {'foci spots':<30}\")\n",
    "for cell_id, my, bf, cr, ts, foci in zip(aligned_nb_rna.iloc[not_close_indices].index, cell_spots.loc[aligned_nb_rna.index]['num_spots'].iloc[not_close_indices], \n",
    "                                         aligned_nb_rna.iloc[not_close_indices], aligned_num_spots.iloc[not_close_indices], \n",
    "                                         cell_spots.loc[aligned_nb_rna.index]['num_spots_ts'].iloc[not_close_indices], cell_spots.loc[aligned_nb_rna.index]['num_spots_foci'].iloc[not_close_indices] ):\n",
    "    print(f\"{cell_id:<10} {my:<30} {bf:<30} {cr:<30} {ts:<30} {foci:<30}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
