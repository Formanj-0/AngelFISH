{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  GR DUSP1 Gating Notebook\n",
    "\n",
    "The Purpose of this notebook is:\n",
    "1) Load in all analyisis for final dataframe preparation \n",
    "2) Filter DUSP1 data to remove partial cells and low SNR spots\n",
    "3) Filter GR data to remove partial cells\n",
    "4) Estimate GR cytoplasmic area from DUPS1 data\n",
    "5) GR intensity to molecular counts \n",
    "6) Concatonate final GR and DUSP1 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import seaborn as sns\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)\n",
    "\n",
    "matplotlib_logger = logging.getLogger('matplotlib')\n",
    "matplotlib_logger.setLevel(logging.WARNING)\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "print(src_path)\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.Analysis import AnalysisManager, Analysis, SpotDetection_SNRConfirmation, Spot_Cluster_Analysis_WeightedSNR, GR_Confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure function to create final DUSP1 dataframe for SSIT\n",
    "\n",
    "def measure_DUSP1(spots, clusters, props) -> pd.DataFrame:\n",
    "    results = pd.DataFrame(columns=['cell_id', 'num_ts', 'num_spots_ts', 'num_foci', 'num_spots_foci', 'num_spots', 'num_nuc_spots', 'num_cyto_spots', \n",
    "                                    'nuc_area_px', 'cyto_area_px', 'avg_nuc_int', 'avg_cyto_int', 'time', 'Dex_conc', 'replica'])\n",
    "    \n",
    "    # Sort spots, clusters, and props by unique_cell_id\n",
    "    spots = spots.sort_values(by='unique_cell_id')\n",
    "    clusters = clusters.sort_values(by='unique_cell_id')\n",
    "    props = props.sort_values(by='unique_cell_id')\n",
    "\n",
    "    # unique cell id\n",
    "    cell_ids = props['unique_cell_id']\n",
    "\n",
    "    # num of ts\n",
    "    num_ts = clusters[clusters['is_nuc'] == 1].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of foci\n",
    "    num_foci = clusters[clusters['is_nuc'] == 0].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of ts spots\n",
    "    num_spots_ts = clusters[clusters['is_nuc'] == 1].groupby('unique_cell_id')['nb_spots'].sum().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of foci spots\n",
    "    num_spots_foci = clusters[clusters['is_nuc'] == 0].groupby('unique_cell_id')['nb_spots'].sum().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of spots\n",
    "    num_spots = spots.groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of spot in nuc\n",
    "    num_nuc_spots = spots[spots['is_nuc'] == 1].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of spot in cyto \n",
    "    num_cyto_spots = spots[spots['is_nuc'] == 0].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # nuc area\n",
    "    nuc_area = props['nuc_area']\n",
    "\n",
    "    # cyto area\n",
    "    cyto_area = props['cyto_area']\n",
    "\n",
    "    # avg int nuc\n",
    "    avg_nuc_int = props['nuc_intensity_mean-0']\n",
    "    \n",
    "    # avg int cyto\n",
    "    avg_cyto_int = props['cyto_intensity_mean-0']\n",
    "\n",
    "    # time (experiment)\n",
    "    time = props['time'] \n",
    "\n",
    "    # Dex conc\n",
    "    dex_conc = props['Dex_Conc']\n",
    "\n",
    "    # Replica\n",
    "    replica = spots.groupby('unique_cell_id')['replica'].first().reindex(cell_ids, fill_value=np.nan)\n",
    "\n",
    "    results['cell_id'] = cell_ids\n",
    "    results['num_ts'] = num_ts.values\n",
    "    results['num_foci'] = num_foci.values\n",
    "    results['num_spots_ts'] = num_spots_ts.values\n",
    "    results['num_spots_foci'] = num_spots_foci.values\n",
    "    results['num_spots'] = num_spots.values\n",
    "    results['num_nuc_spots'] = num_nuc_spots.values\n",
    "    results['num_cyto_spots'] = num_cyto_spots.values\n",
    "    results['nuc_area_px'] = nuc_area.values\n",
    "    results['cyto_area_px'] = cyto_area.values\n",
    "    results['avg_nuc_int'] = avg_nuc_int.values\n",
    "    results['avg_cyto_int'] = avg_cyto_int.values\n",
    "    results['time'] = time.values\n",
    "    results['Dex_conc'] = dex_conc.values\n",
    "    results['replica'] = replica.values\n",
    "\n",
    "    return results\n",
    "\n",
    "# Measure function for GR pre-SSIT dataframe \n",
    "def measure_GR(cellprops) -> pd.DataFrame:\n",
    "    results = pd.DataFrame(columns=['cell_id', 'nuc_area', 'nucGRint', 'cytoGRint', 'time', 'Dex_conc', 'replica'])\n",
    "    \n",
    "    # Sort cellprops by unique_cell_id\n",
    "    props = cellprops.sort_values(by='unique_cell_id')\n",
    "\n",
    "    # unique cell id\n",
    "    cell_ids = props['unique_cell_id']\n",
    "\n",
    "    # nuc area\n",
    "    nuc_area = props['nuc_area']\n",
    "\n",
    "    # avg int nuc\n",
    "    nucGRint = props['nuc_intensity_mean-0']\n",
    "    \n",
    "    # avg int pseudocyto mask\n",
    "    cytoGRint = props['cyto_intensity_mean-0']\n",
    "\n",
    "    # time (experiment)\n",
    "    time = props['time'] \n",
    "\n",
    "    # Dex conc\n",
    "    dex_conc = props['Dex_Conc']\n",
    "\n",
    "    # Replica\n",
    "    replica = spots.groupby('unique_cell_id')['replica'].first().reindex(cell_ids, fill_value=np.nan)\n",
    "\n",
    "    results['cell_id'] = cell_ids\n",
    "    results['nuc_area_px'] = nuc_area.values\n",
    "    results['nucGRint'] = nucGRint.values\n",
    "    results['cytoGRint'] = cytoGRint.values\n",
    "    results['time'] = time.values\n",
    "    results['Dex_conc'] = dex_conc.values\n",
    "    results['replica'] = replica.values\n",
    "\n",
    "    return results    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the log file to search for analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = None \n",
    "log_location = r'/Volumes/share/Users/Eric/AngelFISH_data'  # r'/Volumes/share/Users/Jack/All_Analysis' \n",
    "am = AnalysisManager(location=loc, log_location=log_location, mac=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all analysis done \n",
    "all_analysis_names = am.list_analysis_names()\n",
    "print(\"All discovered analyses:\", all_analysis_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the class and find analysis at log_location\n",
    "am = AnalysisManager(location=loc, log_location=log_location, mac=True) \n",
    "# Select the specific analysis - ex. DUSP1 100nM Dex 3hr Time-sweep Replica 1\n",
    "am.select_analysis('DUSP1_D_020335')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the Weighted SNR analysis class\n",
    "SD = Spot_Cluster_Analysis_WeightedSNR(am)\n",
    "# Load the data\n",
    "SD.get_data()\n",
    "# Assign revise weighted threshold\n",
    "SD.assign_revised_weighted_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter DUPS1 data to remove partial cells and low SNR spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique cell id for every cell\n",
    "SD.cellprops['unique_cell_id'] = np.arange(len(SD.cellprops))\n",
    "\n",
    "# Remove partial cells from dataset\n",
    "SD.cellprops = SD.cellprops[SD.cellprops['touching_border'] == 0]\n",
    "\n",
    "# Remove spots that are less than the weighted snr threshold\n",
    "SD.spots = SD.spots[SD.spots['keep_wsnr']]\n",
    "\n",
    "# Merge the spots and clusters dataframes by the unique cell ID\n",
    "SD.spots = SD.spots.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "SD.clusters = SD.clusters.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use measure_DUSP1 to create SSIT compatible dataframe\n",
    "DUSP1_RepD = measure_DUSP1(SD.spots, SD.clusters, SD.cellprops)\n",
    "am.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 100nM Dex 3hr Time-sweep Replica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the class and find analysis at log_location\n",
    "am = AnalysisManager(location=loc, log_location=log_location, mac=True)\n",
    "# Select the dataset - DUSP1 100nM Dex 3hr Time-sweep Replica 2\n",
    "am.select_analysis('DUSP1_E_Jan2725')\n",
    "# Initiate the Weighted SNR analysis class\n",
    "SD = Spot_Cluster_Analysis_WeightedSNR(am)\n",
    "# Load the data\n",
    "SD.get_data()\n",
    "# Assign revise weighted threshold\n",
    "SD.assign_revised_weighted_threshold()\n",
    "# Create unique cell id for every cell\n",
    "SD.cellprops['unique_cell_id'] = np.arange(len(SD.cellprops))\n",
    "# Remove partial cells from dataset\n",
    "SD.cellprops = SD.cellprops[SD.cellprops['touching_border'] == 0]\n",
    "# Remove spots that are less than the weighted snr threshold\n",
    "SD.spots = SD.spots[SD.spots['keep_wsnr']]\n",
    "# Merge the spots and clusters dataframes by the unique cell ID\n",
    "SD.spots = SD.spots.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "SD.clusters = SD.clusters.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "# Use measure_DUSP1 to create SSIT compatible dataframe\n",
    "DUSP1_RepE = measure_DUSP1(SD.spots, SD.clusters, SD.cellprops)\n",
    "am.close()                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 100nM Dex 3hr Time-sweep Replica 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the class and find analysis at log_location\n",
    "am = AnalysisManager(location=loc, log_location=log_location, mac=True)\n",
    "# Select the dataset\n",
    "am.select_analysis('DUSP1_F_Jan2725')\n",
    "# Initiate the Weighted SNR analysis class\n",
    "SD = Spot_Cluster_Analysis_WeightedSNR(am)\n",
    "# Load the data\n",
    "SD.get_data()\n",
    "# Assign revise weighted threshold\n",
    "SD.assign_revised_weighted_threshold()\n",
    "# Create unique cell id for every cell\n",
    "SD.cellprops['unique_cell_id'] = np.arange(len(SD.cellprops))\n",
    "# Remove partial cells from dataset\n",
    "SD.cellprops = SD.cellprops[SD.cellprops['touching_border'] == 0]\n",
    "# Remove spots that are less than the weighted snr threshold\n",
    "SD.spots = SD.spots[SD.spots['keep_wsnr']]\n",
    "# Merge the spots and clusters dataframes by the unique cell ID\n",
    "SD.spots = SD.spots.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "SD.clusters = SD.clusters.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "# Use measure_DUSP1 to create SSIT compatible dataframe\n",
    "DUSP1_RepF = measure_DUSP1(SD.spots, SD.clusters, SD.cellprops)\n",
    "am.close()                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 100nM Dex 3hr Time-sweep Replica 4 (partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the class and find analysis at log_location\n",
    "am = AnalysisManager(location=loc, log_location=log_location, mac=True)\n",
    "# Select the dataset\n",
    "am.select_analysis('DUSP1_M_020335')\n",
    "# Initiate the Weighted SNR analysis class\n",
    "SD = Spot_Cluster_Analysis_WeightedSNR(am)\n",
    "# Load the data\n",
    "SD.get_data()\n",
    "# Assign revise weighted threshold\n",
    "SD.assign_revised_weighted_threshold()\n",
    "# Create unique cell id for every cell\n",
    "SD.cellprops['unique_cell_id'] = np.arange(len(SD.cellprops))\n",
    "# Remove partial cells from dataset\n",
    "SD.cellprops = SD.cellprops[SD.cellprops['touching_border'] == 0]\n",
    "# Remove spots that are less than the weighted snr threshold\n",
    "SD.spots = SD.spots[SD.spots['keep_wsnr']]\n",
    "# Merge the spots and clusters dataframes by the unique cell ID\n",
    "SD.spots = SD.spots.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "SD.clusters = SD.clusters.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "# Use measure_DUSP1 to create SSIT compatible dataframe\n",
    "DUSP1_RepM = measure_DUSP1(SD.spots, SD.clusters, SD.cellprops)\n",
    "am.close()                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 100nM Dex 3hr Time-sweep Replica 5 (partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initiate the class and find analysis at log_location\n",
    "# am = AnalysisManager(location=loc, log_location=log_location, mac=True)\n",
    "# # Select the dataset\n",
    "# am.select_analysis('')\n",
    "# # Initiate the Weighted SNR analysis class\n",
    "# SD = Spot_Cluster_Analysis_WeightedSNR(am)\n",
    "# # Load the data\n",
    "# SD.get_data()\n",
    "# # Assign revise weighted threshold\n",
    "# SD.assign_revised_weighted_threshold()\n",
    "# # Create unique cell id for every cell\n",
    "# SD.cellprops['unique_cell_id'] = np.arange(len(SD.cellprops))\n",
    "# # Remove partial cells from dataset\n",
    "# SD.cellprops = SD.cellprops[SD.cellprops['touching_border'] == 0]\n",
    "# # Remove spots that are less than the weighted snr threshold\n",
    "# SD.spots = SD.spots[SD.spots['keep_wsnr']]\n",
    "# # Merge the spots and clusters dataframes by the unique cell ID\n",
    "# SD.spots = SD.spots.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "#                             on=['NAS_location', 'cell_label', 'fov'], \n",
    "#                             how='left')\n",
    "# SD.clusters = SD.clusters.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "#                             on=['NAS_location', 'cell_label', 'fov'], \n",
    "#                             how='left')\n",
    "# # Use measure_DUSP1 to create SSIT compatible dataframe\n",
    "# DUSP1_RepN = measure_DUSP1(SD.spots, SD.clusters, SD.cellprops)\n",
    "# am.close()                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 75min Concentration-sweep Replica 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the class and find analysis at log_location\n",
    "am = AnalysisManager(location=loc, log_location=log_location, mac=True)\n",
    "# Select the dataset - DUSP1 100nM Dex 3hr Time-sweep Replica 2\n",
    "am.select_analysis('DUSP1_G_Jan2725')\n",
    "# Initiate the Weighted SNR analysis class\n",
    "SD = Spot_Cluster_Analysis_WeightedSNR(am)\n",
    "# Load the data\n",
    "SD.get_data()\n",
    "# Assign revise weighted threshold\n",
    "SD.assign_revised_weighted_threshold()\n",
    "# Create unique cell id for every cell\n",
    "SD.cellprops['unique_cell_id'] = np.arange(len(SD.cellprops))\n",
    "# Remove partial cells from dataset\n",
    "SD.cellprops = SD.cellprops[SD.cellprops['touching_border'] == 0]\n",
    "# Remove spots that are less than the weighted snr threshold\n",
    "SD.spots = SD.spots[SD.spots['keep_wsnr']]\n",
    "# Merge the spots and clusters dataframes by the unique cell ID\n",
    "SD.spots = SD.spots.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "SD.clusters = SD.clusters.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "# Use measure_DUSP1 to create SSIT compatible dataframe\n",
    "DUSP1_RepG = measure_DUSP1(SD.spots, SD.clusters, SD.cellprops)\n",
    "am.close()                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 75min Concentration-sweep Replica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the class and find analysis at log_location\n",
    "am = AnalysisManager(location=loc, log_location=log_location, mac=True)\n",
    "# Select the dataset\n",
    "am.select_analysis('DUSP1_H_Jan2725')\n",
    "# Initiate the Weighted SNR analysis class\n",
    "SD = Spot_Cluster_Analysis_WeightedSNR(am)\n",
    "# Load the data\n",
    "SD.get_data()\n",
    "# Assign revise weighted threshold\n",
    "SD.assign_revised_weighted_threshold()\n",
    "# Create unique cell id for every cell\n",
    "SD.cellprops['unique_cell_id'] = np.arange(len(SD.cellprops))\n",
    "# Remove partial cells from dataset\n",
    "SD.cellprops = SD.cellprops[SD.cellprops['touching_border'] == 0]\n",
    "# Remove spots that are less than the weighted snr threshold\n",
    "SD.spots = SD.spots[SD.spots['keep_wsnr']]\n",
    "# Merge the spots and clusters dataframes by the unique cell ID\n",
    "SD.spots = SD.spots.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "SD.clusters = SD.clusters.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "# Use measure_DUSP1 to create SSIT compatible dataframe\n",
    "DUSP1_RepH = measure_DUSP1(SD.spots, SD.clusters, SD.cellprops)\n",
    "am.close()                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 75min Concentration-sweep Replica 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the class and find analysis at log_location\n",
    "am = AnalysisManager(location=loc, log_location=log_location, mac=True)\n",
    "# Select the dataset\n",
    "am.select_analysis('DUSP1_I_Jan2725')\n",
    "# Initiate the Weighted SNR analysis class\n",
    "SD = Spot_Cluster_Analysis_WeightedSNR(am)\n",
    "# Load the data\n",
    "SD.get_data()\n",
    "# Assign revise weighted threshold\n",
    "SD.assign_revised_weighted_threshold()\n",
    "# Create unique cell id for every cell\n",
    "SD.cellprops['unique_cell_id'] = np.arange(len(SD.cellprops))\n",
    "# Remove partial cells from dataset\n",
    "SD.cellprops = SD.cellprops[SD.cellprops['touching_border'] == 0]\n",
    "# Remove spots that are less than the weighted snr threshold\n",
    "SD.spots = SD.spots[SD.spots['keep_wsnr']]\n",
    "# Merge the spots and clusters dataframes by the unique cell ID\n",
    "SD.spots = SD.spots.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "SD.clusters = SD.clusters.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "# Use measure_DUSP1 to create SSIT compatible dataframe\n",
    "DUSP1_RepI = measure_DUSP1(SD.spots, SD.clusters, SD.cellprops)\n",
    "am.close()                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 0.3, 1, 10nM Dex 3hr Time-sweep Replica 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initiate the class and find analysis at log_location\n",
    "# am = AnalysisManager(location=loc, log_location=log_location, mac=True)\n",
    "# # Select the dataset\n",
    "# am.select_analysis('')\n",
    "# # Initiate the Weighted SNR analysis class\n",
    "# SD = Spot_Cluster_Analysis_WeightedSNR(am)\n",
    "# # Load the data\n",
    "# SD.get_data()\n",
    "# # Assign revise weighted threshold\n",
    "# SD.assign_revised_weighted_threshold()\n",
    "# # Create unique cell id for every cell\n",
    "# SD.cellprops['unique_cell_id'] = np.arange(len(SD.cellprops))\n",
    "# # Remove partial cells from dataset\n",
    "# SD.cellprops = SD.cellprops[SD.cellprops['touching_border'] == 0]\n",
    "# # Remove spots that are less than the weighted snr threshold\n",
    "# SD.spots = SD.spots[SD.spots['keep_wsnr']]\n",
    "# # Merge the spots and clusters dataframes by the unique cell ID\n",
    "# SD.spots = SD.spots.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "#                             on=['NAS_location', 'cell_label', 'fov'], \n",
    "#                             how='left')\n",
    "# SD.clusters = SD.clusters.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "#                             on=['NAS_location', 'cell_label', 'fov'], \n",
    "#                             how='left')\n",
    "# # Use measure_DUSP1 to create SSIT compatible dataframe\n",
    "# DUSP1_RepJ = measure_DUSP1(SD.spots, SD.clusters, SD.cellprops)\n",
    "# am.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 0.3, 1, 10nM Dex 3hr Time-sweep Replica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the class and find analysis at log_location\n",
    "am = AnalysisManager(location=loc, log_location=log_location, mac=True)\n",
    "# Select the dataset\n",
    "am.select_analysis('DUSP1_K_Jan2725')\n",
    "# Initiate the Weighted SNR analysis class\n",
    "SD = Spot_Cluster_Analysis_WeightedSNR(am)\n",
    "# Load the data\n",
    "SD.get_data()\n",
    "# Assign revise weighted threshold\n",
    "SD.assign_revised_weighted_threshold()\n",
    "# Create unique cell id for every cell\n",
    "SD.cellprops['unique_cell_id'] = np.arange(len(SD.cellprops))\n",
    "# Remove partial cells from dataset\n",
    "SD.cellprops = SD.cellprops[SD.cellprops['touching_border'] == 0]\n",
    "# Remove spots that are less than the weighted snr threshold\n",
    "SD.spots = SD.spots[SD.spots['keep_wsnr']]\n",
    "# Merge the spots and clusters dataframes by the unique cell ID\n",
    "SD.spots = SD.spots.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "SD.clusters = SD.clusters.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "# Use measure_DUSP1 to create SSIT compatible dataframe\n",
    "DUSP1_RepK = measure_DUSP1(SD.spots, SD.clusters, SD.cellprops)\n",
    "am.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 0.3, 1, 10nM Dex 3hr Time-sweep Replica 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the class and find analysis at log_location\n",
    "am = AnalysisManager(location=loc, log_location=log_location, mac=True)\n",
    "# Select the dataset\n",
    "am.select_analysis('DUSP1_L_Jan2725')\n",
    "# Initiate the Weighted SNR analysis class\n",
    "SD = Spot_Cluster_Analysis_WeightedSNR(am)\n",
    "# Load the data\n",
    "SD.get_data()\n",
    "# Assign revise weighted threshold\n",
    "SD.assign_revised_weighted_threshold()\n",
    "# Create unique cell id for every cell\n",
    "SD.cellprops['unique_cell_id'] = np.arange(len(SD.cellprops))\n",
    "# Remove partial cells from dataset\n",
    "SD.cellprops = SD.cellprops[SD.cellprops['touching_border'] == 0]\n",
    "# Remove spots that are less than the weighted snr threshold\n",
    "SD.spots = SD.spots[SD.spots['keep_wsnr']]\n",
    "# Merge the spots and clusters dataframes by the unique cell ID\n",
    "SD.spots = SD.spots.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "SD.clusters = SD.clusters.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "# Use measure_DUSP1 to create SSIT compatible dataframe\n",
    "DUSP1_RepL = measure_DUSP1(SD.spots, SD.clusters, SD.cellprops)\n",
    "am.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatonate all DUSP1 Dex experiments & reset 'unique_cell_id'\n",
    "DUSP1_ALL = pd.concat()\n",
    "[DUSP1_RepD, DUSP1_RepE, DUSP1_RepF, DUSP1_RepM, DUSP1_RepG, DUSP1_RepH, DUSP1_RepI, DUSP1_RepK, DUSP1_RepL], ignore_index=True) # DUSP1_RepN, DUSP1_RepJ\n",
    "DUSP1_ALL['unique_cell_id'] = np.arange(len(DUSP1_ALL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter GR data:\n",
    "1. Remove partial cells\n",
    "2. Use `measure_GR` to prepare pre-SSIT dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    GR 1, 10, 100nM Dex 3hr Time-sweep Replica 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the class and find analysis at log_location\n",
    "am = AnalysisManager(location=loc, log_location=log_location, mac=True)\n",
    "# Select the dataset\n",
    "am.select_analysis('GR_A_Feb0425')\n",
    "# select GR conformation analysis \n",
    "GR = GR_Confirmation(am)\n",
    "# Load the data\n",
    "GR.get_data()\n",
    "# Create unique cell id for every cell\n",
    "GR.cellprops['unique_cell_id'] = np.arange(len(GR.cellprops))\n",
    "# Remove partial cells from dataset\n",
    "GR.cellprops = GR.cellprops[GR.cellprops['touching_border'] == 0]\n",
    "# Use measure_GR to create SSIT compatible dataframe\n",
    "GR_RepA = measure_GR(GR.spots, GR.clusters, GR.cellprops)\n",
    "am.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    GR 1, 10, 100nM Dex 3hr Time-sweep Replica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the class and find analysis at log_location\n",
    "am = AnalysisManager(location=loc, log_location=log_location, mac=True)\n",
    "# Select the dataset\n",
    "am.select_analysis('GR_B_Feb0425')\n",
    "# select GR conformation analysis \n",
    "GR = GR_Confirmation(am)\n",
    "# Load the data\n",
    "GR.get_data()\n",
    "# Create unique cell id for every cell\n",
    "GR.cellprops['unique_cell_id'] = np.arange(len(GR.cellprops))\n",
    "# Remove partial cells from dataset\n",
    "GR.cellprops = GR.cellprops[GR.cellprops['touching_border'] == 0]\n",
    "# Use measure_GR to create SSIT compatible dataframe\n",
    "GR_RepB = measure_GR(GR.spots, GR.clusters, GR.cellprops)\n",
    "am.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    GR 1, 10, 100nM Dex 3hr Time-sweep Replica 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the class and find analysis at log_location\n",
    "am = AnalysisManager(location=loc, log_location=log_location, mac=True)\n",
    "# Select the dataset\n",
    "am.select_analysis('GR_C_Feb0425')\n",
    "# select GR conformation analysis \n",
    "GR = GR_Confirmation(am)\n",
    "# Load the data\n",
    "GR.get_data()\n",
    "# Create unique cell id for every cell\n",
    "GR.cellprops['unique_cell_id'] = np.arange(len(GR.cellprops))\n",
    "# Remove partial cells from dataset\n",
    "GR.cellprops = GR.cellprops[GR.cellprops['touching_border'] == 0]\n",
    "# Use measure_GR to create SSIT compatible dataframe\n",
    "GR_RepC = measure_GR(GR.spots, GR.clusters, GR.cellprops)\n",
    "am.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatonate all DUSP1 Dex experiments & reset 'unique_cell_id'\n",
    "GR_ALL = pd.concat()\n",
    "[GR_RepA, GR_RepB, GR_RebC], ignore_index=True) # DUSP1_RepN, DUSP1_RepJ\n",
    "GR_ALL['unique_cell_id'] = np.arange(len(GR_ALL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GR_ALL & DUSP1_All final dataframe preperation for SSIT\n",
    "\n",
    "1) Fit a Polynomial (2nd-degree) using (nuc_area_px, cyto_area_px) from DUSP1_ALL.\n",
    "\n",
    "2) Estimate Cytoplasm Area in GR_ALL:\n",
    "3) Creates `CalcCytoArea` by evaluating the fitted polynomial at each row’s `nuc_area`.\n",
    "\n",
    "4) Gate both data sets on the 25%–75% range of nuclear area.\n",
    "\n",
    "5) Compute “Normalized” GR (`normGRnuc`, `normGRcyt`) in GR_ALL:\n",
    "- Scales nuclear/cyt intensities (5%→95% range) into integer bins [0,20].\n",
    "\n",
    "6) Plot Histograms for the normalized nuclear/cyt GR (using custom colors).\n",
    "\n",
    "7) Save the updated, gated data sets to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) READ INPUT DATA\n",
    "# =========================\n",
    "# DUSP1_ALL from above:\n",
    "df_dusp = DUSP1_ALL\n",
    "\n",
    "# GR_ALL from above:\n",
    "df_gr = GR_ALL\n",
    "\n",
    "\n",
    "# 2) FIT POLYNOMIAL TO (NUC, CYTO) FROM DUSP1_ALL\n",
    "# =========================\n",
    "# We'll use only the rows that have valid nuc_area_px and cyto_area_px.\n",
    "df_dusp_nonmissing = df_dusp.dropna(subset=['nuc_area_px', 'cyto_area_px']).copy()\n",
    "\n",
    "x_nuc = df_dusp_nonmissing['nuc_area_px'].values\n",
    "y_cyto = df_dusp_nonmissing['cyto_area_px'].values\n",
    "\n",
    "# Fit a 2nd-degree polynomial: cyto_area_px = a*(nuc_area_px)^2 + b*(nuc_area_px) + c\n",
    "poly_coeffs = np.polyfit(x_nuc, y_cyto, deg=2)\n",
    "\n",
    "# optional: for debugging/inspection\n",
    "# print(\"Fitted polynomial coefficients (a, b, c):\", poly_coeffs)\n",
    "\n",
    "\n",
    "# 3) ESTIMATE CYTO AREA IN GR_ALL\n",
    "# =========================\n",
    "# We'll store the computed cytoplasm area in a new column: 'CalcCytoArea'\n",
    "# Evaluate the polynomial at GR_ALL['nuc_area'].\n",
    "df_gr['CalcCytoArea'] = np.polyval(poly_coeffs, df_gr['nuc_area'])\n",
    "\n",
    "\n",
    "\n",
    "# 4) GATE BOTH DATAFRAMES ON [25%, 75%] NUCLEAR AREA\n",
    "# =========================\n",
    "# We'll define a helper function for gating.\n",
    "def gate_on_nuc_area(df, nuc_col):\n",
    "    \"\"\"Return a copy of df gated to [25th, 75th percentile] of nuc_col.\"\"\"\n",
    "    lower = df[nuc_col].quantile(0.25)\n",
    "    upper = df[nuc_col].quantile(0.75)\n",
    "    return df[(df[nuc_col] >= lower) & (df[nuc_col] <= upper)].copy()\n",
    "\n",
    "# Gate DUSP1_ALL on nuc_area_px\n",
    "df_dusp_gated = gate_on_nuc_area(df_dusp, 'nuc_area_px')\n",
    "\n",
    "# Gate GR_ALL on nuc_area\n",
    "df_gr_gated = gate_on_nuc_area(df_gr, 'nuc_area')\n",
    "\n",
    "print(f\"DUSP1_ALL original: {len(df_dusp)} rows -> gated: {len(df_dusp_gated)} rows\")\n",
    "print(f\"GR_ALL original:    {len(df_gr)} rows -> gated: {len(df_gr_gated)} rows\")\n",
    "\n",
    "\n",
    "# 5) COMPUTE \"NORMALIZED\" GR FOR NUC & CYTO IN GR_ALL\n",
    "# =========================\n",
    "# We'll do a percentile-based normalization: 5th->95th percentile => mapped to [0, bins].\n",
    "bins = 20\n",
    "\n",
    "def normalize_by_percentiles(series, low_pct=0.05, high_pct=0.95, bins=20):\n",
    "    \"\"\"Scale 'series' into integer bins [0, bins] based on [low_pct, high_pct].\"\"\"\n",
    "    lower_val = series.quantile(low_pct)\n",
    "    upper_val = series.quantile(high_pct)\n",
    "    clipped = (series - lower_val) / (upper_val - lower_val)\n",
    "    clipped = clipped.clip(lower=0, upper=1)\n",
    "    return (clipped * bins).round().astype(int)\n",
    "\n",
    "df_gr_gated['normGRnuc'] = normalize_by_percentiles(df_gr_gated['nucGRint'], 0.05, 0.95, bins=bins)\n",
    "df_gr_gated['normGRcyt'] = normalize_by_percentiles(df_gr_gated['cytoGRint'], 0.05, 0.95, bins=bins)\n",
    "\n",
    "\n",
    "# 6) HISTOGRAMS\n",
    "# =========================\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(df_gr_gated['normGRnuc'], bins=bins+1, color='darkred', edgecolor='black')\n",
    "plt.title(\"Normalized GR (Nuclear)\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(df_gr_gated['normGRcyt'], bins=bins+1, color='navy', edgecolor='black')\n",
    "plt.title(\"Normalized GR (Cytoplasm)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 7) SAVE THE UPDATED GATED DATAFRAMES\n",
    "# =========================\n",
    "# Gated DUSP1 (unchanged except row filtering)\n",
    "df_dusp_gated.to_csv(\"DUSP1_ALL_gated.csv\", index=False)\n",
    "\n",
    "# Gated GR with new columns: CalcCytoArea, normGRnuc, normGRcyt\n",
    "df_gr_gated.to_csv(\"GR_ALL_gated_with_CytoArea_and_normGR.csv\", index=False)\n",
    "\n",
    "print(\"Saved gated DUSP1 to 'DUSP1_ALL_gated.csv'\")\n",
    "print(\"Saved gated GR to 'GR_ALL_gated_with_CytoArea_and_normGR.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
