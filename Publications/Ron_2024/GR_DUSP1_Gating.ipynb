{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  GR DUSP1 Gating Notebook\n",
    "\n",
    "The Purpose of this notebook is:\n",
    "1) Load in all analyisis for final dataframe preparation \n",
    "2) Filter DUSP1 data to remove partial cells and low SNR spots\n",
    "3) Filter GR data to remove partial cells\n",
    "4) Estimate GR cytoplasmic area from DUPS1 data\n",
    "5) GR intensity to molecular counts \n",
    "6) Concatonate final GR and DUSP1 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import seaborn as sns\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)\n",
    "\n",
    "matplotlib_logger = logging.getLogger('matplotlib')\n",
    "matplotlib_logger.setLevel(logging.WARNING)\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "print(src_path)\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.Analysis import AnalysisManager, Analysis, SpotDetection_SNRConfirmation, Spot_Cluster_Analysis_WeightedSNR, GR_Confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = None \n",
    "log_location = r'Y:\\Users\\Eric\\GR_DUSP1_2025'  # r'/Volumes/share/Users/Jack/All_Analysis' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure function to create final DUSP1 dataframe for SSIT\n",
    "# Function to get the second largest value or default to 0\n",
    "def second_largest(series):\n",
    "    unique_vals = series.dropna().unique()  # Remove NaN and get unique values\n",
    "    if len(unique_vals) < 2:\n",
    "        return 0  # Return 0 if there's no second-largest value\n",
    "    return np.sort(unique_vals)[-2]  # Return the second-largest value\n",
    "\n",
    "def touching_border(df):\n",
    "    # TODO: remove this its a bandaid \n",
    "    min_row, min_col, max_row, max_col = df['cell_bbox-0'], df['cell_bbox-1'], df['cell_bbox-2'], df['cell_bbox-3']\n",
    "    return (min_row == 0) | (min_col == 0) | (max_row == np.max(max_row)) | (max_col == np.max(max_col))\n",
    "\n",
    "def filter_DUSP1(name, is_tpl = False):\n",
    "    # Initiate the class and find analysis at log_location\n",
    "    am = AnalysisManager(location=loc, log_location=log_location, mac=False)\n",
    "    # Select the dataset - DUSP1 100nM Dex 3hr Time-sweep Replica 2\n",
    "    am.select_analysis(name)\n",
    "    # Initiate the Weighted SNR analysis class\n",
    "    SD = Spot_Cluster_Analysis_WeightedSNR(am)\n",
    "    # Load the data\n",
    "    SD.get_data()\n",
    "    print(f'Total number of cells before filtering: {SD.cellprops.shape[0]}')\n",
    "    print(f'Total number of spots before filtering: {SD.spots.shape[0]}')\n",
    "    # Assign revise weighted threshold\n",
    "    SD.assign_revised_weighted_threshold()\n",
    "    # Create unique cell id for every cell\n",
    "    SD.cellprops['unique_cell_id'] = np.arange(len(SD.cellprops))\n",
    "    # Remove partial cells from dataset\n",
    "    SD.cellprops['touching_border'] = touching_border(SD.cellprops) # TODO: remove this bandaid\n",
    "    SD.cellprops = SD.cellprops[SD.cellprops['touching_border'] == 0]\n",
    "    # Remove spots that are less than the weighted snr threshold\n",
    "    SD.spots = SD.spots[SD.spots['keep_wsnr']]\n",
    "    # Merge the spots and clusters dataframes by the unique cell ID\n",
    "    SD.spots = SD.spots.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                                on=['NAS_location', 'cell_label', 'fov'], \n",
    "                                how='left')\n",
    "    SD.clusters = SD.clusters.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                                on=['NAS_location', 'cell_label', 'fov'], \n",
    "                                how='left')\n",
    "    SD.display_gating()\n",
    "    am.close()\n",
    "    # Use measure_DUSP1 to create SSIT compatible dataframe\n",
    "    if not is_tpl:\n",
    "        results = measure_DUSP1(SD.spots, SD.clusters, SD.cellprops)\n",
    "    else:\n",
    "        results = measure_DUSP1_TPL(SD.spots, SD.clusters, SD.cellprops)\n",
    "\n",
    "    print(f'Total number of cells after filtering: {results.shape[0]}')\n",
    "    print(f'Total number of spots counted: {np.sum(results['num_spots'])}')\n",
    "    return results\n",
    "\n",
    "def filter_GR(name):\n",
    "    # Initiate the class and find analysis at log_location\n",
    "    am = AnalysisManager(location=loc, log_location=log_location, mac=True)\n",
    "    # Select the dataset\n",
    "    am.select_analysis(name)\n",
    "    # select GR conformation analysis \n",
    "    GR = GR_Confirmation(am)\n",
    "    # Load the data\n",
    "    GR.get_data()\n",
    "    # Create unique cell id for every cell\n",
    "    GR.cellprops['unique_cell_id'] = np.arange(len(GR.cellprops))\n",
    "    # Remove partial cells from dataset\n",
    "    GR.cellprops['touching_border'] = touching_border(GR.cellprops) # TODO: remove this bandaid\n",
    "    GR.cellprops = GR.cellprops[GR.cellprops['touching_border'] == 0]\n",
    "    am.close()\n",
    "    # Use measure_GR to create SSIT compatible dataframe\n",
    "    return measure_GR(GR.cellprops)\n",
    "\n",
    "def measure_DUSP1(spots, clusters, props) -> pd.DataFrame:\n",
    "    results = pd.DataFrame(columns=['cell_id', 'num_ts', 'num_spots_ts', 'largest_ts', 'second_largest_ts', 'num_foci', 'num_spots_foci', 'num_spots', 'num_nuc_spots', 'num_cyto_spots', \n",
    "                                    'nuc_area_px', 'cyto_area_px', 'avg_nuc_int', 'avg_cyto_int', 'time', 'Dex_conc', 'replica', 'fov', 'nas_location', ])\n",
    "    \n",
    "    # Sort spots, clusters, and props by unique_cell_id\n",
    "    spots = spots.sort_values(by='unique_cell_id')\n",
    "    clusters = clusters.sort_values(by='unique_cell_id')\n",
    "    props = props.sort_values(by='unique_cell_id')\n",
    "\n",
    "    # unique cell id\n",
    "    cell_ids = props['unique_cell_id']\n",
    "\n",
    "    # num of ts\n",
    "    num_ts = clusters[clusters['is_nuc'] == 1].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of foci\n",
    "    num_foci = clusters[clusters['is_nuc'] == 0].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of ts spots\n",
    "    num_spots_ts = clusters[clusters['is_nuc'] == 1].groupby('unique_cell_id')['nb_spots'].sum().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # largest TS size\n",
    "    largest_ts = clusters[clusters['is_nuc'] == 1].groupby('unique_cell_id')['nb_spots'].max().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # Compute second-largest TS size per cell\n",
    "    second_largest_ts = (clusters[clusters['is_nuc'] == 1].groupby('unique_cell_id')['nb_spots'].apply(second_largest).reindex(cell_ids, fill_value=0))    \n",
    "\n",
    "    # num of foci spots\n",
    "    num_spots_foci = clusters[clusters['is_nuc'] == 0].groupby('unique_cell_id')['nb_spots'].sum().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of spots\n",
    "    num_spots = spots.groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of spot in nuc\n",
    "    num_nuc_spots = spots[spots['is_nuc'] == 1].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of spot in cyto \n",
    "    num_cyto_spots = spots[spots['is_nuc'] == 0].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # nuc area\n",
    "    nuc_area = props['nuc_area']\n",
    "\n",
    "    # cyto area\n",
    "    cyto_area = props['cyto_area']\n",
    "\n",
    "    # avg int nuc\n",
    "    avg_nuc_int = props['nuc_intensity_mean-0']\n",
    "    \n",
    "    # avg int cyto\n",
    "    avg_cyto_int = props['cyto_intensity_mean-0']\n",
    "\n",
    "    # time (experiment)\n",
    "    time = props['time'] \n",
    "\n",
    "    # Dex conc\n",
    "    dex_conc = props['Dex_Conc']\n",
    "\n",
    "    # Replica\n",
    "    replica = spots.groupby('unique_cell_id')['replica'].first().reindex(cell_ids, fill_value=np.nan)\n",
    "\n",
    "    results['cell_id'] = cell_ids\n",
    "    results['num_ts'] = num_ts.values\n",
    "    results['largest_ts'] = largest_ts.values\n",
    "    results['second_largest_ts'] = second_largest_ts.values\n",
    "    results['num_foci'] = num_foci.values\n",
    "    results['num_spots_ts'] = num_spots_ts.values\n",
    "    results['num_spots_foci'] = num_spots_foci.values\n",
    "    results['num_spots'] = num_spots.values\n",
    "    results['num_nuc_spots'] = num_nuc_spots.values\n",
    "    results['num_cyto_spots'] = num_cyto_spots.values\n",
    "    results['nuc_area_px'] = nuc_area.values\n",
    "    results['cyto_area_px'] = cyto_area.values\n",
    "    results['avg_nuc_int'] = avg_nuc_int.values\n",
    "    results['avg_cyto_int'] = avg_cyto_int.values\n",
    "    results['time'] = time.values\n",
    "    results['Dex_conc'] = dex_conc.values\n",
    "    results['replica'] = replica.values\n",
    "\n",
    "    return results\n",
    "\n",
    "def measure_DUSP1_TPL(spots, clusters, props) -> pd.DataFrame:\n",
    "    results = pd.DataFrame(columns=['cell_id', 'num_ts', 'num_spots_ts', 'largest_ts', 'second_largest_ts', 'num_foci', 'num_spots_foci', 'num_spots', 'num_nuc_spots', 'num_cyto_spots', \n",
    "                                    'nuc_area_px', 'cyto_area_px', 'avg_nuc_int', 'avg_cyto_int', 'time', 'time_tpl' 'Dex_conc', 'replica',\n",
    "                                    'tryptCond1', 'tryptCond2', 'tryptCond3', 'tryptCond4', 'tryptCond5'])\n",
    "    \n",
    "    # Sort spots, clusters, and props by unique_cell_id\n",
    "    spots = spots.sort_values(by='unique_cell_id')\n",
    "    clusters = clusters.sort_values(by='unique_cell_id')\n",
    "    props = props.sort_values(by='unique_cell_id')\n",
    "\n",
    "    # unique cell id\n",
    "    cell_ids = props['unique_cell_id']\n",
    "\n",
    "    # num of ts\n",
    "    num_ts = clusters[clusters['is_nuc'] == 1].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of foci\n",
    "    num_foci = clusters[clusters['is_nuc'] == 0].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of ts spots\n",
    "    num_spots_ts = clusters[clusters['is_nuc'] == 1].groupby('unique_cell_id')['nb_spots'].sum().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # largest TS size\n",
    "    largest_ts = clusters[clusters['is_nuc'] == 1].groupby('unique_cell_id')['nb_spots'].max().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # Compute second-largest TS size per cell\n",
    "    second_largest_ts = (clusters[clusters['is_nuc'] == 1].groupby('unique_cell_id')['nb_spots'].apply(second_largest).reindex(cell_ids, fill_value=0))    \n",
    "\n",
    "    # num of foci spots\n",
    "    num_spots_foci = clusters[clusters['is_nuc'] == 0].groupby('unique_cell_id')['nb_spots'].sum().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of spots\n",
    "    num_spots = spots.groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of spot in nuc\n",
    "    num_nuc_spots = spots[spots['is_nuc'] == 1].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # num of spot in cyto \n",
    "    num_cyto_spots = spots[spots['is_nuc'] == 0].groupby('unique_cell_id').size().reindex(cell_ids, fill_value=0)\n",
    "\n",
    "    # nuc area\n",
    "    nuc_area = props['nuc_area']\n",
    "\n",
    "    # cyto area\n",
    "    cyto_area = props['cyto_area']\n",
    "\n",
    "    # avg int nuc\n",
    "    avg_nuc_int = props['nuc_intensity_mean-0']\n",
    "    \n",
    "    # avg int cyto\n",
    "    avg_cyto_int = props['cyto_intensity_mean-0']\n",
    "\n",
    "    # time of Dex(experiment)\n",
    "    time = props['time'] \n",
    "\n",
    "    # time of tpl\n",
    "    time_tpl = props['time_tpl']\n",
    "\n",
    "    # Dex conc\n",
    "    dex_conc = props['Dex_Conc']\n",
    "\n",
    "    # Replica\n",
    "    replica = spots.groupby('unique_cell_id')['replica'].first().reindex(cell_ids, fill_value=np.nan)\n",
    "\n",
    "    # Extract unique TPL times\n",
    "    trptTimes = np.sort(props['time_tpl'].dropna().unique())\n",
    "    \n",
    "    # Initialize tryptCond columns\n",
    "    for k, t_TPL in enumerate(trptTimes, start=1):\n",
    "        JJ = (\n",
    "            ((dex_conc == 100) | (time == 0)) &\n",
    "            ((time == 0) | ((time <= t_TPL) & time_tpl.isna()) | ((time >= t_TPL) & (time_tpl == t_TPL)))\n",
    "        )\n",
    "        results[f'tryptCond{k}'] = JJ.astype(int) * k\n",
    "    \n",
    "    # Populate DataFrame\n",
    "    results['cell_id'] = cell_ids\n",
    "    results['num_ts'] = num_ts.values\n",
    "    results['largest_ts'] = largest_ts.values\n",
    "    results['second_largest_ts'] = second_largest_ts.values\n",
    "    results['num_foci'] = num_foci.values\n",
    "    results['num_spots_ts'] = num_spots_ts.values\n",
    "    results['num_spots_foci'] = num_spots_foci.values\n",
    "    results['num_spots'] = num_spots.values\n",
    "    results['num_nuc_spots'] = num_nuc_spots.values\n",
    "    results['num_cyto_spots'] = num_cyto_spots.values\n",
    "    results['nuc_area_px'] = nuc_area.values\n",
    "    results['cyto_area_px'] = cyto_area.values\n",
    "    results['avg_nuc_int'] = avg_nuc_int.values\n",
    "    results['avg_cyto_int'] = avg_cyto_int.values\n",
    "    results['time'] = time.values\n",
    "    results['time_tpl'] = time_tpl.values\n",
    "    results['Dex_conc'] = dex_conc.values\n",
    "    results['replica'] = replica.values\n",
    "\n",
    "    return results\n",
    "\n",
    "# Measure function for GR pre-SSIT dataframe \n",
    "def measure_GR(cellprops) -> pd.DataFrame:\n",
    "    results = pd.DataFrame(columns=['cell_id', 'nuc_area', 'nucGRint', 'cytoGRint', 'time', 'Dex_conc', 'replica'])\n",
    "    \n",
    "    # Sort cellprops by unique_cell_id\n",
    "    props = cellprops.sort_values(by='unique_cell_id')\n",
    "\n",
    "    # unique cell id\n",
    "    cell_ids = props['unique_cell_id']\n",
    "\n",
    "    # nuc area\n",
    "    nuc_area = props['nuc_area']\n",
    "\n",
    "    # avg int nuc\n",
    "    nucGRint = props['nuc_intensity_mean-0']\n",
    "    \n",
    "    # avg int pseudocyto mask\n",
    "    cytoGRint = props['cyto_intensity_mean-0']\n",
    "\n",
    "    # time (experiment)\n",
    "    time = props['time'] \n",
    "\n",
    "    # Dex conc\n",
    "    dex_conc = props['Dex_Conc']\n",
    "\n",
    "    # Replica\n",
    "    replica = props['replica']\n",
    "\n",
    "    results['cell_id'] = cell_ids\n",
    "    results['nuc_area'] = nuc_area.values\n",
    "    results['nucGRint'] = nucGRint.values\n",
    "    results['cytoGRint'] = cytoGRint.values\n",
    "    results['time'] = time.values\n",
    "    results['Dex_conc'] = dex_conc.values\n",
    "    results['replica'] = replica.values\n",
    "\n",
    "    return results    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the log file to search for analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = AnalysisManager(location=loc, log_location=log_location, mac=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all analysis done \n",
    "all_analysis_names = am.list_analysis_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUSP1 Experiment Analysis List\n",
    "\n",
    "### DUSP1 100nM Dex 3hr Time-sweep\n",
    "- Replica D: `Analysis_DUSP1_D_JacksRunAll_2025-02-05`\n",
    "- Replica E: `Analysis_DUSP1_E_ERonRunAll_2025-02-06`\n",
    "- Replica F: `Analysis_DUSP1_F_ERonReRun_2025-02-08`\n",
    "- Replica M: `Analysis_DUSP1_M_ERonRunAll_2025-02-06`\n",
    "- Replica N: `Analysis_DUSP1_N_JacksRunAll_2025-02-06`\n",
    "\n",
    "### DUSP1 75min Concentration-sweep\n",
    "- Replica G: `Analysis_DUSP1_G_ERonReRun_2025-02-08`\n",
    "- Replica H: `Analysis_DUSP1_H_ERonRunAll_2025-02-06`\n",
    "- Replica I: `Analysis_DUSP1_I_JacksRunAll_2025-02-06`\n",
    "\n",
    "### DUSP1 0.3, 1, 10nM Dex 3hr Time-sweep\n",
    "- Replica J: `Analysis_DUSP1_J_ERonRunAll_2025-02-06`\n",
    "- Replica K: `Analysis_DUSP1_K_ERonReRun_2025-02-08`\n",
    "- Replica L: `Analysis_DUSP1_L_JacksRunAll_2025-02-06`\n",
    "\n",
    "### DUSP1 TPL\n",
    "- Replica O `Analysis_DUSP1_O_JacksRunAll_2025-02-06`\n",
    "- Replica P `Analysis_DUSP1_P_ERonReRun_2025-02-08`\n",
    "\n",
    "# GR Experiment Analyis List\n",
    "\n",
    "### GR 1, 10, 100nM Dex 3hr Time-Sweep\n",
    "- Replica A: `Analysis_GR_IC_A_ER020725_2025-02-07`\n",
    "- Replica B: `Analysis_GR_IC_B_ReRun021025_2025-02-10`\n",
    "- Replica C: `Analysis_GR_IC_C_ER020725_2025-02-08`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the class and find analysis at log_location\n",
    "# Select the specific analysis - ex. DUSP1 100nM Dex 3hr Time-sweep Replica 1\n",
    "am.select_analysis('DUSP1_D_JacksRunAll')\n",
    "print('locations with this dataset:', am.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the Weighted SNR analysis class\n",
    "SD = Spot_Cluster_Analysis_WeightedSNR(am)\n",
    "# Load the data\n",
    "SD.get_data()\n",
    "print(f'Total number of cells before filtering: {SD.cellprops.shape[0]}')\n",
    "print(f'Total number of spots before filtering: {SD.spots.shape[0]}')\n",
    "# Assign revise weighted threshold\n",
    "SD.assign_revised_weighted_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter DUPS1 data to remove partial cells and low SNR spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique cell id for every cell\n",
    "SD.cellprops['unique_cell_id'] = np.arange(len(SD.cellprops))\n",
    "print(SD.cellprops.shape)\n",
    "\n",
    "# Remove partial cells from dataset\n",
    "SD.cellprops = SD.cellprops[SD.cellprops['touching_border'] == 0]\n",
    "print(SD.cellprops.shape)\n",
    "\n",
    "# Remove spots that are less than the weighted snr threshold\n",
    "SD.spots = SD.spots[SD.spots['keep_wsnr']]\n",
    "\n",
    "\n",
    "# Merge the spots and clusters dataframes by the unique cell ID\n",
    "SD.spots = SD.spots.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "SD.clusters = SD.clusters.merge(SD.cellprops[['NAS_location', 'cell_label', 'fov', 'unique_cell_id']], \n",
    "                            on=['NAS_location', 'cell_label', 'fov'], \n",
    "                            how='left')\n",
    "print(SD.cellprops.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD.display_gating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use measure_DUSP1 to create SSIT compatible dataframe\n",
    "DUSP1_RepD = measure_DUSP1(SD.spots, SD.clusters, SD.cellprops)\n",
    "am.close()\n",
    "\n",
    "print(f'Total number of cells after filtering: {DUSP1_RepD.shape[0]}')\n",
    "print(f'Total number of spots counted: {np.sum(DUSP1_RepD['num_spots'])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 100nM Dex 3hr Time-sweep Replica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUSP1_RepE = filter_DUSP1('DUSP1_E_ERonRunAll')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 100nM Dex 3hr Time-sweep Replica 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUSP1_RepF = filter_DUSP1('DUSP1_F_ERonReRun')                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 100nM Dex 3hr Time-sweep Replica 4 (partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUSP1_RepM = filter_DUSP1('DUSP1_M_ERonRunAll')                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 100nM Dex 3hr Time-sweep Replica 5 (partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUSP1_RepN = filter_DUSP1('DUSP1_N_JacksRunAll')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 75min Concentration-sweep Replica 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUSP1_RepG = filter_DUSP1('DUSP1_G_ERonReRun')                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 75min Concentration-sweep Replica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUSP1_RepH = filter_DUSP1('DUSP1_H_ERonRunAll')                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 75min Concentration-sweep Replica 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUSP1_RepI = filter_DUSP1('DUSP1_I_JacksRunAll')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 0.3, 1, 10nM Dex 3hr Time-sweep Replica 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUSP1_RepJ = filter_DUSP1('DUSP1_J_ERonRunAll')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 0.3, 1, 10nM Dex 3hr Time-sweep Replica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUSP1_RepK = filter_DUSP1('DUSP1_K_ERonReRun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 0.3, 1, 10nM Dex 3hr Time-sweep Replica 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUSP1_RepL = filter_DUSP1('DUSP1_L_JacksRunAll')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 100nM Dex & 5µM TPL Time-sweep Replica 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUSP1_RepO_TPL = filter_DUSP1('DUSP1_O_JacksRunAll', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DUSP1 100nM Dex & 5µM TPL Time-sweep Replica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUSP1_RepP_TPL = filter_DUSP1('DUSP1_P_ERonReRun', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatonate all DUSP1 Dex experiments & reset 'unique_cell_id'\n",
    "DUSP1_ALL = pd.concat(\n",
    "[DUSP1_RepD, DUSP1_RepE, DUSP1_RepF, DUSP1_RepM, DUSP1_RepN, DUSP1_RepG, DUSP1_RepH, DUSP1_RepI, DUSP1_RepJ, DUSP1_RepK, DUSP1_RepL], ignore_index=True) # \n",
    "DUSP1_ALL['unique_cell_id'] = np.arange(len(DUSP1_ALL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter GR data:\n",
    "1. Remove partial cells\n",
    "2. Use `measure_GR` to prepare pre-SSIT dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    GR 1, 10, 100nM Dex 3hr Time-sweep Replica 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GR_RepA = filter_GR('GR_IC_A_ER020725')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    GR 1, 10, 100nM Dex 3hr Time-sweep Replica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GR_RepB = filter_GR('GR_IC_B_ReRun021025')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    GR 1, 10, 100nM Dex 3hr Time-sweep Replica 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GR_RepC = filter_GR('GR_IC_C_ER020725')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatonate all DUSP1 Dex experiments & reset 'unique_cell_id'\n",
    "GR_ALL = pd.concat(\n",
    "[GR_RepA, GR_RepB, GR_RepC], ignore_index=True) # DUSP1_RepN, DUSP1_RepJ\n",
    "GR_ALL['unique_cell_id'] = np.arange(len(GR_ALL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GR_ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GR_ALL & DUSP1_All final dataframe preperation for SSIT\n",
    "\n",
    "1) Fit a Polynomial (2nd-degree) using (nuc_area_px, cyto_area_px) from DUSP1_ALL.\n",
    "\n",
    "2) Estimate Cytoplasm Area in GR_ALL:\n",
    "3) Creates `CalcCytoArea` by evaluating the fitted polynomial at each row’s `nuc_area`.\n",
    "\n",
    "4) Gate both data sets on the 25%–75% range of nuclear area.\n",
    "\n",
    "5) Compute “Normalized” GR (`normGRnuc`, `normGRcyt`) in GR_ALL:\n",
    "- Scales nuclear/cyt intensities (5%→95% range) into integer bins [0,20].\n",
    "\n",
    "6) Plot Histograms for the normalized nuclear/cyt GR (using custom colors).\n",
    "\n",
    "7) Save the updated, gated data sets to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) READ INPUT DATA\n",
    "# =========================\n",
    "# DUSP1_ALL from above:\n",
    "df_dusp = DUSP1_ALL\n",
    "\n",
    "# GR_ALL from above:\n",
    "df_gr = GR_ALL\n",
    "\n",
    "\n",
    "# 2) FIT POLYNOMIAL TO (NUC, CYTO) FROM DUSP1_ALL\n",
    "# =========================\n",
    "# We'll use only the rows that have valid nuc_area_px and cyto_area_px.\n",
    "num_cells = df_dusp.shape[0]\n",
    "df_dusp_nonmissing = df_dusp.dropna(subset=['nuc_area_px', 'cyto_area_px']).copy()\n",
    "print(f'Cells removed because of NaN areas in DUSP1: {df_dusp_nonmissing.shape[0] - num_cells}')\n",
    "\n",
    "x_nuc = df_dusp_nonmissing['nuc_area_px'].values\n",
    "y_cyto = df_dusp_nonmissing['cyto_area_px'].values\n",
    "\n",
    "# Fit a 2nd-degree polynomial: cyto_area_px = a*(nuc_area_px)^2 + b*(nuc_area_px) + c\n",
    "poly_coeffs = np.polyfit(x_nuc, y_cyto, deg=2)\n",
    "\n",
    "# optional: for debugging/inspection\n",
    "# print(\"Fitted polynomial coefficients (a, b, c):\", poly_coeffs)\n",
    "\n",
    "\n",
    "# 3) ESTIMATE CYTO AREA IN GR_ALL\n",
    "# =========================\n",
    "# We'll store the computed cytoplasm area in a new column: 'CalcCytoArea'\n",
    "# Evaluate the polynomial at GR_ALL['nuc_area'].\n",
    "print('Predict the cyto area of GR from dusp1')\n",
    "df_gr['CalcCytoArea'] = np.polyval(poly_coeffs, df_gr['nuc_area'])\n",
    "\n",
    "\n",
    "\n",
    "# 4) GATE BOTH DATAFRAMES ON [25%, 75%] NUCLEAR AREA\n",
    "# =========================\n",
    "# We'll define a helper function for gating.\n",
    "num_cells = df_dusp.shape[0]\n",
    "def gate_on_nuc_area(df, nuc_col):\n",
    "    \"\"\"Return a copy of df gated to [25th, 75th percentile] of nuc_col.\"\"\"\n",
    "    lower = df[nuc_col].quantile(0.25)\n",
    "    upper = df[nuc_col].quantile(0.75)\n",
    "    return df[(df[nuc_col] >= lower) & (df[nuc_col] <= upper)].copy()\n",
    "\n",
    "# Gate DUSP1_ALL on nuc_area_px\n",
    "print('+++ Gating Nuc Area +++')\n",
    "df_dusp_gated = gate_on_nuc_area(df_dusp, 'nuc_area_px') # TODO: Eric is df_dusp the correct dataframe should it be df_dusp_nonmissing\n",
    "\n",
    "\n",
    "# Gate GR_ALL on nuc_area\n",
    "df_gr_gated = gate_on_nuc_area(df_gr, 'nuc_area')\n",
    "\n",
    "print(f\"DUSP1_ALL original: {len(df_dusp)} rows -> gated: {len(df_dusp_gated)} rows\")\n",
    "print(f\"GR_ALL original:    {len(df_gr)} rows -> gated: {len(df_gr_gated)} rows\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_dusp['nuc_area_px'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Nuclear Area (Before Gating)\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df_dusp_gated['nuc_area_px'], bins=30, color='orange', edgecolor='black')\n",
    "plt.title(\"Nuclear Area (After Gating)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_gr['nuc_area'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Nuclear Area (Before Gating)\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df_gr_gated['nuc_area'], bins=30, color='orange', edgecolor='black')\n",
    "plt.title(\"Nuclear Area (After Gating)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 5) COMPUTE \"NORMALIZED\" GR FOR NUC & CYTO IN GR_ALL\n",
    "# =========================\n",
    "# We'll do a percentile-based normalization: 5th->95th percentile => mapped to [0, bins].\n",
    "bins = 20\n",
    "\n",
    "def normalize_by_percentiles(series, low_pct=0.05, high_pct=0.95, bins=20):\n",
    "    \"\"\"Scale 'series' into integer bins [0, bins] based on [low_pct, high_pct].\"\"\"\n",
    "    lower_val = series.quantile(low_pct)\n",
    "    upper_val = series.quantile(high_pct)\n",
    "    clipped = (series - lower_val) / (upper_val - lower_val)\n",
    "    clipped = clipped.clip(lower=0, upper=1)\n",
    "    return (clipped * bins).round().astype(int)\n",
    "\n",
    "df_gr_gated['normGRnuc'] = normalize_by_percentiles(df_gr_gated['nucGRint'], 0.05, 0.95, bins=bins)\n",
    "df_gr_gated['normGRcyt'] = normalize_by_percentiles(df_gr_gated['cytoGRint'], 0.05, 0.95, bins=bins)\n",
    "\n",
    "\n",
    "# 6) HISTOGRAMS\n",
    "# =========================\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(df_gr_gated['nucGRint'], bins=bins+1, color='darkred', edgecolor='black')\n",
    "plt.title(\"Original GR (Nuclear)\")\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(df_gr_gated['cytoGRint'], bins=bins+1, color='navy', edgecolor='black')\n",
    "plt.title(\"Original GR (Cytoplasm)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(df_gr_gated['normGRnuc'], bins=bins+1, color='darkred', edgecolor='black')\n",
    "plt.title(\"Normalized GR (Nuclear)\")\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(df_gr_gated['normGRcyt'], bins=bins+1, color='navy', edgecolor='black')\n",
    "plt.title(\"Normalized GR (Cytoplasm)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) SAVE THE UPDATED GATED DATAFRAMES\n",
    "# =========================\n",
    "# Gated DUSP1 (unchanged except row filtering)\n",
    "df_dusp_gated.to_csv(\"DUSP1_ALL_gated_V01.csv\", index=False)\n",
    "\n",
    "# Gated GR with new columns: CalcCytoArea, normGRnuc, normGRcyt\n",
    "df_gr_gated.to_csv(\"GR_ALL_gated_with_CytoArea_and_normGR_V01.csv\", index=False)\n",
    "\n",
    "print(\"Saved gated DUSP1 to 'DUSP1_ALL_gated.csv'\")\n",
    "print(\"Saved gated GR to 'GR_ALL_gated_with_CytoArea_and_normGR.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
