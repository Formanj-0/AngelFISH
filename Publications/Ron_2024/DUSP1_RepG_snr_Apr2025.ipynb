{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUSP1 Analysis and Visualization Notebook\n",
    "\n",
    "This notebook demonstrates how to use the new analysis manager code from `Analysis_DUSP1.py`.\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Load the processed CSV files (spots, clusters, and cell properties).\n",
    "2. Instantiate the measurement manager (DUSP1Measurement) and compute cell-level metrics,\n",
    "   with optional SNR filtering.\n",
    "3. Create a DisplayManager instance to visualize gating overlays and cell crops.\n",
    "4. (Optional) Use the new expression grouping and visualization functions.\n",
    "\n",
    "Make sure that `Analysis_DUSP1.py` is in the same directory or on the Python path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "# Today's date\n",
    "today = datetime.date.today()\n",
    "# Format date as 'Mar21' (for example)\n",
    "date_str = today.strftime(\"%b%d\")\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)\n",
    "\n",
    "matplotlib_logger = logging.getLogger('matplotlib')\n",
    "matplotlib_logger.setLevel(logging.WARNING)\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "print(src_path)\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.Analysis_DUSP1_v2 import DUSP1AnalysisManager, SNRAnalysis, DUSP1Measurement, DUSP1DisplayManager, DUSP1_filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the log file to search for analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = None\n",
    "log_location = r'/Volumes/share/Users/Eric/GR_DUSP1_reruns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = DUSP1AnalysisManager(location=loc, log_location=log_location, mac=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all analysis done \n",
    "all_analysis_names = am.list_analysis_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the class and find analysis at log_location\n",
    "# Select the specific analysis - ex. DUSP1 Dex Time-Concentration Sweep Replica 1\n",
    "am.select_analysis('DUSP1_G_Final')\n",
    "print('locations with this dataset:', am.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "spots_df = am.select_datasets(\"spotresults\", dtype=\"dataframe\")\n",
    "clusters_df = am.select_datasets(\"clusterresults\", dtype=\"dataframe\")\n",
    "props_df = am.select_datasets(\"cell_properties\", dtype=\"dataframe\")\n",
    "cellresults_df = am.select_datasets(\"cellresults\", dtype=\"dataframe\")\n",
    "\n",
    "print(\"Spots shape:\", spots_df.shape)\n",
    "print(\"Clusters shape:\", clusters_df.shape)\n",
    "print(\"Cell properties shape:\", props_df.shape)\n",
    "print(\"Cell results shape:\", cellresults_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Compute Cell-Level Metrics with Different SNR Filtering Methods\n",
    "\n",
    "We create three DUSP1Measurement objects (or re-use one with different filtering options)\n",
    "to compare the following methods:\n",
    "- Weighted: uses weighted thresholding based on 'snr'.\n",
    "- Absolute: keeps spots with snr >= 4.\n",
    "- MG: computes MG_SNR and keeps spots with MG_SNR >= mg_threshold.\n",
    "\n",
    "Note: Adjust the snr_threshold for MG if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Thresholds\n",
    "abs_threshold = 4\n",
    "mg_threshold = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_df = SNRAnalysis(spots_df, props_df, clusters_df, abs_threshold=abs_threshold, mg_threshold=mg_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_spots_df, merged_clusters_df, merged_cellprops_df = snr_df.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of spots:', merged_spots_df['unique_spot_id'].count())\n",
    "print('Number of cells:', len(merged_spots_df['unique_cell_id'].unique()))\n",
    "print('Numcer of cells from cell properties:', len(merged_cellprops_df['unique_cell_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique time points and sort them.\n",
    "unique_conc = sorted(merged_spots_df['dex_conc'].unique())\n",
    "\n",
    "for c in unique_conc:\n",
    "    subset = merged_spots_df[merged_spots_df['dex_conc'] == c]\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.hist(subset['snr'], bins=50, alpha=0.5, edgecolor='black', label='snr')\n",
    "    plt.hist(subset['MG_SNR'], bins=50, alpha=0.5, edgecolor='black', label='MG_SNR')\n",
    "    plt.axvline(4, color='red', linestyle='dashed', linewidth=2, label='Absolute Threshold (4)')\n",
    "    plt.title(f'Distribution of snr and MG_SNR at time {c}')\n",
    "    plt.xlabel('Intensity Value')\n",
    "    plt.xlim(-10, 50)\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by dex_conc and calculate the fraction passing each threshold.\n",
    "time_groups = merged_spots_df.groupby('dex_conc')\n",
    "abs_fraction = time_groups['absolute'].mean()  # True = 1, so the mean is the fraction passing.\n",
    "weighted_fraction = time_groups['weighted'].mean()\n",
    "mg_fraction = time_groups['MG_pass'].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(abs_fraction.index, abs_fraction, marker='o', label='Absolute Threshold (>=4)')\n",
    "plt.plot(weighted_fraction.index, weighted_fraction, marker='o', label='Weighted Threshold')\n",
    "plt.plot(mg_fraction.index, mg_fraction, marker='o', label='MG_SNR Threshold')\n",
    "plt.axhline(0.5, color='red', linestyle='dashed', linewidth=2, label='50% Passing')\n",
    "plt.title('Fraction of Spots Passing Thresholds by Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Fraction Passing')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample up to 1000 spots per dex_conc for visualization.\n",
    "sampled_df = merged_spots_df.groupby('dex_conc', group_keys=False).apply(lambda x: x.sample(min(1000, len(x))))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(sampled_df['snr'], sampled_df['MG_SNR'], alpha=0.3)\n",
    "plt.xlabel('snr (Signal to Local Background)')\n",
    "plt.ylabel('MG_SNR (Signal to Cell Background)')\n",
    "plt.title('Scatter Plot of snr vs MG_SNR (Sampled)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the DUSP1Measurement class.\n",
    "dusp = DUSP1Measurement(merged_spots_df, merged_clusters_df, merged_cellprops_df)\n",
    "\n",
    "# Process the data with a chosen SNR threshold \n",
    "cell_level_results = dusp.measure(snr_threshold=4, mg_threshold=mg_threshold)\n",
    "\n",
    "# Now cell_level_results is a cell-level dataframe that you can use for comparisons,\n",
    "# downstream analysis, or plotting with your preferred tools.\n",
    "print(cell_level_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the output directory\n",
    "# output_dir = f'/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/dataframes'\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # Save dataframes to CSV with today's date appended to the filename.\n",
    "# cell_level_results.to_csv(os.path.join(output_dir, f'TS_R1_cell_level_results_{date_str}.csv'))\n",
    "# merged_spots_df.to_csv(os.path.join(output_dir, f'DUSP1_D_merged_spots_{date_str}.csv'))\n",
    "# merged_clusters_df.to_csv(os.path.join(output_dir, f'DUSP1_D_merged_clusters_{date_str}.csv'))\n",
    "# merged_cellprops_df.to_csv(os.path.join(output_dir, f'DUSP1_D_merged_cellprops_{date_str}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out partial cells and spots that are not passing the SNR threshold method.\n",
    "filtering = DUSP1_filtering(method='MG')\n",
    "filtered_cell_level_results = filtering.apply(cell_level_results)\n",
    "filtered_spots, removed_spots = filtering.apply_spots(merged_spots_df, results=filtered_cell_level_results)\n",
    "filtered_clusters, filtered_cellprops = filtering.remove_partial_cells(merged_clusters_df, merged_cellprops_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the keys of the filtered dataframes.\n",
    "filtered_cell_level_results.keys()\n",
    "filtered_spots.keys()\n",
    "filtered_clusters.keys()\n",
    "filtered_cellprops.keys()\n",
    "# Check the number of spots before and after filtering.\n",
    "print(\"Number of spots before filtering:\", merged_spots_df.shape[0])\n",
    "print(\"Number of spots after filtering:\", filtered_spots.shape[0])\n",
    "print(\"Number of spots removed:\", removed_spots.shape[0])\n",
    "# Check the number of cells before and after filtering.\n",
    "print(\"Number of cells before filtering:\", merged_cellprops_df.shape[0])\n",
    "print(\"Number of cells after filtering:\", filtered_cellprops.shape[0])\n",
    "# Check the number of clusters before and after filtering.\n",
    "print(\"Number of clusters before filtering:\", merged_clusters_df.shape[0])\n",
    "print(\"Number of clusters after filtering:\", filtered_clusters.shape[0])\n",
    "# Check the number of cells that were removed.\n",
    "print(\"Number of cells removed:\", merged_cellprops_df.shape[0] - filtered_cellprops.shape[0])\n",
    "# Check the number of clusters that were removed.\n",
    "print(\"Number of clusters removed:\", merged_clusters_df.shape[0] - filtered_clusters.shape[0])\n",
    "# Check the number of spots that were removed.\n",
    "print(\"Number of spots removed:\", merged_spots_df.shape[0] - filtered_spots.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_dir = f'/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/dataframes'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save filtered dataframes to CSV with today's date in the filename.\n",
    "filtered_cell_level_results.to_csv(os.path.join(output_dir,f'DUSP1_G_cell_level_results_{date_str}_filtered_MG{mg_threshold}.csv'))\n",
    "filtered_spots.to_csv(os.path.join(output_dir,f'DUSP1_G_merged_spots_{date_str}_filtered_MG{mg_threshold}.csv'))\n",
    "removed_spots.to_csv(os.path.join(output_dir,f'DUSP1_G_merged_spots_{date_str}_removed_MG{mg_threshold}.csv'))\n",
    "filtered_clusters.to_csv(os.path.join(output_dir,f'DUSP1_G_merged_clusters_{date_str}_filtered_MG{mg_threshold}.csv'))\n",
    "filtered_cellprops.to_csv(os.path.join(output_dir,f'DUSP1_G_merged_cellprops_{date_str}_filtered_MG{mg_threshold}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load in csv files\n",
    "# filtered_cell_level_results = pd.read_csv('/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/dataframes/DUSP1_G_cell_level_results_Apr18_filtered.csv')\n",
    "# filtered_spots = pd.read_csv('/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/dataframes/DUSP1_G_merged_spots_Apr18_filtered.csv')\n",
    "# removed_spots = pd.read_csv('/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/dataframes/DUSP1_G_merged_spots_Apr18_removed.csv')\n",
    "# filtered_clusters = pd.read_csv('/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/dataframes/DUSP1_G_merged_clusters_Apr18_filtered.csv')\n",
    "# filtered_cellprops = pd.read_csv('/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/dataframes/DUSP1_G_merged_cellprops_Apr18_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================================\n",
    "# Settings and Data\n",
    "# ============================================================================\n",
    "metrics = ['nuc_MG_count', 'cyto_MG_count', 'MG_count', 'num_ts', 'num_foci']\n",
    "\n",
    "# Sorted unique values for concentrations and time\n",
    "concentrations = sorted(filtered_cell_level_results['dex_conc'].unique())\n",
    "timepoints = sorted(filtered_cell_level_results['time'].unique())\n",
    "\n",
    "# Set common aesthetics\n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Make a copy of the main dataframe\n",
    "df = filtered_cell_level_results.copy()\n",
    "\n",
    "# ============================================================================\n",
    "# Get the control (baseline) data: all rows with time == 0.\n",
    "# ============================================================================\n",
    "reference_data = df[df['time'] == 0]\n",
    "print(\"Reference (control) data sample:\")\n",
    "print(reference_data.head())\n",
    "\n",
    "# For the histograms below, we also calculate CDF thresholds based on one metric.\n",
    "# (In this example, we use 'nuc_MG_count'; update as needed for other metrics.)\n",
    "cdf_values = np.sort(reference_data['nuc_MG_count'])\n",
    "cdf = np.arange(1, len(cdf_values) + 1) / len(cdf_values)\n",
    "cdf_50_threshold = np.interp(0.50, cdf, cdf_values)\n",
    "cdf_95_threshold = np.interp(0.95, cdf, cdf_values)\n",
    "\n",
    "# Define the concentrations and desired timepoints for the histograms (e.g., concentration 100 only)\n",
    "concentrations_to_plot = [0, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]  # modify as needed\n",
    "desired_timepoints = [75]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 1. HISTOGRAMS\n",
    "# For each desired timepoint and concentration, compare the histogram for the \n",
    "# experimental condition (given dex_conc and time) with the control (time==0) data.\n",
    "# ============================================================================\n",
    "for time in desired_timepoints:\n",
    "    for dex_conc in concentrations_to_plot:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        specific_data = df[(df['dex_conc'] == dex_conc) & (df['time'] == time)]\n",
    "        \n",
    "        sns.histplot(reference_data['nuc_MG_count'], color='grey', label='Control (0 min)', kde=True)\n",
    "        sns.histplot(specific_data['nuc_MG_count'], color='blue', label=f'{dex_conc} nM, {time} min', kde=True)\n",
    "        \n",
    "        plt.axvline(cdf_50_threshold, color='red', linestyle='--', label='CDF 50% Threshold')\n",
    "        plt.axvline(cdf_95_threshold, color='red', linestyle='-',  label='CDF 95% Threshold')\n",
    "        \n",
    "        plt.annotate(f'Ref Cell Count: {len(reference_data)}\\nSpec Cell Count: {len(specific_data)}',\n",
    "                     xy=(0.77, 0.70), xycoords='axes fraction', verticalalignment='top')\n",
    "        plt.title(f'Nuclear Distribution Comparison: Control vs {dex_conc} nM, {time} min')\n",
    "        plt.xlabel('nuc_MG_count')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 2. LINE PLOTS (with control overlay)\n",
    "# For each concentration, plot the mean metric value over time\n",
    "# and overlay a horizontal dashed line indicating the control (0 min) mean.\n",
    "# ============================================================================\n",
    "for conc in concentrations:\n",
    "    fig, axes = plt.subplots(1, len(metrics), figsize=(5 * len(metrics), 5))\n",
    "    fig.suptitle(f'Line Plots with Shared Control — Concentration {conc} nM', fontsize=16)\n",
    "\n",
    "    # Experimental data for this concentration\n",
    "    data_conc = df[df['dex_conc'] == conc]\n",
    "\n",
    "    # Control data (baseline): dex_conc == 0 and time == 0\n",
    "    control_data = df[(df['dex_conc'] == 0) & (df['time'] == 0)]\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Experimental mean metric over time\n",
    "        grouped_exp = data_conc.groupby('dex_conc')[metric].mean().reset_index()\n",
    "\n",
    "        # Add baseline mean as the 0 min point\n",
    "        if not control_data.empty:\n",
    "            control_mean = control_data[metric].mean()\n",
    "            # Create a new row at time=0\n",
    "            control_point = pd.DataFrame({'time': [0], metric: [control_mean]})\n",
    "            # Concatenate with experimental data\n",
    "            combined = pd.concat([control_point, grouped_exp], ignore_index=True)\n",
    "        else:\n",
    "            combined = grouped_exp.copy()\n",
    "\n",
    "        sns.lineplot(data=combined, x='dex_conc', y=metric, marker='o', ax=ax, label=f'{conc} nM + Control')\n",
    "\n",
    "        ax.set_title(metric)\n",
    "        ax.set_xlabel('Time (min)')\n",
    "        ax.set_ylabel(f'Mean {metric}')\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 3. BAR PLOTS (with control overlay)\n",
    "# For each concentration, plot a bar chart displaying the mean metric value at each timepoint\n",
    "# and overlay a horizontal dashed line indicating the control (0 min) mean.\n",
    "# ============================================================================\n",
    "for conc in concentrations:\n",
    "    fig, axes = plt.subplots(1, len(metrics), figsize=(5 * len(metrics), 5))\n",
    "    fig.suptitle(f'Bar Plots for Concentration {conc} nM', fontsize=16)\n",
    "    \n",
    "    # Data for this concentration\n",
    "    data_conc = df[df['dex_conc'] == conc]\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i]\n",
    "        df_grouped = data_conc.groupby('dex_conc')[metric].mean().reset_index()\n",
    "        sns.barplot(data=df_grouped, x='dex_conc', y=metric, ax=ax, palette='viridis')\n",
    "        \n",
    "        # Compute control mean from reference\n",
    "        control_mean = reference_data[metric].mean()\n",
    "        ax.axhline(control_mean, color='black', linestyle='--', label='Control (0 min)')\n",
    "        \n",
    "        ax.set_title(metric)\n",
    "        ax.set_xlabel('Dex (nM)')\n",
    "        ax.set_ylabel(f'Mean {metric}')\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 4. CATEGORY-BASED BAR PLOTS FOR 'num_ts' and 'num_foci'\n",
    "# For each concentration, display for each timepoint the fraction (percentage) of cells \n",
    "# falling into the categories \"0\", \"1\", \"2\", \"3\", or \">=4\".\n",
    "# Now baseline (control) data is included by concatenating the control data.\n",
    "# ============================================================================\n",
    "def cat_func(x):\n",
    "    if x == 1:\n",
    "        return '1'\n",
    "    elif x == 2:\n",
    "        return '2'\n",
    "    elif x == 3:\n",
    "        return '3'\n",
    "    elif x >= 4:\n",
    "        return '>=4'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "cat_metrics = ['num_ts', 'num_foci']\n",
    "\n",
    "for conc in concentrations:\n",
    "    data_conc = df[df['dex_conc'] == conc]\n",
    "    control_data = df[(df['time'] == 0) & (df['dex_conc'] == 0)]\n",
    "    data_for_plot = pd.concat([control_data, data_conc], ignore_index=True)\n",
    "    time_points = sorted(data_for_plot['dex_conc'].unique())\n",
    "\n",
    "    fig, axes = plt.subplots(len(time_points), len(cat_metrics), \n",
    "                             figsize=(8 * len(cat_metrics), 4 * len(time_points)))\n",
    "\n",
    "    # ---- MAKE AXES ALWAYS 2D ----\n",
    "    if len(time_points) == 1 and len(cat_metrics) == 1:\n",
    "        axes = np.array([[axes]])\n",
    "    elif len(time_points) == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "    elif len(cat_metrics) == 1:\n",
    "        axes = np.expand_dims(axes, axis=1)\n",
    "    # -----------------------------\n",
    "\n",
    "    fig.suptitle(f'Percentage of Cells by TS Category for {conc} nM (including control)', fontsize=16)\n",
    "\n",
    "    for row, t in enumerate(time_points):\n",
    "        for col, metric in enumerate(cat_metrics):\n",
    "            ax = axes[row][col]\n",
    "            subset = data_for_plot[data_for_plot['dex_conc'] == t].copy()\n",
    "            subset['category'] = subset[metric].apply(cat_func)\n",
    "\n",
    "            counts = subset['category'].value_counts(normalize=True).sort_index() * 100\n",
    "            categories = ['0', '1', '2', '3', '>=4']\n",
    "            counts = counts.reindex(categories, fill_value=0)\n",
    "\n",
    "            sns.barplot(x=counts.index, y=counts.values, ax=ax, palette='viridis')\n",
    "            ax.set_title(f'{metric} at {t} nM')\n",
    "            ax.set_xlabel('Category')\n",
    "            ax.set_ylabel('Percentage (%)')\n",
    "\n",
    "            for i, v in enumerate(counts.values):\n",
    "                ax.text(i, v + 1, f\"{v:.1f}%\", ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = DUSP1AnalysisManager(location=loc, log_location=log_location, mac=True)\n",
    "am.select_analysis('DUSP1_G_Final')\n",
    "\n",
    "display_manager = DUSP1DisplayManager(am, \n",
    "                                      cell_level_results=filtered_cell_level_results,\n",
    "                                      spots=filtered_spots,\n",
    "                                      clusters=filtered_clusters,\n",
    "                                      cellprops=filtered_cellprops,\n",
    "                                      method='MG',\n",
    "                                      removed_spots=removed_spots)\n",
    "# Run the main display function.\n",
    "display_manager.main_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
