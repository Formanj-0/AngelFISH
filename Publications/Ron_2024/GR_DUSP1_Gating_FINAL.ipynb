{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  GR DUSP1 Gating Notebook\n",
    "\n",
    "The Purpose of this notebook is:\n",
    "1) Load in all analyisis for final dataframe preparation (GR_Confirmation)\n",
    "3) Filter GR data to remove partial cells\n",
    "4) Estimate GR cytoplasmic area from DUPS1 data\n",
    "5) GR intensity to molecular counts \n",
    "6) Concatonate final GR and DUSP1 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ericron/Desktop/AngelFISH\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import glob\n",
    "\n",
    "# Today's date\n",
    "today = datetime.date.today()\n",
    "# Format date as 'Jun03' (for example)\n",
    "date_str = today.strftime(\"%b%d\")\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)\n",
    "\n",
    "matplotlib_logger = logging.getLogger('matplotlib')\n",
    "matplotlib_logger.setLevel(logging.WARNING)\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "print(src_path)\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.Analysis_DUSP1 import DUSP1DisplayManager, PostProcessingPlotter, ExperimentPlotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory containing your CSV files\n",
    "base_dir = \"/Volumes/share/Users/Eric/GR_DUSP1_AllData/DUSP1_FinalAnalysis_061925\"\n",
    "save_dir = \"/Volumes/share/Users/Eric/GR_DUSP1_AllData/DUSP1_FinalAnalysis_061925/ConcatPlots\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to load and concat by pattern\n",
    "def load_and_concat(pattern):\n",
    "    paths = glob.glob(os.path.join(base_dir, pattern))\n",
    "    dfs = []\n",
    "    for path in paths:\n",
    "        df = pd.read_csv(path)\n",
    "        # normalize columns to lowercase\n",
    "        df.columns = [c.lower() for c in df.columns]\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 34930 entries in SSIT did not match replica pattern.\n",
      "Warning: 6131741 entries in Spots did not match replica pattern.\n",
      "Warning: 36562 entries in Clusters did not match replica pattern.\n",
      "Warning: 34930 entries in CellProps did not match replica pattern.\n",
      "SSIT cells: 34930\n",
      "Spots:      6131741\n",
      "Clusters:   36562\n",
      "Cell props: 34930\n"
     ]
    }
   ],
   "source": [
    "# Load each dataset\n",
    "ssit_all      = load_and_concat(\"*_SSITcellresults.csv\")\n",
    "spots_all     = load_and_concat(\"*_FinalSpots.csv\")\n",
    "clusters_all  = load_and_concat(\"*_FinalClusters.csv\")\n",
    "cellprops_all = load_and_concat(\"*_FinalCellProps.csv\")\n",
    "\n",
    "# Extract replica letter from strings like \"D_slide1\", \"E_day2\", etc.\n",
    "for df in [ssit_all, spots_all, clusters_all, cellprops_all]:\n",
    "    df['replica'] = df['replica'].str.extract(r'^([D-N])_')\n",
    "\n",
    "# Optional: warn if any entries didn’t match\n",
    "for name, df in zip(\n",
    "    ['SSIT', 'Spots', 'Clusters', 'CellProps'],\n",
    "    [ssit_all, spots_all, clusters_all, cellprops_all]\n",
    "):\n",
    "    n_missing = df['replica'].isna().sum()\n",
    "    if n_missing > 0:\n",
    "        print(f\"Warning: {n_missing} entries in {name} did not match replica pattern.\")\n",
    "\n",
    "# Quick check on length of each dataset\n",
    "print(f\"SSIT cells: {len(ssit_all)}\")\n",
    "print(f\"Spots:      {len(spots_all)}\")\n",
    "print(f\"Clusters:   {len(clusters_all)}\")\n",
    "print(f\"Cell props: {len(cellprops_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute quartiles on 'nuc_area'\n",
    "q_low  = cellprops_all['nuc_area'].quantile(0.25)\n",
    "q_high = cellprops_all['nuc_area'].quantile(0.75)\n",
    "\n",
    "# Filter cellprops by nuclear area range\n",
    "gated_cells = cellprops_all[(cellprops_all['nuc_area'] >= q_low) &\n",
    "                             (cellprops_all['nuc_area'] <= q_high)].copy()\n",
    "\n",
    "# Extract unique_cell_ids for gating\n",
    "gated_ids = gated_cells['unique_cell_id'].unique()\n",
    "\n",
    "# Subset SSIT and clusters by gated unique_cell_id\n",
    "ssit_gated     = ssit_all[ssit_all['unique_cell_id'].isin(gated_ids)].copy()\n",
    "clusters_gated = clusters_all[clusters_all['unique_cell_id'].isin(gated_ids)].copy()\n",
    "spots_gated    = spots_all[spots_all['unique_cell_id'].isin(gated_ids)].copy()\n",
    "\n",
    "display(gated_cells.shape, ssit_gated.shape, clusters_gated.shape, spots_gated.shape)\n",
    "\n",
    "# Print cells before and after gating\n",
    "print(f\"Cells before gating: {cellprops_all['unique_cell_id'].nunique()}\")\n",
    "print(f\"Cells after gating: {gated_cells['unique_cell_id'].nunique()}\")\n",
    "# Print spots before and after gating\n",
    "print(f\"Spots before gating: {spots_all['unique_cell_id'].nunique()}\")\n",
    "print(f\"Spots after gating: {spots_gated['unique_cell_id'].nunique()}\")\n",
    "# Print clusters before and after gating\n",
    "print(f\"Clusters before gating: {clusters_all['unique_cell_id'].nunique()}\")\n",
    "print(f\"Clusters after gating: {clusters_gated['unique_cell_id'].nunique()}\")\n",
    "\n",
    "# Save the gated data\n",
    "gated_cells.to_csv(os.path.join(save_dir, f'gated_cells_{date_str}.csv'), index=False)\n",
    "ssit_gated.to_csv(os.path.join(save_dir, f'ssit_gated_{date_str}.csv'), index=False)\n",
    "clusters_gated.to_csv(os.path.join(save_dir, f'clusters_gated_{date_str}.csv'), index=False)\n",
    "spots_gated.to_csv(os.path.join(save_dir, f'spots_gated_{date_str}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the gated data (if already saved)\n",
    "df_dir = \"/Volumes/share/Users/Eric/GR_DUSP1_AllData/DUSP1_AllAnalysis_061725/ConcatPlots\"\n",
    "# gated_cells = pd.read_csv(os.path.join(save_dir, f'gated_cells_{date_str}.csv'))\n",
    "ssit_gated = pd.read_csv(os.path.join(df_dir, f'ssit_gated_Jun17.csv'))\n",
    "# clusters_gated = pd.read_csv(os.path.join(save_dir, f'clusters_gated_{date_str}.csv'))\n",
    "# spots_gated = pd.read_csv(os.path.join(save_dir, f'spots_gated_{date_str}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssit_gated.keys() # Display keys of the gated SSIT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of unique cell IDs in the gated SSIT data\n",
    "print(f\"Unique cell IDs in gated SSIT data: {ssit_gated['unique_cell_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssit_gated['replica'].unique()  # Display unique replicates in the gated SSIT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = ExperimentPlotter(ssit_gated)\n",
    "\n",
    "# 1) 100 nM Time Sweep:\n",
    "plotter.plot_experiment(\n",
    "    replicas=['D','E','F','M','N'],\n",
    "    times=[10,20,30,40,50,60,75,90,120,150,180],\n",
    "    concs=[100],\n",
    "    save_dir=save_dir\n",
    ")\n",
    "\n",
    "# 2) 75 min Conc Sweep:\n",
    "plotter.plot_experiment(\n",
    "    replicas=['G','H','I'],\n",
    "    times=[75],\n",
    "    concs=[0.001,0.01,0.1,1,10,100,1000,10000],\n",
    "    save_dir=save_dir\n",
    ")\n",
    "\n",
    "# 3) Both‐varying: 0.3,1,10 nM across multiple times:\n",
    "plotter.plot_experiment(\n",
    "    replicas=['J','K','L'],\n",
    "    times=[30,50,75,90,120,180],\n",
    "    concs=[0.3,1,10],\n",
    "    save_dir=save_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cytoplasmic and Nuclear mRNA Spot Counts at 0 min\n",
    "\n",
    "# Make a copy of the DUSP1 data\n",
    "DUSP1_data = ssit_gated.copy()\n",
    "\n",
    "# Subset data for 0 min time points\n",
    "df_0min = DUSP1_data[DUSP1_data['time'] == 0]\n",
    "\n",
    "# Plot distribution of nuclear and cytoplasmic mRNA spots across replicas for 0 min time point\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "sns.boxplot(data=df_0min, x='replica', y='num_nuc_spots', ax=axes[0])\n",
    "axes[0].set_title('Nuclear mRNA Spot Counts at 0 min')\n",
    "axes[0].set_ylabel('Nuclear Spot Count')\n",
    "axes[0].set_xlabel('Replica')\n",
    "\n",
    "sns.boxplot(data=df_0min, x='replica', y='num_cyto_spots', ax=axes[1])\n",
    "axes[1].set_title('Cytoplasmic mRNA Spot Counts at 0 min')\n",
    "axes[1].set_ylabel('Cytoplasmic Spot Count')\n",
    "axes[1].set_xlabel('Replica')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
