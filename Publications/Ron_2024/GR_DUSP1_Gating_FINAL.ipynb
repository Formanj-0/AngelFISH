{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  GR DUSP1 Gating Notebook\n",
    "\n",
    "The Purpose of this notebook is:\n",
    "1) Load in all analyisis for final dataframe preparation (GR_Confirmation)\n",
    "3) Filter GR data to remove partial cells\n",
    "4) Estimate GR cytoplasmic area from DUPS1 data\n",
    "5) GR intensity to molecular counts \n",
    "6) Concatonate final GR and DUSP1 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import glob\n",
    "\n",
    "# Today's date\n",
    "today = datetime.date.today()\n",
    "# Format date as 'Jun03' (for example)\n",
    "date_str = today.strftime(\"%b%d\")\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)\n",
    "\n",
    "matplotlib_logger = logging.getLogger('matplotlib')\n",
    "matplotlib_logger.setLevel(logging.WARNING)\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "print(src_path)\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.Analysis_DUSP1 import DUSP1DisplayManager, PostProcessingPlotter, ExperimentPlotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory containing your CSV files\n",
    "base_dir = \"/Volumes/share/Users/Eric/GR_DUSP1_AllData/DUSP1_FinalAnalysis_062425\"\n",
    "save_dir = \"/Volumes/share/Users/Eric/GR_DUSP1_AllData/DUSP1_FinalAnalysis_062425/ConcatPlots\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to load and concat by pattern\n",
    "def load_and_concat(pattern):\n",
    "    paths = glob.glob(os.path.join(base_dir, pattern))\n",
    "    dfs = []\n",
    "    for path in paths:\n",
    "        df = pd.read_csv(path)\n",
    "        # normalize columns to lowercase\n",
    "        df.columns = [c.lower() for c in df.columns]\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each DUSP1 dataset\n",
    "ssit_all      = load_and_concat(\"*_SSITcellresults.csv\")\n",
    "spots_all     = load_and_concat(\"*_FinalSpots.csv\")\n",
    "clusters_all  = load_and_concat(\"*_FinalClusters.csv\")\n",
    "cellprops_all = load_and_concat(\"*_FinalCellProps.csv\")\n",
    "\n",
    "# Extract replica letter from strings like \"D_slide1\", \"E_day2\", etc.\n",
    "for df in [ssit_all, spots_all, clusters_all, cellprops_all]:\n",
    "    df['replica'] = df['replica'].str.extract(r'^([D-N])_')\n",
    "\n",
    "# Optional: warn if any entries didn’t match\n",
    "for name, df in zip(\n",
    "    ['SSIT', 'Spots', 'Clusters', 'CellProps'],\n",
    "    [ssit_all, spots_all, clusters_all, cellprops_all]\n",
    "):\n",
    "    n_missing = df['replica'].isna().sum()\n",
    "    if n_missing > 0:\n",
    "        print(f\"Warning: {n_missing} entries in {name} did not match replica pattern.\")\n",
    "\n",
    "# Quick check on length of each dataset\n",
    "print(f\"SSIT cells: {len(ssit_all)}\")\n",
    "print(f\"Spots:      {len(spots_all)}\")\n",
    "print(f\"Clusters:   {len(clusters_all)}\")\n",
    "print(f\"Cell props: {len(cellprops_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_replica_prefix(df: pd.DataFrame,\n",
    "                       replica_col: str = 'replica',\n",
    "                       id_col: str = 'unique_cell_id',\n",
    "                       prefix_map: dict[str, int] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each replica in prefix_map, offset its unique_cell_id by\n",
    "      prefix * (10 ** num_digits)\n",
    "    where num_digits is the number of digits in that replica’s max ID.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Your dataframe containing replica_col and id_col.\n",
    "    replica_col : str\n",
    "        Name of column holding replica labels (e.g. 'A','B','C').\n",
    "    id_col : str\n",
    "        Name of the integer column to rewrite.\n",
    "    prefix_map : dict[str,int]\n",
    "        Mapping of replica → small integer prefix.\n",
    "        E.g. {'A':1, 'B':2, 'C':3}.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The same df, with id_col updated in place.\n",
    "    \"\"\"\n",
    "    if prefix_map is None:\n",
    "        raise ValueError(\"You must supply a prefix_map, e.g. {'A':1,'B':2,'C':3}\")\n",
    "\n",
    "    for rep, prefix in prefix_map.items():\n",
    "        mask = df[replica_col] == rep\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        # compute number of digits based on this replica’s max ID\n",
    "        max_id = int(df.loc[mask, id_col].max())\n",
    "        num_digits = len(str(max_id))\n",
    "\n",
    "        offset = prefix * (10 ** num_digits)\n",
    "        df.loc[mask, id_col] = df.loc[mask, id_col] + offset\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the GR data\n",
    "gr_data = pd.read_csv('/Users/ericron/Desktop/AngelFISH/Publications/Ron_2024/dataframes/GR_ALL_noIC_pregate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the prefixes you want:\n",
    "prefix_map = {'A':150, 'B':160, 'C':170}\n",
    "\n",
    "# apply the function\n",
    "gr_data = add_replica_prefix(gr_data,\n",
    "                        replica_col='replica',\n",
    "                        id_col='unique_cell_id',\n",
    "                        prefix_map=prefix_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) FIT POLYNOMIAL TO (NUC, CYTO) FROM DUSP1_ALL\n",
    "# =========================\n",
    "# We'll use only the rows that have valid nuc_area_px and cyto_area_px.\n",
    "\n",
    "\n",
    "x_nuc = ssit_all['nuc_area'].values\n",
    "y_cyto = ssit_all['cyto_area'].values\n",
    "\n",
    "# Fit a 2nd-degree polynomial: cyto_area_px = a*(nuc_area_px)^2 + b*(nuc_area_px) + c\n",
    "poly_coeffs = np.polyfit(x_nuc, y_cyto, deg=2)\n",
    "\n",
    "# optional: for debugging/inspection\n",
    "print(\"Fitted polynomial coefficients (a, b, c):\", poly_coeffs)\n",
    "# plot the fitted polynomial on the data\n",
    "plt.scatter(x_nuc, y_cyto, label='data')\n",
    "x_fit = np.linspace(x_nuc.min(), x_nuc.max(), 100)\n",
    "y_fit = np.polyval(poly_coeffs, x_fit)\n",
    "plt.plot(x_fit, y_fit, label='fitted polynomial', color='red')\n",
    "plt.xlabel('Nuclear area (px)')\n",
    "plt.ylabel('Cytoplasm area (px)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 3) ESTIMATE CYTO AREA IN GR_ALL\n",
    "# =========================\n",
    "# We'll store the computed cytoplasm area in a new column: 'CalcCytoArea'\n",
    "# Evaluate the polynomial at GR_ALL['nuc_area'].\n",
    "print('Predict the cyto area of GR from dusp1')\n",
    "gr_data['CalcCytoArea'] = np.polyval(poly_coeffs, gr_data['nuc_area'])\n",
    "\n",
    "# 4) GATE BOTH DATAFRAMES ON [25%, 75%] NUCLEAR AREA\n",
    "# =========================\n",
    "# We'll define a helper function for gating.\n",
    "num_cells = ssit_all.shape[0]\n",
    "def gate_on_nuc_area(df, nuc_col):\n",
    "    \"\"\"Return a copy of df gated to [25th, 75th percentile] of nuc_col.\"\"\"\n",
    "    lower = df[nuc_col].quantile(0.25)\n",
    "    upper = df[nuc_col].quantile(0.75)\n",
    "    return df[(df[nuc_col] >= lower) & (df[nuc_col] <= upper)].copy()\n",
    "\n",
    "# Gate DUSP1_ALL on nuc_area_px\n",
    "print('+++ Gating Nuc Area +++')\n",
    "df_dusp_gated = gate_on_nuc_area(ssit_all, 'nuc_area') \n",
    "\n",
    "# Gate GR_ALL on nuc_area\n",
    "df_gr_gated = gate_on_nuc_area(gr_data, 'nuc_area')\n",
    "\n",
    "print(f\"DUSP1_ALL original: {len(ssit_all)} rows -> gated: {len(df_dusp_gated)} rows\")\n",
    "print(f\"GR_ALL original:    {len(gr_data)} rows -> gated: {len(df_gr_gated)} rows\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(ssit_all['nuc_area'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Nuclear Area (Before Gating)\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df_dusp_gated['nuc_area'], bins=30, color='orange', edgecolor='black')\n",
    "plt.title(\"Nuclear Area (After Gating)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(gr_data['nuc_area'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Nuclear Area (Before Gating) IC\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df_gr_gated['nuc_area'], bins=30, color='orange', edgecolor='black')\n",
    "plt.title(\"Nuclear Area (After Gating) IC \")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # (Optional) Save a copy of the gated GR data\n",
    "# df_gr_gated.to_csv(\"GR_ALL_Gated_On_Nuc.csv\", index=False)\n",
    "\n",
    "nuc_mean = df_dusp_gated['nuc_area'].mean()\n",
    "cyto_mean = df_dusp_gated['cyto_area_px'].mean()\n",
    "ratio = nuc_mean / cyto_mean\n",
    "print(\"Estimated (Nuc : Cyto) area ratio =\", ratio)\n",
    "\n",
    "# Remove timepoints 20, 40, 60, 90, 150 without replicas\n",
    "timepoints_to_remove = [20, 40, 60, 90, 150]\n",
    "df_gr_gated = df_gr_gated[~df_gr_gated['time'].isin(timepoints_to_remove)]\n",
    "\n",
    "# # (Optional) Randomly assign Dex=0 rows to 1, 10, 100 nM\n",
    "# # Find rows where Dex_Conc == 0\n",
    "# mask_zero = (df_gr_gated['Dex_Conc'] == 0)\n",
    "# n_zero = mask_zero.sum()\n",
    "# if n_zero > 0:\n",
    "#     # Generate random indices in [0, 2] for each zero row\n",
    "#     rand_indices = np.random.randint(0, 3, size=n_zero)\n",
    "#     dex_values = [1, 10, 100]\n",
    "#     df_gr_gated.loc[mask_zero, 'Dex_Conc'] = [dex_values[i] for i in rand_indices]\n",
    "\n",
    "\n",
    "# 5) COMPUTE \"NORMALIZED\" GR FOR NUC & CYTO IN GR_ALL\n",
    "# =========================\n",
    "#  Define bins & threshold:\n",
    "binsCyt = 30\n",
    "threshold = 0.01\n",
    "\n",
    "#  Sort cytoplasmic intensities:\n",
    "sortGRcyt = df_gr_gated['cytoGRint'].sort_values().values\n",
    "\n",
    "#  Identify the indices for the 1% and 99% cutoffs\n",
    "low_idx  = int(np.ceil(threshold * len(sortGRcyt))) - 1\n",
    "high_idx = int(np.ceil((1 - threshold) * len(sortGRcyt))) - 1\n",
    "\n",
    "\n",
    "#  Gather the min/max thresholds\n",
    "minThreshold = sortGRcyt[low_idx]\n",
    "maxCytGR     = sortGRcyt[high_idx]\n",
    "\n",
    "\n",
    "def apply_cyt_norm(values):\n",
    "    # Scale to [0,1] based on [minThreshold, maxCytGR], then clip\n",
    "    scaled = (values - minThreshold) / (maxCytGR - minThreshold)\n",
    "    clipped = np.clip(scaled, 0, 1)\n",
    "    return np.round(clipped * binsCyt).astype(int)\n",
    "\n",
    "# Compute normGRcyt:\n",
    "df_gr_gated['normGRcyt'] = apply_cyt_norm(df_gr_gated['cytoGRint'])\n",
    "\n",
    "# Brian's Matlab logic for the nuclear intensity:\n",
    "#   'nucGRLevel = ratio * Nuc_GR_avg_int', then scale by the same [minThreshold, maxCytGR].\n",
    "df_gr_gated['nucGR_Level'] = ratio * df_gr_gated['nucGRint']\n",
    "df_gr_gated['normGRnuc']   = apply_cyt_norm(df_gr_gated['nucGR_Level'])\n",
    "\n",
    "# Remove intermediate column:\n",
    "df_gr_gated.drop(columns=['nucGR_Level'], inplace=True)\n",
    "\n",
    "# Debug: check a few rows\n",
    "print(df_gr_gated[['nucGRint','cytoGRint','normGRnuc','normGRcyt']].head())\n",
    "\n",
    "# Save the gated GR data with normalized GR columns\n",
    "df_gr_gated.to_csv(os.path.join(save_dir, f\"GR_ALL_Gated_Normed_{date_str}_Final.csv\"), index=False)\n",
    "\n",
    "# Save the gated DUSP1_ALL data\n",
    "df_dusp_gated.to_csv(os.path.join(save_dir, f\"DUSP1_ALL_Gated_{date_str}_Final.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute quartiles on 'nuc_area'\n",
    "q_low  = cellprops_all['nuc_area'].quantile(0.25)\n",
    "q_high = cellprops_all['nuc_area'].quantile(0.75)\n",
    "\n",
    "# Filter cellprops by nuclear area range\n",
    "gated_cells = cellprops_all[(cellprops_all['nuc_area'] >= q_low) &\n",
    "                             (cellprops_all['nuc_area'] <= q_high)].copy()\n",
    "\n",
    "\n",
    "# Extract unique_cell_ids for gating\n",
    "gated_ids = gated_cells['unique_cell_id'].unique()\n",
    "\n",
    "# Subset SSIT and clusters by gated unique_cell_id\n",
    "ssit_gated     = ssit_all[ssit_all['unique_cell_id'].isin(gated_ids)].copy()\n",
    "clusters_gated = clusters_all[clusters_all['unique_cell_id'].isin(gated_ids)].copy()\n",
    "spots_gated    = spots_all[spots_all['unique_cell_id'].isin(gated_ids)].copy()\n",
    "\n",
    "display(gated_cells.shape, ssit_gated.shape, clusters_gated.shape, spots_gated.shape)\n",
    "\n",
    "# Print cells before and after gating\n",
    "print(f\"Cells before gating: {cellprops_all['unique_cell_id'].nunique()}\")\n",
    "print(f\"Cells after gating: {gated_cells['unique_cell_id'].nunique()}\")\n",
    "# Print spots before and after gating\n",
    "print(f\"Spots before gating: {spots_all['unique_cell_id'].nunique()}\")\n",
    "print(f\"Spots after gating: {spots_gated['unique_cell_id'].nunique()}\")\n",
    "# Print clusters before and after gating\n",
    "print(f\"Clusters before gating: {clusters_all['unique_cell_id'].nunique()}\")\n",
    "print(f\"Clusters after gating: {clusters_gated['unique_cell_id'].nunique()}\")\n",
    "\n",
    "# Save the gated data\n",
    "gated_cells.to_csv(os.path.join(save_dir, f'gated_cells_{date_str}.csv'), index=False)\n",
    "ssit_gated.to_csv(os.path.join(save_dir, f'ssit_gated_{date_str}.csv'), index=False)\n",
    "clusters_gated.to_csv(os.path.join(save_dir, f'clusters_gated_{date_str}.csv'), index=False)\n",
    "spots_gated.to_csv(os.path.join(save_dir, f'spots_gated_{date_str}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the gated data (if already saved)\n",
    "df_dir = \"/Volumes/share/Users/Eric/GR_DUSP1_AllData/DUSP1_AllAnalysis_062425/ConcatPlots\"\n",
    "# gated_cells = pd.read_csv(os.path.join(save_dir, f'gated_cells_{date_str}.csv'))\n",
    "ssit_gated = pd.read_csv(os.path.join(df_dir, f'ssit_gated_Jun24.csv'))\n",
    "# clusters_gated = pd.read_csv(os.path.join(save_dir, f'clusters_gated_{date_str}.csv'))\n",
    "# spots_gated = pd.read_csv(os.path.join(save_dir, f'spots_gated_{date_str}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssit_gated.keys() # Display keys of the gated SSIT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of unique cell IDs in the gated SSIT data\n",
    "print(f\"Unique cell IDs in gated SSIT data: {ssit_gated['unique_cell_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssit_gated['replica'].unique()  # Display unique replicates in the gated SSIT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = ExperimentPlotter(ssit_gated)\n",
    "\n",
    "# 1) 100 nM Time Sweep:\n",
    "plotter.plot_experiment(\n",
    "    replicas=['D','E','F','M','N'],\n",
    "    times=[10,20,30,40,50,60,75,90,120,150,180],\n",
    "    concs=[100],\n",
    "    save_dir=save_dir\n",
    ")\n",
    "\n",
    "# 2) 75 min Conc Sweep:\n",
    "plotter.plot_experiment(\n",
    "    replicas=['G','H','I'],\n",
    "    times=[75],\n",
    "    concs=[0.001,0.01,0.1,1,10,100,1000,10000],\n",
    "    save_dir=save_dir\n",
    ")\n",
    "\n",
    "# 3) Both‐varying: 0.3,1,10 nM across multiple times:\n",
    "plotter.plot_experiment(\n",
    "    replicas=['J','K','L'],\n",
    "    times=[30,50,75,90,120,180],\n",
    "    concs=[0.3,1,10],\n",
    "    save_dir=save_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cytoplasmic and Nuclear mRNA Spot Counts at 0 min\n",
    "\n",
    "# Make a copy of the DUSP1 data\n",
    "DUSP1_data = ssit_gated.copy()\n",
    "\n",
    "# Subset data for 0 min time points\n",
    "df_0min = DUSP1_data[DUSP1_data['time'] == 0]\n",
    "\n",
    "# Plot distribution of nuclear and cytoplasmic mRNA spots across replicas for 0 min time point\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "sns.boxplot(data=df_0min, x='replica', y='num_nuc_spots', ax=axes[0])\n",
    "axes[0].set_title('Nuclear mRNA Spot Counts at 0 min')\n",
    "axes[0].set_ylabel('Nuclear Spot Count')\n",
    "axes[0].set_xlabel('Replica')\n",
    "\n",
    "sns.boxplot(data=df_0min, x='replica', y='num_cyto_spots', ax=axes[1])\n",
    "axes[1].set_title('Cytoplasmic mRNA Spot Counts at 0 min')\n",
    "axes[1].set_ylabel('Cytoplasmic Spot Count')\n",
    "axes[1].set_xlabel('Replica')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
